{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T23:55:16.424411Z",
     "start_time": "2025-06-03T23:55:16.416845Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import platform\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "from collections import defaultdict\n",
    "import joblib\n",
    "import json\n",
    "import warnings\n",
    "import time\n",
    "from scipy.stats.mstats import winsorize\n",
    "import numba\n",
    "import pandas_ta as pta\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add one directory up to sys.path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "# Internal Libraries\n",
    "from data_loader import load_and_resample_data, apply_feature_engineering\n",
    "from backtest import evaluate_regression\n",
    "from labeling_utils import label_and_save\n",
    "from helpers import check_overfit, generate_oof_predictions, is_same_session\n",
    "#\n",
    "\n",
    "# Tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.losses import Huber, MeanSquaredError\n",
    "import tensorflow as tf\n",
    "#\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.base import clone, BaseEstimator, RegressorMixin, ClassifierMixin\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, cross_val_predict\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, StackingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, ElasticNet, Ridge, ElasticNetCV, RidgeCV\n",
    "from sklearn.metrics import classification_report, root_mean_squared_error, mean_squared_error, mean_absolute_error, r2_score, \\\n",
    "    confusion_matrix, precision_recall_curve, roc_curve, auc, accuracy_score, classification_report, f1_score, precision_score, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import label_binarize, StandardScaler, LabelEncoder\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils.class_weight import compute_sample_weight, compute_class_weight\n",
    "\n",
    "# Models and Training\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.svm import SVC\n",
    "#\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*There are no meaningful features.*\", category=UserWarning)\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "market = \"NQ\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize features or indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T23:55:16.469642Z",
     "start_time": "2025-06-03T23:55:16.434730Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is your Cell 5: Feature Engineering Function Definitions\n",
    "\n",
    "# --- Helper Functions for Custom Features (Some will be kept, some modified/called differently) ---\n",
    "# These helpers now expect columns to be named as pandas_ta typically names them (e.g., RSI_14, EMA_10, MACD_12_26_9, etc.)\n",
    "def add_market_regime_features(df):\n",
    "    chop_col = f'CHOP_14_1_100'\n",
    "    adx_col = f'ADX_14'\n",
    "    atr_col = f'ATR_14'  # Use base_tf for ATR\n",
    "\n",
    "    # Handle missing data\n",
    "    if any(col not in df.columns for col in [chop_col, adx_col, atr_col]):\n",
    "        raise ValueError(f\"Required columns not found for regime detection: {chop_col}, {adx_col}, {atr_col}\")\n",
    "\n",
    "    atr_thresh = df[atr_col].rolling(100, min_periods=20).mean() * 1.1\n",
    "\n",
    "    df['Is_Trending'] = (df[adx_col] > 20).astype(int)\n",
    "    df['Is_Choppy'] = (df[chop_col] > 60).astype(int)\n",
    "    df['Is_High_Vol'] = (df[atr_col] > atr_thresh).astype(int)\n",
    "    df['Is_Low_Vol'] = (df[atr_col] <= atr_thresh).astype(int)\n",
    "\n",
    "    df['Market_Regime'] = (\n",
    "        df['Is_Trending'].astype(str) + \"_\" +\n",
    "        df['Is_High_Vol'].astype(str)\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_price_vs_ma(df, price_col='close', ma_col_name='EMA_20', new_col_name_suffix='_vs_EMA20'):\n",
    "    # Ensure ma_col_name exists (it would have been created by pandas_ta)\n",
    "    if ma_col_name in df.columns and price_col in df.columns:\n",
    "        # Ensure inputs are numeric before division\n",
    "        df[price_col + new_col_name_suffix] = pd.to_numeric(df[price_col], errors='coerce') / pd.to_numeric(df[ma_col_name], errors='coerce')\n",
    "    return df\n",
    "\n",
    "def add_ma_vs_ma(df, ma1_col_name='EMA_10', ma2_col_name='EMA_20', new_col_name_suffix='_vs_EMA20'):\n",
    "    if ma1_col_name in df.columns and ma2_col_name in df.columns:\n",
    "        df[ma1_col_name + new_col_name_suffix] = pd.to_numeric(df[ma1_col_name], errors='coerce') / pd.to_numeric(df[ma2_col_name], errors='coerce')\n",
    "    return df\n",
    "\n",
    "def add_ma_slope(df, ma_col_name='EMA_10', new_col_name_suffix='_Slope_10', periods=1):\n",
    "    if ma_col_name in df.columns:\n",
    "        df[new_col_name_suffix] = pd.to_numeric(df[ma_col_name], errors='coerce').diff(periods) / periods\n",
    "    return df\n",
    "\n",
    "def add_rsi_signals(df, rsi_col_name='RSI_14', ob_level=70, os_level=30):\n",
    "    if rsi_col_name in df.columns:\n",
    "        rsi_series = pd.to_numeric(df[rsi_col_name], errors='coerce')\n",
    "        df[rsi_col_name + f'_Is_Overbought_{ob_level}'] = (rsi_series > ob_level).astype(int)\n",
    "        df[rsi_col_name + f'_Is_Oversold_{os_level}'] = (rsi_series < os_level).astype(int)\n",
    "    return df\n",
    "\n",
    "def add_stoch_signals(df, stoch_k_col_name='STOCHk_14_3_3', ob_level=80, os_level=20): # Default pandas_ta name for k\n",
    "    if stoch_k_col_name in df.columns:\n",
    "        stoch_k_series = pd.to_numeric(df[stoch_k_col_name], errors='coerce')\n",
    "        df[stoch_k_col_name + f'_Is_Overbought_{ob_level}'] = (stoch_k_series > ob_level).astype(int)\n",
    "        df[stoch_k_col_name + f'_Is_Oversold_{os_level}'] = (stoch_k_series < os_level).astype(int)\n",
    "    return df\n",
    "\n",
    "def add_macd_cross_signal(df, macd_col_name='MACD_12_26_9', signal_col_name='MACDs_12_26_9'): # Default pandas_ta name for signal\n",
    "    if macd_col_name in df.columns and signal_col_name in df.columns:\n",
    "        macd_series = pd.to_numeric(df[macd_col_name], errors='coerce')\n",
    "        signal_series = pd.to_numeric(df[signal_col_name], errors='coerce')\n",
    "        crossed_above = (macd_series > signal_series) & (macd_series.shift(1) < signal_series.shift(1))\n",
    "        crossed_below = (macd_series < signal_series) & (macd_series.shift(1) > signal_series.shift(1))\n",
    "        df[macd_col_name + '_Cross_Signal'] = np.where(crossed_above, 1, np.where(crossed_below, -1, 0))\n",
    "    return df\n",
    "\n",
    "def add_price_vs_bb(df, price_col='close', bb_upper_col='BBU_20_2.0', bb_lower_col='BBL_20_2.0'): # Default pandas_ta names\n",
    "    if price_col in df.columns and bb_upper_col in df.columns and bb_lower_col in df.columns:\n",
    "        price_series = pd.to_numeric(df[price_col], errors='coerce')\n",
    "        bb_upper_series = pd.to_numeric(df[bb_upper_col], errors='coerce')\n",
    "        bb_lower_series = pd.to_numeric(df[bb_lower_col], errors='coerce')\n",
    "        df[price_col + '_vs_BB_Upper'] = (price_series > bb_upper_series).astype(int)\n",
    "        df[price_col + '_vs_BB_Lower'] = (price_series < bb_lower_series).astype(int)\n",
    "    return df\n",
    "\n",
    "def add_daily_vwap(df, high_col='high', low_col='low', close_col='close', volume_col='volume', new_col_name='VWAP_D'): # Changed name to VWAP_D for daily\n",
    "    # ... (your existing robust add_daily_vwap function - ensure it uses .copy() and numeric conversions internally)\n",
    "    # Make sure the final column is named VWAP_D or adjust add_price_vs_ma call later\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        print(\"Error: DataFrame index must be DatetimeIndex for daily VWAP.\")\n",
    "        return df\n",
    "    df_temp = df.copy()\n",
    "    for col in [high_col, low_col, close_col, volume_col]:\n",
    "        df_temp[col] = pd.to_numeric(df_temp[col], errors='coerce')\n",
    "    tpv = ((df_temp[high_col] + df_temp[low_col] + df_temp[close_col]) / 3) * df_temp[volume_col]\n",
    "    cumulative_tpv = tpv.groupby(df_temp.index.date).cumsum()\n",
    "    cumulative_volume = df_temp[volume_col].groupby(df_temp.index.date).cumsum()\n",
    "    vwap_series = cumulative_tpv / cumulative_volume\n",
    "    df[new_col_name] = vwap_series.replace([np.inf, -np.inf], np.nan)\n",
    "    return df\n",
    "\n",
    "def add_candle_features(df):\n",
    "    # ... (your existing add_candle_features function - ensure numeric conversions) ...\n",
    "    df_temp = df.copy()\n",
    "    for col in ['open', 'high', 'low', 'close']:\n",
    "        df_temp[col] = pd.to_numeric(df_temp[col], errors='coerce')\n",
    "    df['Candle_Range'] = df_temp['high'] - df_temp['low']\n",
    "    df['Candle_Body'] = (df_temp['close'] - df_temp['open']).abs()\n",
    "    df['Upper_Wick'] = df_temp['high'] - np.maximum(df_temp['open'], df_temp['close'])\n",
    "    df['Upper_Wick_Length'] = df_temp['high'] - df_temp[['open','close']].max(axis=1)\n",
    "    df['Lower_Wick'] = np.minimum(df_temp['open'], df_temp['close']) - df_temp['low']\n",
    "    df['Body_vs_Range'] = (df['Candle_Body'] / df['Candle_Range'].replace(0, np.nan)).replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    df['Is_Bearish_Wick']   = (\n",
    "        (df_temp['close'] < df_temp['open']) &\n",
    "        (df['Upper_Wick_Length'] > 2 * df['Candle_Body']) &\n",
    "        ((df_temp[['open','close']].min(axis=1) - df_temp['low']) < 0.2 * df['Candle_Body'])\n",
    "    ).astype(int)\n",
    "    return df\n",
    "\n",
    "def add_return_features(df, price_col='close'):\n",
    "    # ... (your existing add_return_features function - ensure numeric conversions and inf handling) ...\n",
    "    price_series_num = pd.to_numeric(df[price_col], errors='coerce').replace(0, np.nan)\n",
    "    df[f'Log_Return_1'] = np.log(price_series_num / price_series_num.shift(1))\n",
    "    df[f'Log_Return_3'] = np.log(price_series_num / price_series_num.shift(3))\n",
    "    df[f'Log_Return_6'] = np.log(price_series_num / price_series_num.shift(6))\n",
    "    df[f'Simple_Return_1'] = price_series_num.pct_change(1)\n",
    "    for col_ret in [f'Log_Return_1', f'Log_Return_3', f'Log_Return_6', f'Simple_Return_1']:\n",
    "        if col_ret in df.columns: df[col_ret] = df[col_ret].replace([np.inf, -np.inf], np.nan)\n",
    "    return df\n",
    "\n",
    "def add_rolling_stats(df, price_col='close', window1=14, window2=30):\n",
    "    # ... (your existing add_rolling_stats function - ensure numeric conversions and inf handling) ...\n",
    "    returns = pd.to_numeric(df[price_col], errors='coerce').pct_change(1).replace([np.inf, -np.inf], np.nan)\n",
    "    df[f'Rolling_Std_Dev_{window1}'] = returns.rolling(window=window1).std()\n",
    "    df[f'Rolling_Skew_{window2}'] = returns.rolling(window=window2).skew()\n",
    "    df[f'Rolling_Kurtosis_{window2}'] = returns.rolling(window=window2).kurt()\n",
    "    return df\n",
    "\n",
    "def add_lagged_features(df, cols_to_lag, lags=[1, 3, 6]):\n",
    "    # ... (your existing add_lagged_features function - ensure numeric conversions on source col if needed) ...\n",
    "    for col_orig in cols_to_lag:\n",
    "        if col_orig in df.columns:\n",
    "            series_to_lag = pd.to_numeric(df[col_orig], errors='coerce')\n",
    "            for lag in lags:\n",
    "                df[f'{col_orig}_Lag_{lag}'] = series_to_lag.shift(lag)\n",
    "    return df\n",
    "\n",
    "def add_trend_features(df_input, suffix=''):\n",
    "    \"\"\"\n",
    "    Add trend, volatility regime, and momentum features with proper suffix handling.\n",
    "    Assumes standard column names from pandas_ta (e.g., EMA_20, VWAP_D, etc.)\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    \n",
    "    # Ensure we have the base columns with correct suffixes\n",
    "    required_cols = [\n",
    "        f'EMA_20{suffix}', f'EMA_50{suffix}', \n",
    "        f'VWAP_D{suffix}', f'ATR_14{suffix}',\n",
    "        f'RSI_14{suffix}', f'close'\n",
    "    ]\n",
    "    \n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        print(f\"Warning: Missing some required columns for trend features with suffix {suffix}\")\n",
    "        return df\n",
    "\n",
    "    # Trend Direction using EMAs\n",
    "    df[f'Trend_Direction{suffix}'] = np.where(\n",
    "        df[f'EMA_20{suffix}'] > df[f'EMA_50{suffix}'], 1, -1\n",
    "    )\n",
    "    \n",
    "    # Price vs VWAP (normalized)\n",
    "    df[f'Price_vs_VWAP{suffix}'] = (\n",
    "        df['close'] / df[f'VWAP_D{suffix}'] - 1\n",
    "    ) * 100  # Convert to percentage\n",
    "    \n",
    "    # Volatility Regime (normalized)\n",
    "    vol_short = df[f'ATR_14{suffix}'].rolling(24).mean()\n",
    "    vol_long = df[f'ATR_14{suffix}'].rolling(120).mean()\n",
    "    df[f'Vol_Regime{suffix}'] = (vol_short / vol_long - 1) * 100\n",
    "    \n",
    "    # Momentum Confirmation (multiple timeframe alignment)\n",
    "    df[f'RSI_Trend_Align{suffix}'] = (\n",
    "        (df[f'RSI_14{suffix}'] > 50) & \n",
    "        (df[f'EMA_20{suffix}'] > df[f'EMA_50{suffix}'])\n",
    "    ).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# --- Main Feature Generation Function using pandas_ta ---\n",
    "def add_all_features(df_input, suffix=''):\n",
    "    \"\"\"\n",
    "    Adds technical indicators and derived features using pandas_ta.\n",
    "    Assumes df_input has 'open', 'high', 'low', 'close', 'volume' columns (DatetimeIndex).\n",
    "    \"\"\"\n",
    "    if not isinstance(df_input.index, pd.DatetimeIndex):\n",
    "        print(f\"Warning: DataFrame for suffix '{suffix}' does not have a DatetimeIndex.\")\n",
    "    \n",
    "    df = df_input.copy() # Work on a copy\n",
    "\n",
    "    # Ensure base OHLCV columns are numeric and present\n",
    "    base_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "    if not all(col in df.columns for col in base_cols):\n",
    "         raise ValueError(f\"DataFrame must contain {base_cols}. Found: {df.columns.tolist()}\")\n",
    "    for col in base_cols: # Ensure correct dtypes for pandas_ta\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df.dropna(subset=base_cols, inplace=True) # Drop rows if OHLCV became NaN\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"DataFrame became empty after coercing OHLCV for suffix '{suffix}'. Returning empty DataFrame.\")\n",
    "        # Return an empty dataframe with expected suffixed columns if possible or raise error\n",
    "        # For simplicity, we'll let it create columns that will be all NaN, then suffixing will apply.\n",
    "        # Or handle more gracefully by creating expected columns with NaNs.\n",
    "        # For now, we will proceed, and suffixing will apply to what gets created.\n",
    "        pass\n",
    "\n",
    "\n",
    "    print(f\"DataFrame shape for pandas_ta (suffix: {suffix}): {df.shape}\")\n",
    "\n",
    "    # I. Technical Indicators using pandas_ta\n",
    "    # Most pandas_ta functions automatically name columns (e.g., SMA_10, RSI_14)\n",
    "    # and handle NaNs internally. `append=True` adds them to df.\n",
    "\n",
    "    # Volume\n",
    "    df.ta.sma(close=df['volume'], length=20, append=True, col_names=('Volume_SMA_20'))\n",
    "    df = add_daily_vwap(df, new_col_name='VWAP_D') # Using your custom daily VWAP, named VWAP_D\n",
    "    df = add_price_vs_ma(df, ma_col_name='VWAP_D', new_col_name_suffix='_vs_VWAP_D')\n",
    "\n",
    "    # Volatility\n",
    "    df.ta.bbands(length=20, std=2, append=True) # Creates BBL_20_2.0, BBM_20_2.0, BBU_20_2.0, BBB_20_2.0, BBP_20_2.0\n",
    "    # Helpers will need these names: BBU_20_2.0, BBL_20_2.0\n",
    "    df = add_price_vs_bb(df, bb_upper_col='BBU_20_2.0', bb_lower_col='BBL_20_2.0')\n",
    "    df.ta.atr(length=14, append=True, col_names=('ATR_14')) # pandas_ta might name it ATRr_14 or similar. We force ATR_14.\n",
    "\n",
    "    # Trend\n",
    "    df.ta.sma(length=10, append=True) # SMA_10\n",
    "    df.ta.sma(length=20, append=True) # SMA_20 (also BBM_20_2.0 from bbands)\n",
    "    df.ta.sma(length=50, append=True) # SMA_50\n",
    "    df.ta.ema(length=10, append=True) # EMA_10\n",
    "    df.ta.ema(length=20, append=True) # EMA_20\n",
    "    df.ta.ema(length=50, append=True) # EMA_50\n",
    "    \n",
    "    df = add_price_vs_ma(df, ma_col_name='EMA_20', new_col_name_suffix='_vs_EMA20')\n",
    "    df = add_ma_vs_ma(df, ma1_col_name='EMA_10', ma2_col_name='EMA_20', new_col_name_suffix='_vs_EMA20')\n",
    "    df = add_ma_slope(df, ma_col_name='EMA_10', new_col_name_suffix='_Slope_10')\n",
    "\n",
    "    df.ta.macd(fast=12, slow=26, signal=9, append=True) # MACD_12_26_9, MACDh_12_26_9, MACDs_12_26_9\n",
    "    df = add_macd_cross_signal(df, macd_col_name='MACD_12_26_9', signal_col_name='MACDs_12_26_9')\n",
    "\n",
    "    df.ta.adx(length=14, append=True) # ADX_14, DMP_14, DMN_14\n",
    "    # Rename DMN_14 and DMP_14 to match your old Minus_DI_14, Plus_DI_14 if helpers depend on it\n",
    "    if 'DMP_14' in df.columns: df.rename(columns={'DMP_14': 'Plus_DI_14'}, inplace=True)\n",
    "    if 'DMN_14' in df.columns: df.rename(columns={'DMN_14': 'Minus_DI_14'}, inplace=True)\n",
    "\n",
    "    df.ta.cci(length=20, append=True, col_names=('CCI_20')) # pandas_ta uses CCI_20_0.015 by default\n",
    "\n",
    "    # Momentum\n",
    "    df.ta.rsi(length=14, append=True) # RSI_14\n",
    "    df = add_rsi_signals(df, rsi_col_name='RSI_14')\n",
    "    df.ta.chop(length=14, append=True)  # Adds column: CHOP_14\n",
    "\n",
    "    df.ta.willr(length=14, append=True)  # Adds column: WILLR_14\n",
    "\n",
    "    \n",
    "    df.ta.stoch(k=14, d=3, smooth_k=3, append=True) # STOCHk_14_3_3, STOCHd_14_3_3\n",
    "    df = add_stoch_signals(df, stoch_k_col_name='STOCHk_14_3_3')\n",
    "\n",
    "    df.ta.ppo(fast=12, slow=26, signal=9, append=True) # PPO_12_26_9, PPOh_12_26_9, PPOs_12_26_9\n",
    "    df.ta.roc(length=10, append=True) # ROC_10\n",
    "    \n",
    "    # Explicitly convert PPO and ROC to numeric (belt and braces after pandas_ta)\n",
    "    for col_name in ['PPO_12_26_9', 'ROC_10']: # Check exact names if pandas_ta produces variants\n",
    "        base_name_ppo = [c for c in df.columns if \"PPO_\" in c and \"PPOh\" not in c and \"PPOs\" not in c]\n",
    "        base_name_roc = [c for c in df.columns if \"ROC_\" in c]\n",
    "        \n",
    "        for actual_col_name in base_name_ppo + base_name_roc:\n",
    "            if actual_col_name in df.columns:\n",
    "                df[actual_col_name] = df[actual_col_name].replace([np.inf, -np.inf], np.nan)\n",
    "                df[actual_col_name] = pd.to_numeric(df[actual_col_name], errors='coerce')\n",
    "\n",
    "    # II. Price Action & Basic Features (Keep your custom functions)\n",
    "    df = add_candle_features(df)\n",
    "    # df = add_candlestick_patterns(df) # We'll replace this with pandas_ta candlestick patterns\n",
    "\n",
    "    # --- pandas_ta Candlestick Patterns ---\n",
    "    # Example: Add Doji, Hammer, Engulfing. pandas_ta has many more.\n",
    "    # 'name=\"all\"' would add many columns, so be selective or use a list.\n",
    "    candle_patterns_to_check = [\"doji\", \"hammer\", \"engulfing\"] \n",
    "    df.ta.cdl_pattern(name=candle_patterns_to_check, append=True)\n",
    "    # Rename columns to match your old convention if needed, e.g., CDLDOJI -> Is_Doji\n",
    "    if 'CDLDOJI' in df.columns: df.rename(columns={'CDLDOJI': 'Is_Doji_pta'}, inplace=True) # Add _pta to distinguish\n",
    "    if 'CDLHAMMER' in df.columns: df.rename(columns={'CDLHAMMER': 'Is_Hammer_pta'}, inplace=True)\n",
    "    if 'CDLENGULFING' in df.columns: df.rename(columns={'CDLENGULFING': 'Is_Engulfing_pta'}, inplace=True) # This is a general engulfing signal (+/-)\n",
    "\n",
    "    df = add_return_features(df)\n",
    "\n",
    "    # III. Statistical Features (Keep your custom functions)\n",
    "    df = add_rolling_stats(df)\n",
    "    \n",
    "    # Lagged Features\n",
    "    # Ensure base columns for lagging are the ones created by pandas_ta or your helpers\n",
    "    cols_to_lag_pta = ['close', 'RSI_14', 'Candle_Body', 'Volume_SMA_20'] \n",
    "    # Check if these columns actually exist, as pandas_ta might name them slightly differently\n",
    "    # This valid_cols_to_lag should use the names as they are in df at this point\n",
    "    valid_cols_to_lag = [col for col in cols_to_lag_pta if col in df.columns]\n",
    "    df = add_lagged_features(df, valid_cols_to_lag, lags=[1,2,3])\n",
    "    df = add_market_regime_features(df)\n",
    "\n",
    "    # --- Suffixing ---\n",
    "    # All columns created by pandas_ta (that were appended) or by helpers\n",
    "    # that are not the original 'open', 'high', 'low', 'close', 'volume' will be suffixed.\n",
    "    current_cols = list(df.columns)\n",
    "    # Identify features generated in this function call (not the original base OHLCV)\n",
    "    generated_feature_cols = [col for col in current_cols if col not in base_cols]\n",
    "    \n",
    "    rename_dict = {col: col + suffix for col in generated_feature_cols}\n",
    "    df.rename(columns=rename_dict, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_trend_features(df_input, suffix=''):\n",
    "    \"\"\"\n",
    "    Enhanced trend features with proper suffix handling.\n",
    "    Assumes standard column names from pandas_ta with appropriate suffixes.\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    \n",
    "    # Required columns check with suffix\n",
    "    required_cols = [\n",
    "        f'EMA_20{suffix}', f'EMA_50{suffix}', \n",
    "        f'VWAP_D{suffix}', f'ATR_14{suffix}',\n",
    "        f'RSI_14{suffix}', f'MACD_12_26_9{suffix}',\n",
    "        f'BBM_20_2.0{suffix}',  # BB middle band\n",
    "        'close', 'volume'  # Base columns without suffix\n",
    "    ]\n",
    "    \n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        print(f\"Warning: Missing some required columns for trend features with suffix {suffix}\")\n",
    "        return df\n",
    "\n",
    "    # 1. Trend Direction Features\n",
    "    df[f'Trend_Direction{suffix}'] = np.where(\n",
    "        df[f'EMA_20{suffix}'] > df[f'EMA_50{suffix}'], 1, -1\n",
    "    )\n",
    "    \n",
    "    # 2. Trend Strength (normalized)\n",
    "    df[f'Trend_Strength{suffix}'] = (\n",
    "        (df[f'EMA_20{suffix}'] - df[f'EMA_50{suffix}']) / \n",
    "        df[f'ATR_14{suffix}']\n",
    "    ).rolling(20).mean()\n",
    "    \n",
    "    # 3. Price vs Moving Averages (percentage based)\n",
    "    df[f'Price_vs_EMA20{suffix}'] = (\n",
    "        (df['close'] - df[f'EMA_20{suffix}']) / \n",
    "        df[f'EMA_20{suffix}'] * 100\n",
    "    )\n",
    "    \n",
    "    # 4. VWAP-based trend\n",
    "    df[f'Price_vs_VWAP{suffix}'] = (\n",
    "        (df['close'] - df[f'VWAP_D{suffix}']) / \n",
    "        df[f'VWAP_D{suffix}'] * 100\n",
    "    )\n",
    "    \n",
    "    # 5. Volatility Regime Features\n",
    "    vol_short = df[f'ATR_14{suffix}'].rolling(24).mean()\n",
    "    vol_long = df[f'ATR_14{suffix}'].rolling(120).mean()\n",
    "    df[f'Vol_Regime{suffix}'] = (\n",
    "        (vol_short / vol_long - 1) * 100\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # 6. Volume-Weighted Trend\n",
    "    volume_ma = df['volume'].rolling(20).mean()\n",
    "    df[f'Volume_Trend{suffix}'] = (\n",
    "        df['volume'] / volume_ma - 1\n",
    "    ) * df[f'Trend_Direction{suffix}']\n",
    "    \n",
    "    # 7. Multi-Indicator Trend Alignment\n",
    "    df[f'Trend_Alignment{suffix}'] = (\n",
    "        (df[f'EMA_20{suffix}'] > df[f'EMA_50{suffix}']) &  # EMA trend\n",
    "        (df['close'] > df[f'VWAP_D{suffix}']) &            # Above VWAP\n",
    "        (df[f'RSI_14{suffix}'] > 50) &                     # RSI momentum\n",
    "        (df[f'MACD_12_26_9{suffix}'] > 0)                  # MACD positive\n",
    "    ).astype(int)\n",
    "    \n",
    "    # 8. Mean Reversion Potential\n",
    "    df[f'Mean_Reversion{suffix}'] = (\n",
    "        (df['close'] - df[f'BBM_20_2.0{suffix}']) / \n",
    "        df[f'ATR_14{suffix}']\n",
    "    ).rolling(10).mean()\n",
    "    \n",
    "    # 9. Trend Acceleration\n",
    "    df[f'Trend_Acceleration{suffix}'] = (\n",
    "        df[f'EMA_20{suffix}'].diff() - \n",
    "        df[f'EMA_50{suffix}'].diff()\n",
    "    ) / df[f'ATR_14{suffix}']\n",
    "    \n",
    "    # 10. Composite Trend Score (-100 to +100)\n",
    "    df[f'Trend_Score{suffix}'] = (\n",
    "        (df[f'Trend_Direction{suffix}'] * 20) +                    # Base direction\n",
    "        (df[f'Price_vs_EMA20{suffix}'].clip(-20, 20)) +          # Price vs EMA\n",
    "        (df[f'RSI_14{suffix}'] - 50) +                           # RSI contribution\n",
    "        (np.sign(df[f'MACD_12_26_9{suffix}']) * 10) +           # MACD direction\n",
    "        (df[f'Volume_Trend{suffix}'].clip(-20, 20)) +           # Volume trend\n",
    "        (df[f'Trend_Alignment{suffix}'] * 20)                    # Alignment bonus\n",
    "    ).clip(-100, 100)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# --- Time & Session Features (Keep as is) ---\n",
    "def add_time_session_features(df):\n",
    "    # ... (your existing add_time_session_features function) ...\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        print(\"Error: DataFrame index must be DatetimeIndex for time/session features.\")\n",
    "        return df\n",
    "    df = df.copy()\n",
    "    df['Hour_of_Day'] = df.index.hour\n",
    "    df['Minute_of_Hour'] = df.index.minute\n",
    "    df['Day_of_Week'] = df.index.dayofweek\n",
    "    time_fraction_of_day = df['Hour_of_Day'] + df['Minute_of_Hour'] / 60.0\n",
    "    df['Time_Sin'] = np.sin(2 * np.pi * time_fraction_of_day / 24.0)\n",
    "    df['Time_Cos'] = np.cos(2 * np.pi * time_fraction_of_day / 24.0)\n",
    "    df['Day_Sin'] = np.sin(2 * np.pi * df['Day_of_Week'] / 7.0)\n",
    "    df['Day_Cos'] = np.cos(2 * np.pi * df['Day_of_Week'] / 7.0)\n",
    "    df['Is_Asian_Session'] = ((df['Hour_of_Day'] >= 20) | (df['Hour_of_Day'] < 5)).astype(int)\n",
    "    df['Is_London_Session'] = ((df['Hour_of_Day'] >= 3) & (df['Hour_of_Day'] < 12)).astype(int)\n",
    "    df['Is_NY_Session'] = ((df['Hour_of_Day'] >= 8) & (df['Hour_of_Day'] < 17)).astype(int)\n",
    "    df['Is_Overlap'] = ((df['Hour_of_Day'] >= 8) & (df['Hour_of_Day'] < 12)).astype(int)\n",
    "    df['Is_US_Open_Hour'] = ((df['Hour_of_Day'] == 9) & (df['Minute_of_Hour'] >= 30) | (df['Hour_of_Day'] == 10) & (df['Minute_of_Hour'] < 30)).astype(int)\n",
    "    df['Is_US_Close_Hour'] = ((df['Hour_of_Day'] == 15) | (df['Hour_of_Day'] == 16) & (df['Minute_of_Hour'] == 0)).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T23:55:16.521479Z",
     "start_time": "2025-06-03T23:55:16.518032Z"
    }
   },
   "outputs": [],
   "source": [
    "avoid_funcs = {\n",
    "    #'avoid_hour_18_19': avoid_hour_18_19\n",
    "    #'news_window': avoid_news,\n",
    "}\n",
    "\n",
    "param_grid_strategy = {\n",
    "    'SL_ATR_MULT': [1.0, 1.5, 2.0],  # Wider stops\n",
    "    'TP_ATR_MULT': [3.0, 4.0, 5.0, 8.0],   # More conservative targets\n",
    "    'TRAIL_START_MULT': [1.0, 1.5],    # Let winners run\n",
    "    'TRAIL_STOP_MULT': [0.8, 1.0],     # Tighter trailing stops\n",
    "    'TICK_VALUE': [20],\n",
    "}\n",
    "\n",
    "keys, values = zip(*param_grid_strategy.items())\n",
    "combinations = [dict(zip(keys, v)) for v in product(*values)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T23:55:25.118760Z",
     "start_time": "2025-06-03T23:55:16.558279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Found matching folder: ./../data/NQ\n",
      "5min shape: (300923, 5)\n",
      "15min shape: (100530, 5)\n",
      "1h shape: (25383, 5)\n",
      "--- Starting Feature Engineering Execution ---\n",
      "\n",
      "Generating features for timeframe: 5min — shape: (300923, 5)\n",
      "DataFrame shape for pandas_ta (suffix: _5min): (300923, 5)\n",
      "Adding trend features for timeframe: 5min\n",
      "Output shape for 5min: (300923, 90)\n",
      "\n",
      "Generating features for timeframe: 15min — shape: (100530, 5)\n",
      "DataFrame shape for pandas_ta (suffix: _15min): (100530, 5)\n",
      "Adding trend features for timeframe: 15min\n",
      "Output shape for 15min: (100530, 90)\n",
      "\n",
      "Generating features for timeframe: 1h — shape: (25383, 5)\n",
      "DataFrame shape for pandas_ta (suffix: _1h): (25383, 5)\n",
      "Adding trend features for timeframe: 1h\n",
      "Output shape for 1h: (25383, 90)\n",
      "\n",
      "Adding time/session features to base timeframe: 5min\n",
      "\n",
      "Merging additional timeframe features into base...\n",
      "--- Feature Engineering Execution COMPLETE ---\n",
      "Final df_merged shape: (300923, 273)\n",
      "Original merged dataset shape: (300923, 273)\n",
      "Rows with at least one NaN: 794 out of 300923 (0.26%)\n"
     ]
    }
   ],
   "source": [
    "df_1min, resampled = load_and_resample_data(market, timeframes=['5min', '15min','1h'])\n",
    "\n",
    "df_5min = resampled['5min']\n",
    "df_15min = resampled['15min']\n",
    "df_1hr = resampled['1h']\n",
    "\n",
    "print(\"5min shape:\", df_5min.shape)\n",
    "print(\"15min shape:\", df_15min.shape)\n",
    "print(\"1h shape:\", df_1hr.shape)\n",
    "\n",
    "\n",
    "df_merged = apply_feature_engineering(\n",
    "    resampled=resampled,\n",
    "    add_all_features=add_all_features,\n",
    "    add_time_session_features=add_time_session_features,\n",
    "    add_trend_features=add_trend_features,  # Pass your trend features function here\n",
    "    timeframes=['5min', '15min', '1h'],\n",
    "    base_tf='5min'\n",
    ")\n",
    "\n",
    "# Add this code right after the feature engineering but before model fitting\n",
    "\n",
    "print(f\"Original merged dataset shape: {df_merged.shape}\")\n",
    "\n",
    "# Count rows with at least one NaN\n",
    "nan_rows_count = df_merged.isna().any(axis=1).sum()\n",
    "total_rows = len(df_merged)\n",
    "print(f\"Rows with at least one NaN: {nan_rows_count} out of {total_rows} ({(nan_rows_count/total_rows)*100:.2f}%)\")\n",
    "\n",
    "\n",
    "# Verify Data\n",
    "# def check_feature_alignment(df_merged, tf_suffix, feature_keyword, sample_times):\n",
    "#     \"\"\"\n",
    "#     Check if features from the correct timeframe are available and what values they have at key timestamps.\n",
    "#     \"\"\"\n",
    "#     suffix_str = f\"_{tf_suffix}\"\n",
    "#     matching_cols = [col for col in df_merged.columns if feature_keyword in col and col.endswith(suffix_str)]\n",
    "    \n",
    "#     print(f\"\\n🔍 Checking features containing '{feature_keyword}' with suffix '{suffix_str}'\")\n",
    "\n",
    "#     if not matching_cols:\n",
    "#         print(f\"⚠️ No matching columns found. Available columns ending with {suffix_str}:\")\n",
    "#         sample_suffix_cols = [col for col in df_merged.columns if col.endswith(suffix_str)]\n",
    "#         print(sample_suffix_cols[:10])  # Show only first 10 to keep it clean\n",
    "#         return\n",
    "\n",
    "#     for time in sample_times:\n",
    "#         if time not in df_merged.index:\n",
    "#             print(f\"❌ Time {time} not found in df_merged index.\")\n",
    "#         else:\n",
    "#             print(f\"\\n⏰ At time {time} — values:\")\n",
    "#             print(df_merged.loc[time, matching_cols])\n",
    "\n",
    "# sample_times = [\n",
    "#     pd.Timestamp(\"2022-01-05 12:05:00-05:00\"),\n",
    "#     pd.Timestamp(\"2022-01-05 12:15:00-05:00\"),\n",
    "#     pd.Timestamp(\"2022-01-05 12:59:00-05:00\"),\n",
    "#     pd.Timestamp(\"2022-01-05 13:00:00-05:00\")\n",
    "# ]\n",
    "\n",
    "# check_feature_alignment(df_merged, tf_suffix=\"1h\", feature_keyword=\"RSI\", sample_times=sample_times)\n",
    "# check_feature_alignment(df_merged, tf_suffix=\"15min\", feature_keyword=\"MACD\", sample_times=sample_times)\n",
    "# check_feature_alignment(df_merged, tf_suffix=\"5min\", feature_keyword=\"EMA\", sample_times=sample_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T23:55:28.681923Z",
     "start_time": "2025-06-03T23:55:25.163561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing for output suffix: L12_PT2SL1VB12NQ ---\n",
      "Adding Regression Targets...\n",
      "reg_value NaNs: 14\n",
      "reg_side  NaNs: 0\n",
      "\n",
      "Adding Classification Target: clf_target_numba_pt2.0sl1.0vb12 ...\n",
      "clf_target_numba_pt2.0sl1.0vb12 NaNs: 0\n",
      "Rows after dropping NaNs from targets: 300909\n",
      "✅ Saved parquet/labeled_data_L12_PT2SL1VB12NQ.parquet with 300909 rows\n"
     ]
    }
   ],
   "source": [
    "labeled = label_and_save(\n",
    "    df_input_features=df_merged,\n",
    "    lookahead_period=12,\n",
    "    vol_col_name='ATR_14_5min',\n",
    "    pt_multiplier=2.0,\n",
    "    sl_multiplier=1.0,\n",
    "    min_return_percentage=0.0005,\n",
    "    output_file_suffix=f'L12_PT2SL1VB12{market}',\n",
    "    feature_columns_for_dropna=[]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T23:55:28.724938Z",
     "start_time": "2025-06-03T23:55:28.718184Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_indicators = [\n",
    "    # ─── Volume & Volatility ────────────────────────────────────────────────\n",
    "    \"ATR_14_5min\",\n",
    "    \"ATR_14_15min\",\n",
    "    \"Volume_SMA_20_5min\",\n",
    "    \"Volume_SMA_20_Lag_1_5min\",\n",
    "\n",
    "    # ─── Raw Regime Flags (needed because your labels switch SL/TP by ADX/CHOP) ──\n",
    "    \"ADX_14_5min\",\n",
    "    \"CHOP_14_1_100_5min\",\n",
    "    # (optional: if you run add_market_regime_features, you could also include “Is_Trending”/“Is_Choppy” here)\n",
    "\n",
    "    # ─── Trend / Momentum ─────────────────────────────────────────────────────\n",
    "    \"RSI_14_5min\",\n",
    "    \"RSI_14_1h\",\n",
    "    \"RSI_14_Is_Overbought_70_5min\",\n",
    "    \"RSI_14_Is_Oversold_30_5min\",\n",
    "    \"MACDh_12_26_9_1h\",                # MACD histogram on 1h\n",
    "    \"EMA_20_5min\",\n",
    "    \"MACD_12_26_9_Cross_Signal_5min\",\n",
    "    \"STOCHk_14_3_3_5min\",\n",
    "\n",
    "    # ─── Composite Trend Signals ─────────────────────────────────────────────\n",
    "    \"Trend_Score_5min\",                # Composite of RSI, EMA alignment, VWAP, etc.\n",
    "    \"Trend_Alignment_5min\",            # 1 iff (EMA alignment & RSI>50 & MACD>0 & close>VWAP)\n",
    "    \"Price_vs_VWAP_5min\",              # (close / VWAP) – 1, in percent\n",
    "\n",
    "    # ─── Bollinger Mean Reversion ────────────────────────────────────────────\n",
    "    \"close_vs_BB_Upper_5min\",               # 1 if close > upper BB20‐2σ, else 0\n",
    "    \"close_vs_BB_Lower_5min\",               # 1 if close < lower BB20‐2σ, else 0\n",
    "\n",
    "    # ─── CCI (Commodity Channel Index) ───────────────────────────────────────\n",
    "    \"CCI_20_5min\",                     # pandas_ta’s CCI_20 on 5m\n",
    "\n",
    "    # ─── Statistical Features ─────────────────────────────────────────────────\n",
    "    \"Rolling_Std_Dev_14_5min\",         # 14-bar std of 5m simple return\n",
    "    \"Rolling_Skew_30_5min\",            # 30-bar skew of 5m simple return\n",
    "    \"Rolling_Kurtosis_30_5min\",        # 30-bar kurtosis of 5m simple return\n",
    "\n",
    "    # ─── Lagged Versions of Key Signals ──────────────────────────────────────\n",
    "    \"RSI_14_Lag_1_5min\",\n",
    "    \"Candle_Body_Lag_1_5min\",\n",
    "\n",
    "    # ─── Session + Time Context ──────────────────────────────────────────────\n",
    "    \"Is_NY_Session\",\n",
    "    \"Is_Asian_Session\",\n",
    "    \"Hour_of_Day\",\n",
    "    \"Time_Cos\",\n",
    "\n",
    "    # ─── Price Action ─────────────────────────────────────────────────────────\n",
    "    \"WILLR_14_5min\",\n",
    "    # (drop “Simple_Return_1_5min” here, since its corr ≈0.0009; model will see it via rolling stats)\n",
    "    \"Body_vs_Range_5min\",\n",
    "    \"Upper_Wick_5min\",\n",
    "\n",
    "    # ─── Macro / Higher‐Timeframe Anchors ────────────────────────────────────\n",
    "    \"VWAP_D_1h\",                        # Daily VWAP computed on 1h bars\n",
    "    \"Is_Bearish_Wick_5min\",\n",
    "    \"Candle_Body_5min\",\n",
    "    \"Upper_Wick_Length_5min\",\n",
    "    \"Is_Trending_5min\",\n",
    "    \"Is_Choppy_5min\",\n",
    "    \"Is_High_Vol_5min\",\n",
    "    \"Is_Low_Vol_5min\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1DWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, input_shape, filters=64, kernel_size=3, dropout=0.2, learning_rate=0.001):\n",
    "        self.input_shape = input_shape\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dropout = dropout\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = None\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential([\n",
    "            Conv1D(self.filters, kernel_size=self.kernel_size, activation='relu', input_shape=(self.input_shape, 1)),\n",
    "            Dropout(self.dropout),\n",
    "            Conv1D(self.filters * 2, kernel_size=self.kernel_size, activation='relu'),\n",
    "            Dropout(self.dropout),\n",
    "            GlobalAveragePooling1D(),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer=Adam(learning_rate=self.learning_rate), loss='mse')\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        X_reshaped = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "        self.model = self.build_model()\n",
    "        self.model.fit(\n",
    "            X_reshaped, y,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "            ],\n",
    "            verbose=0\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_reshaped = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "        return self.model.predict(X_reshaped).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T00:54:25.841256Z",
     "start_time": "2025-06-04T00:54:25.810221Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_lookahead_for_session_regression():\n",
    "    # === Load data ===\n",
    "    path = f\"parquet/labeled_data_L12_PT2SL1VB12{market}.parquet\"\n",
    "    labeled = pd.read_parquet(path)\n",
    "\n",
    "    # === Ensure datetime column exists and is parsed ===\n",
    "    if labeled.index.name == 'datetime' or pd.api.types.is_datetime64_any_dtype(labeled.index):\n",
    "        labeled = labeled.reset_index()\n",
    "    if 'datetime' not in labeled.columns:\n",
    "        raise KeyError(\"❌ 'datetime' column is missing.\")\n",
    "\n",
    "    labeled['datetime'] = pd.to_datetime(labeled['datetime'])\n",
    "    labeled = labeled.sort_values('datetime')\n",
    "\n",
    "    # === Train/test split ===\n",
    "    cutoff_date = pd.Timestamp(\"2025-05-01\", tz=\"America/New_York\")\n",
    "    train = labeled[labeled['datetime'] < cutoff_date]\n",
    "    test = labeled[labeled['datetime'] >= cutoff_date]\n",
    "\n",
    "    train = train.set_index('datetime')\n",
    "    test = test.set_index('datetime')\n",
    "\n",
    "    # === Feature selection ===\n",
    "    X_train = train[selected_indicators]\n",
    "    X_test = test[selected_indicators]\n",
    "\n",
    "    # === Find regression target column ===\n",
    "    reg_cols = [col for col in labeled.columns if col.startswith(\"reg_value\")]\n",
    "    if not reg_cols:\n",
    "        raise ValueError(\"❌ No regression target column found starting with 'reg_value'.\")\n",
    "    reg_col = reg_cols[0]\n",
    "    print(f\"📌 Using regression target column: {reg_col}\")\n",
    "\n",
    "    y_train_seq = train[reg_col]\n",
    "    y_test_seq = test[reg_col]\n",
    "\n",
    "    print(f\"Train range: {train.index.min()} to {train.index.max()} | Rows: {len(train)}\")\n",
    "    print(f\"Test range: {test.index.min()} to {test.index.max()} | Rows: {len(test)}\")\n",
    "\n",
    "    ###########################\n",
    "    ########## Models #########\n",
    "    ###########################    \n",
    "    def tune_catboost_regressor(X, y, df, study_name=\"catboost-default\", db_path=\"dbs/catboost.db\", n_trials=100, threshold_points=10):\n",
    "        def objective(trial):\n",
    "            # 1) Suggest a set of CatBoost hyperparameters:\n",
    "            params = {\n",
    "                \"iterations\"       : trial.suggest_int(\"iterations\", 100, 5000, step=100),\n",
    "                \"depth\"            : trial.suggest_int(\"depth\", 4, 10),\n",
    "                \"learning_rate\"    : trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "                \"l2_leaf_reg\"      : trial.suggest_float(\"l2_leaf_reg\", 1.0, 10.0),\n",
    "                \"random_strength\"  : trial.suggest_float(\"random_strength\", 0.5, 5.0),\n",
    "                \"min_data_in_leaf\" : trial.suggest_int(\"min_data_in_leaf\", 10, 100),\n",
    "                \"loss_function\"    : \"RMSE\",   # We will still optimize Sharpe, not RMSE directly.\n",
    "                \"verbose\"          : 0,\n",
    "                \"thread_count\"     : 3,\n",
    "                \"random_state\"     : 42\n",
    "            }\n",
    "\n",
    "            fold_scores = []\n",
    "            tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "            for train_idx, val_idx in tscv.split(X):\n",
    "                X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "                y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                prices_val   = df.iloc[val_idx][\"open\"].to_numpy()  # entry prices\n",
    "\n",
    "                # build sample weights that up‐weight negative examples if you like:\n",
    "                w_tr = np.ones(len(train_idx))\n",
    "                # (optional) w_tr[y_tr<0] *= (1 + 10*abs(y_tr[y_tr<0]))\n",
    "\n",
    "                # train\n",
    "                model = CatBoostRegressor(**params)\n",
    "                model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
    "\n",
    "                # predict\n",
    "                preds = model.predict(X_val)\n",
    "                actual = y_val.to_numpy()\n",
    "\n",
    "                # compute direction‐aware 10-point threshold in pct\n",
    "                thr_pct = threshold_points / prices_val\n",
    "\n",
    "                # classify\n",
    "                long_pred =  preds >=  thr_pct\n",
    "                long_true =  actual >=  thr_pct\n",
    "                short_pred = preds <= -thr_pct\n",
    "                short_true = actual <= -thr_pct\n",
    "\n",
    "                correct = np.sum(long_pred & long_true) + np.sum(short_pred & short_true)\n",
    "                wrong   = np.sum(long_pred & ~long_true) + np.sum(short_pred & ~short_true)\n",
    "\n",
    "                fold_scores.append(correct - wrong)\n",
    "\n",
    "            # average net‐correctness across folds\n",
    "            return float(np.mean(fold_scores))\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\",\n",
    "            study_name=study_name,\n",
    "            storage=f\"sqlite:///{db_path}\",\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=n_trials, n_jobs=4)\n",
    "\n",
    "        # pull out only the CatBoost init args\n",
    "        all_params = study.best_trial.params\n",
    "        valid_keys = {\"iterations\",\"depth\",\"learning_rate\",\"l2_leaf_reg\",\"random_strength\",\"min_data_in_leaf\",\"loss_function\"}\n",
    "        best_model_params = {k: all_params[k] for k in all_params if k in valid_keys}\n",
    "        return best_model_params\n",
    "    \n",
    "    def tune_xgbm_regressor(X, y, df,study_name=\"xgbm-default\", db_path=\"dbs/xgbm.db\", n_trials=100, threshold_points=10):\n",
    "        def objective(trial):\n",
    "            # 1) Suggest a set of CatBoost hyperparameters:\n",
    "            params = {\n",
    "                \"objective\":        \"reg:squarederror\",    # we’ll still optimize Sharpe, not RMSE directly\n",
    "                \"n_estimators\":     trial.suggest_int(\"n_estimators\",     100,  5000, step=50),\n",
    "                \"learning_rate\":    trial.suggest_float(\"learning_rate\",  0.01, 0.3,  log=True),\n",
    "                \"max_depth\":        trial.suggest_int(\"max_depth\",        3,    12),\n",
    "                \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1,    10),\n",
    "                \"subsample\":        trial.suggest_float(\"subsample\",       0.6,  1.0),\n",
    "                \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\",0.6,  1.0),\n",
    "                \"gamma\":            trial.suggest_float(\"gamma\",           0.0,  0.1),\n",
    "                \"reg_alpha\":        trial.suggest_float(\"reg_alpha\",       0.0,  1.0),\n",
    "                \"reg_lambda\":       trial.suggest_float(\"reg_lambda\",      0.0,  1.0),\n",
    "                \"random_state\":     42,\n",
    "                \"n_jobs\":           3,         # or -1 if you have ≥8 physical cores\n",
    "                \"verbosity\":        0          # silent\n",
    "            }\n",
    "\n",
    "            fold_scores = []\n",
    "            tscv = TimeSeriesSplit(n_splits=4)\n",
    "\n",
    "            for train_idx, val_idx in tscv.split(X):\n",
    "                X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "                y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                prices_val   = df.iloc[val_idx][\"open\"].to_numpy()  # entry prices\n",
    "\n",
    "                # build sample weights that up‐weight negative examples if you like:\n",
    "                w_tr = np.ones(len(train_idx))\n",
    "                # (optional) w_tr[y_tr<0] *= (1 + 10*abs(y_tr[y_tr<0]))\n",
    "\n",
    "                # train\n",
    "                model = xgb.XGBRegressor(**params)\n",
    "                model.fit(X_tr, y_tr, sample_weight=w_tr)\n",
    "\n",
    "                # predict\n",
    "                preds = model.predict(X_val)\n",
    "                actual = y_val.to_numpy()\n",
    "\n",
    "                # compute direction‐aware 10-point threshold in pct\n",
    "                thr_pct = threshold_points / prices_val\n",
    "\n",
    "                # classify\n",
    "                long_pred =  preds >=  thr_pct\n",
    "                long_true =  actual >=  thr_pct\n",
    "                short_pred = preds <= -thr_pct\n",
    "                short_true = actual <= -thr_pct\n",
    "\n",
    "                correct = np.sum(long_pred & long_true) + np.sum(short_pred & short_true)\n",
    "                wrong   = np.sum(long_pred & ~long_true) + np.sum(short_pred & ~short_true)\n",
    "\n",
    "                fold_scores.append(correct - wrong)\n",
    "\n",
    "            # average net‐correctness across folds\n",
    "            return float(np.mean(fold_scores))\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\",\n",
    "            study_name=study_name,\n",
    "            storage=f\"sqlite:///{db_path}\",\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=n_trials, n_jobs=3)\n",
    "\n",
    "        # pull out only the CatBoost init args\n",
    "        all_params = study.best_trial.params\n",
    "        valid_keys = {\"iterations\",\"depth\",\"learning_rate\",\"l2_leaf_reg\",\"random_strength\",\"min_data_in_leaf\",\"loss_function\"}\n",
    "        best_model_params = {k: all_params[k] for k in all_params if k in valid_keys}\n",
    "        return best_model_params\n",
    "\n",
    "    ################################################\n",
    "    ####### Tune models\n",
    "    xgbm_params          = tune_xgbm_regressor(X_train, y_train_seq, train, study_name=f\"xgbm-{market}\")\n",
    "    catboost_params      = tune_catboost_regressor(X_train, y_train_seq, train, study_name=f\"catboost-{market}\")\n",
    "\n",
    "    ################################################\n",
    "    ####### Train models\n",
    "    catboost    = CatBoostRegressor(**catboost_params, random_state=42, verbose=0)\n",
    "    xgbm        = xgb.XGBRegressor(**xgbm_params, random_state=42)\n",
    "\n",
    "    ################################################\n",
    "    ####### Base Stacks\n",
    "    catboost_models = [catboost]\n",
    "    catboost_oof = generate_oof_predictions(catboost_models, X_train, y_train_seq, splits=4)\n",
    "    # The returned DataFrame usually has column name [\"model_0\"] by default.\n",
    "    # Rename it to \"catboost_oof\" so that the same name can be used at test time:\n",
    "    catboost_oof = catboost_oof.rename(columns={\"model_0\": \"catboost_oof\"})\n",
    "\n",
    "    scaler_cb = StandardScaler()\n",
    "    catboost_oof_scaled = scaler_cb.fit_transform(catboost_oof)  \n",
    "    # Now the scaler knows there’s exactly one feature: \"catboost_oof\".\n",
    "\n",
    "    # (b) LightGBM OOF\n",
    "    xgbm_models = [xgbm]\n",
    "    xgbm_oof = generate_oof_predictions(xgbm_models, X_train, y_train_seq, splits=4)\n",
    "    xgbm_oof = xgbm_oof.rename(columns={\"model_0\": \"xgbm_oof\"})\n",
    "\n",
    "    scaler_xgb = StandardScaler()\n",
    "    xgbm_oof_scaled = scaler_xgb.fit_transform(xgbm_oof)\n",
    "    # The scaler now knows there’s exactly one feature: \"lgbm_oof\".\n",
    "\n",
    "\n",
    "    # 5) === Build your meta‐training matrix ===\n",
    "    X_meta_train = pd.DataFrame({\n",
    "        \"catboost_oof\": catboost_oof_scaled.ravel(),   # flatten into 1D\n",
    "        \"xgbm_oof\":     xgbm_oof_scaled.ravel()\n",
    "    }, index=X_train.index)\n",
    "\n",
    "    alphas     = np.logspace(-4, 2, 40)\n",
    "    meta_model = RidgeCV(alphas=alphas)\n",
    "    meta_model.fit(X_meta_train, y_train_seq)\n",
    "\n",
    "\n",
    "    # 6) === Retrain base models on the full training set ===\n",
    "    for model in catboost_models + xgbm_models:\n",
    "        model.fit(X_train, y_train_seq)\n",
    "\n",
    "\n",
    "    # 7) === At test time, get each base model’s raw prediction on X_test ===\n",
    "    #      Make sure to use the exact same column names as above!\n",
    "\n",
    "    # (a) CatBoost raw test‐pred:\n",
    "    cat_preds = pd.DataFrame({\n",
    "        \"catboost_oof\": catboost_models[0].predict(X_test)\n",
    "    }, index=X_test.index)\n",
    "\n",
    "    # (b) LightGBM raw test‐pred:\n",
    "    lgb_preds = pd.DataFrame({\n",
    "        \"xgbm_oof\": xgbm_models[0].predict(X_test)\n",
    "    }, index=X_test.index)\n",
    "\n",
    "\n",
    "    # 8) === Scale those test‐time columns with the *same* scalers ===\n",
    "    cat_preds_scaled = scaler_cb.transform(cat_preds)    # cat_preds has column \"catboost_oof\"\n",
    "    xgb_preds_scaled = scaler_xgb.transform(lgb_preds)  # lgb_preds has column \"lgbm_oof\"\n",
    "\n",
    "\n",
    "    # 9) === Build the two‐column “meta” feature matrix for test ===\n",
    "    X_meta_test = pd.DataFrame({\n",
    "        \"catboost_oof\": cat_preds_scaled.ravel(),\n",
    "        \"xgbm_oof\":     xgb_preds_scaled.ravel()\n",
    "    }, index=X_test.index)\n",
    "\n",
    "\n",
    "    # 10) === Final stacked prediction ===\n",
    "    preds_stack = meta_model.predict(X_meta_test)\n",
    "\n",
    "    corr = np.corrcoef(y_test_seq, preds_stack)[0, 1]\n",
    "    print(f\"Correlation with target: {corr:.4f}\")\n",
    "\n",
    "    ################################################\n",
    "    ####### Evaluate Model\n",
    "    def evaluate_model(name, model, Xtr, Xte, ytr, yte, transformed=False):\n",
    "        train_preds = model.predict(Xtr)\n",
    "        test_preds = model.predict(Xte)\n",
    "\n",
    "        if transformed:\n",
    "        # Inverse-transform predictions\n",
    "            train_preds = np.sign(train_preds) * (np.expm1(np.abs(train_preds)))\n",
    "            test_preds = np.sign(test_preds) * (np.expm1(np.abs(test_preds)))\n",
    "            ytr = np.sign(ytr) * (np.expm1(np.abs(ytr)))\n",
    "\n",
    "        train_mse = mean_squared_error(ytr, train_preds)\n",
    "        test_mse = mean_squared_error(yte, test_preds)\n",
    "        overfit_ratio = test_mse / train_mse if train_mse != 0 else float('inf')\n",
    "\n",
    "        print(f\"\\n📊 {name} Performance:\")\n",
    "        print(f\"Train MSE: {train_mse:.8f}\")\n",
    "        print(f\"Test MSE: {test_mse:.8f}\")\n",
    "        print(f\"Overfit ratio (Test / Train): {overfit_ratio:.2f}\")\n",
    "        if overfit_ratio > 1.5:\n",
    "            print(\"⚠️ Potential overfitting detected.\")\n",
    "        elif overfit_ratio < 0.7:\n",
    "            print(\"⚠️ Possibly underfitting.\")\n",
    "        else:\n",
    "            print(\"✅ Generalization looks reasonable.\")\n",
    "        return test_preds\n",
    "\n",
    "    ####### Tree Based #######\n",
    "    print(\"\\nEvaluation CatBoost\")\n",
    "    preds_catboost  = evaluate_model(\"CatBoostRegressorUp\", catboost, X_train, X_test, y_train_seq, y_test_seq, transformed=False)\n",
    "\n",
    "    print(\"\\nEvaluation LGBM\")\n",
    "    preds_xgbm  = evaluate_model(\"XGBM\", xgbm, X_train, X_test, y_train_seq, y_test_seq, transformed=False)\n",
    "\n",
    "    ################################################\n",
    "    ####### Target Distribution\n",
    "    print(\"\\n🔍 Target distribution Seq:\")\n",
    "    print(y_train_seq.describe())\n",
    "\n",
    "    ################################################\n",
    "    ####### Choose final model\n",
    "    for pred in [preds_stack, preds_xgbm, preds_catboost]:\n",
    "        print(\"\\n🔍 Checking prediction variance:\")\n",
    "        print(f\"Min: {pred.min():.8f}\")\n",
    "        print(f\"Max: {pred.max():.8f}\")\n",
    "        print(f\"Mean: {pred.mean():.8f}\")\n",
    "        print(f\"Std Dev: {pred.std():.8f}\")\n",
    "        print(f\"First 5 Predictions: {pred[:5]}\")\n",
    "\n",
    "        mae = mean_absolute_error(y_test_seq, pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_seq, pred))\n",
    "        r2 = r2_score(y_test_seq, pred)\n",
    "\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "    # === Ensure datetime is preserved ===\n",
    "    X_test = X_test.copy()\n",
    "    X_test[\"datetime\"] = X_test.index\n",
    "\n",
    "    metadata = {\n",
    "        \"catboost_params\": catboost_params,\n",
    "        \"xgbm_params\": xgbm_params,\n",
    "    }\n",
    "    with open(f\"regression_metadata_{market}.json\", \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "\n",
    "    joblib.dump(list(X_train.columns), f\"pkl/model_features_{market}-12combo.pkl\")\n",
    "    joblib.dump(meta_model, f\"pkl/stack_model_regression_{market}-12combo.pkl\")\n",
    "\n",
    "    return {\n",
    "        'preds_stack': preds_stack,\n",
    "        'X_test': X_test,\n",
    "        'true_values': y_test_seq\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T01:17:27.107482Z",
     "start_time": "2025-06-04T00:54:31.122684Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-06 19:19:23,756] Using an existing study with name 'xgbm-NQ' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Using regression target column: reg_value\n",
      "Train range: 2021-03-07 19:10:00-05:00 to 2025-04-30 23:55:00-04:00 | Rows: 294672\n",
      "Test range: 2025-05-01 00:00:00-04:00 to 2025-06-02 16:00:00-04:00 | Rows: 6237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-06 19:19:28,695] Trial 132 finished with value: 9579.25 and parameters: {'n_estimators': 350, 'learning_rate': 0.027429443357893303, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.865355102140468, 'colsample_bytree': 0.798836166605503, 'gamma': 0.0002768675393213465, 'reg_alpha': 0.5914096811657106, 'reg_lambda': 0.8973014742015782}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:28,710] Trial 133 finished with value: 9467.25 and parameters: {'n_estimators': 300, 'learning_rate': 0.02664333676045995, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8874003763279371, 'colsample_bytree': 0.7990084164301638, 'gamma': 0.0001360568086117749, 'reg_alpha': 0.5536953961208877, 'reg_lambda': 0.9129461766372888}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:29,799] Trial 134 finished with value: 9341.75 and parameters: {'n_estimators': 300, 'learning_rate': 0.027886493386713878, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8804757060412443, 'colsample_bytree': 0.7986799773530224, 'gamma': 4.4335903064115175e-05, 'reg_alpha': 0.586963897249956, 'reg_lambda': 0.9141955535528643}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:33,670] Trial 137 finished with value: 9191.0 and parameters: {'n_estimators': 300, 'learning_rate': 0.03250404347944433, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8718614594092067, 'colsample_bytree': 0.7851197062748014, 'gamma': 0.0014059081544387179, 'reg_alpha': 0.5514853879942712, 'reg_lambda': 0.8774053077828965}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:34,083] Trial 135 finished with value: 9490.0 and parameters: {'n_estimators': 350, 'learning_rate': 0.026860366232307867, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8726786087794642, 'colsample_bytree': 0.7852864263266628, 'gamma': 0.00013550050763148458, 'reg_alpha': 0.5904295021864941, 'reg_lambda': 0.8700975490091445}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:35,136] Trial 136 finished with value: 9303.25 and parameters: {'n_estimators': 350, 'learning_rate': 0.03243039819701839, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8766191306465363, 'colsample_bytree': 0.7849340998521527, 'gamma': 3.1941361209023044e-05, 'reg_alpha': 0.5886214510100232, 'reg_lambda': 0.881668451169478}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:37,892] Trial 138 finished with value: 5636.75 and parameters: {'n_estimators': 350, 'learning_rate': 0.0249028650605242, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8341793665351538, 'colsample_bytree': 0.8071772624903842, 'gamma': 0.004946381885582684, 'reg_alpha': 0.589151708065341, 'reg_lambda': 0.8696260413616649}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:38,551] Trial 139 finished with value: 6274.25 and parameters: {'n_estimators': 400, 'learning_rate': 0.02490596141420286, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8928274688905679, 'colsample_bytree': 0.7728948662753827, 'gamma': 0.004484682052212094, 'reg_alpha': 0.5036582982212195, 'reg_lambda': 0.864109788683471}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:39,624] Trial 140 finished with value: 6013.25 and parameters: {'n_estimators': 400, 'learning_rate': 0.025343244517759256, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.9104749603644662, 'colsample_bytree': 0.7761943233211414, 'gamma': 0.004834526993156852, 'reg_alpha': 0.5018171844218352, 'reg_lambda': 0.8642831240244542}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:41,489] Trial 142 finished with value: 8107.75 and parameters: {'n_estimators': 200, 'learning_rate': 0.037050117202053846, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.912031810967227, 'colsample_bytree': 0.7627185874412632, 'gamma': 0.002179242451059587, 'reg_alpha': 0.5614444483920478, 'reg_lambda': 0.9002877196912545}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:42,450] Trial 141 finished with value: 6894.0 and parameters: {'n_estimators': 400, 'learning_rate': 0.021699960580823074, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8905632084969987, 'colsample_bytree': 0.7617807543954489, 'gamma': 0.003895340562246454, 'reg_alpha': 0.499164730764517, 'reg_lambda': 0.898768724129926}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:43,039] Trial 143 finished with value: 8218.25 and parameters: {'n_estimators': 250, 'learning_rate': 0.028791925953823645, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.8689676403083709, 'colsample_bytree': 0.7914224170090759, 'gamma': 0.001994616230142442, 'reg_alpha': 0.5552967587808417, 'reg_lambda': 0.9296532620393567}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:44,967] Trial 144 finished with value: 8670.5 and parameters: {'n_estimators': 250, 'learning_rate': 0.029352045987359274, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.9020861100293406, 'colsample_bytree': 0.7917296640281339, 'gamma': 0.0017272227971894501, 'reg_alpha': 0.630205657910957, 'reg_lambda': 0.9323436370700177}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:46,038] Trial 145 finished with value: 8680.25 and parameters: {'n_estimators': 250, 'learning_rate': 0.02705487284703467, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.8633603884774329, 'colsample_bytree': 0.7919496666871603, 'gamma': 0.001663265025020607, 'reg_alpha': 0.6289808398588288, 'reg_lambda': 0.9336376495111065}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:46,385] Trial 146 finished with value: 4862.0 and parameters: {'n_estimators': 250, 'learning_rate': 0.02662692234714423, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8625732220111801, 'colsample_bytree': 0.7990718643057356, 'gamma': 0.006709757100276074, 'reg_alpha': 0.3474353549280712, 'reg_lambda': 0.9479797326769667}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:47,115] Trial 147 finished with value: 4871.5 and parameters: {'n_estimators': 100, 'learning_rate': 0.02308881609223816, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8609242349400611, 'colsample_bytree': 0.8396171850746116, 'gamma': 0.006748041396534403, 'reg_alpha': 0.5312674878186642, 'reg_lambda': 0.9520931693120311}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:51,997] Trial 149 finished with value: 9564.0 and parameters: {'n_estimators': 450, 'learning_rate': 0.022879184460863403, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8461884801557257, 'colsample_bytree': 0.7520353162960224, 'gamma': 0.0003145891227323477, 'reg_alpha': 0.5303076889663138, 'reg_lambda': 0.9656049984395492}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:52,681] Trial 148 finished with value: 9455.0 and parameters: {'n_estimators': 450, 'learning_rate': 0.023346442696171348, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8510003986628444, 'colsample_bytree': 0.8003759328251733, 'gamma': 9.873788617753462e-05, 'reg_alpha': 0.5318966241595627, 'reg_lambda': 0.9592182346153916}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:53,661] Trial 150 finished with value: 9293.5 and parameters: {'n_estimators': 450, 'learning_rate': 0.04061343515222569, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8853409974793921, 'colsample_bytree': 0.802730198846202, 'gamma': 3.9283243969353275e-05, 'reg_alpha': 0.4701298983802075, 'reg_lambda': 0.968561535494701}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:54,849] Trial 151 finished with value: 9504.5 and parameters: {'n_estimators': 100, 'learning_rate': 0.04060743760306865, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8499376656888901, 'colsample_bytree': 0.7330108900727765, 'gamma': 0.00011863208189790493, 'reg_alpha': 0.4696956704233814, 'reg_lambda': 0.8284301855610071}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:56,054] Trial 153 finished with value: 7199.75 and parameters: {'n_estimators': 100, 'learning_rate': 0.021941224657233336, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8442205753371799, 'colsample_bytree': 0.7541116930453772, 'gamma': 0.003137751974276318, 'reg_alpha': 0.5239437440087802, 'reg_lambda': 0.9180367135966883}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:56,996] Trial 154 finished with value: 7105.25 and parameters: {'n_estimators': 100, 'learning_rate': 0.042719967292163444, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8496067598248799, 'colsample_bytree': 0.7162534963212019, 'gamma': 0.003470879926905911, 'reg_alpha': 0.6033939167452037, 'reg_lambda': 0.9082403833847429}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:19:57,223] Trial 152 finished with value: 4724.75 and parameters: {'n_estimators': 400, 'learning_rate': 0.02045140861135463, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.900713392855317, 'colsample_bytree': 0.7327012545340146, 'gamma': 0.011920867309017815, 'reg_alpha': 0.46082253400649653, 'reg_lambda': 0.8287928675849449}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:00,162] Trial 155 finished with value: 6908.25 and parameters: {'n_estimators': 350, 'learning_rate': 0.03733736242986938, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.8531103122828821, 'colsample_bytree': 0.7298748332662282, 'gamma': 0.003589071740883468, 'reg_alpha': 0.6019791146749015, 'reg_lambda': 0.8256948397679901}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:01,048] Trial 156 finished with value: 5401.5 and parameters: {'n_estimators': 350, 'learning_rate': 0.03807818898391497, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.899129991065096, 'colsample_bytree': 0.732486953870611, 'gamma': 0.005740751487385925, 'reg_alpha': 0.42030404250336384, 'reg_lambda': 0.8298132888955218}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:01,441] Trial 157 finished with value: 4874.75 and parameters: {'n_estimators': 350, 'learning_rate': 0.03411980638591834, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.6901532477334004, 'colsample_bytree': 0.7803747408383895, 'gamma': 0.005945967682460434, 'reg_alpha': 0.5751880334866927, 'reg_lambda': 0.8875936756395799}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:03,823] Trial 159 finished with value: 4877.0 and parameters: {'n_estimators': 200, 'learning_rate': 0.044606975024203833, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.8765679716394007, 'colsample_bytree': 0.7471015000809499, 'gamma': 0.007950705165851588, 'reg_alpha': 0.5717027339066274, 'reg_lambda': 0.8954394568783894}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:04,040] Trial 158 finished with value: 4773.0 and parameters: {'n_estimators': 300, 'learning_rate': 0.034893801326992574, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.6881734579034315, 'colsample_bytree': 0.9988634479029446, 'gamma': 0.007513574104461045, 'reg_alpha': 0.4130530447947071, 'reg_lambda': 0.8824681039874664}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:06,196] Trial 160 finished with value: 9238.75 and parameters: {'n_estimators': 250, 'learning_rate': 0.044169569459568, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.8240285813548861, 'colsample_bytree': 0.7154398132454863, 'gamma': 5.283924380472088e-05, 'reg_alpha': 0.549234021363012, 'reg_lambda': 0.9133298294404948}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:09,453] Trial 162 finished with value: 8646.5 and parameters: {'n_estimators': 500, 'learning_rate': 0.03201584767962329, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.8217454338760292, 'colsample_bytree': 0.7492503547345737, 'gamma': 0.0017517562010243228, 'reg_alpha': 0.5495513800121056, 'reg_lambda': 0.8486891839584274}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:10,165] Trial 161 finished with value: 9317.75 and parameters: {'n_estimators': 450, 'learning_rate': 0.03488718114551501, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.7062208925654839, 'colsample_bytree': 0.7148858902219853, 'gamma': 8.636766055065834e-05, 'reg_alpha': 0.6616124550909228, 'reg_lambda': 0.8477365600587481}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:12,489] Trial 165 finished with value: 7716.5 and parameters: {'n_estimators': 100, 'learning_rate': 0.02294133010730063, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8539688797800156, 'colsample_bytree': 0.8070061192553859, 'gamma': 0.0023628366606562655, 'reg_alpha': 0.5142440001816032, 'reg_lambda': 0.9635790648808494}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:16,094] Trial 164 finished with value: 9396.0 and parameters: {'n_estimators': 450, 'learning_rate': 0.026499581134960627, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8381886857752459, 'colsample_bytree': 0.6839848093000038, 'gamma': 7.550721502989112e-05, 'reg_alpha': 0.5178795236110143, 'reg_lambda': 0.9672840087895357}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:17,888] Trial 163 finished with value: 9248.25 and parameters: {'n_estimators': 500, 'learning_rate': 0.023823867173500237, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.855734086943391, 'colsample_bytree': 0.7518161099540226, 'gamma': 9.713478152816772e-06, 'reg_alpha': 0.5195444158065716, 'reg_lambda': 0.9433734822470023}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:21,378] Trial 167 finished with value: 6273.25 and parameters: {'n_estimators': 500, 'learning_rate': 0.02064135032010581, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.8705787233213345, 'colsample_bytree': 0.771855631221717, 'gamma': 0.004447087652318497, 'reg_alpha': 0.48013852414946223, 'reg_lambda': 0.9409267448493198}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:25,382] Trial 169 finished with value: 6947.5 and parameters: {'n_estimators': 300, 'learning_rate': 0.029177850461311963, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6441092889383052, 'colsample_bytree': 0.8232982368780606, 'gamma': 0.002740742213310643, 'reg_alpha': 0.5405357977786772, 'reg_lambda': 0.9740250453623973}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:27,146] Trial 166 finished with value: 6872.5 and parameters: {'n_estimators': 1750, 'learning_rate': 0.026178974589759544, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.868571635780364, 'colsample_bytree': 0.7703061633220839, 'gamma': 0.003911572354855666, 'reg_alpha': 0.48330017655103774, 'reg_lambda': 0.93560189554004}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:28,431] Trial 170 finished with value: 5587.0 and parameters: {'n_estimators': 200, 'learning_rate': 0.04101871821665533, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6605681420057468, 'colsample_bytree': 0.8103748410501601, 'gamma': 0.0041231552878946785, 'reg_alpha': 0.43610664085718237, 'reg_lambda': 0.9198542866670749}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:32,298] Trial 168 finished with value: 6828.25 and parameters: {'n_estimators': 1650, 'learning_rate': 0.02974012336194903, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.8671244179807382, 'colsample_bytree': 0.8233498247473018, 'gamma': 0.00407066229097534, 'reg_alpha': 0.36175042810589736, 'reg_lambda': 0.9286583652293504}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:37,009] Trial 173 finished with value: 8183.25 and parameters: {'n_estimators': 400, 'learning_rate': 0.023723240369137612, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.8325307359657728, 'colsample_bytree': 0.7843188932104966, 'gamma': 0.0020043711508900943, 'reg_alpha': 0.3884226805867007, 'reg_lambda': 0.9756467788385225}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:39,918] Trial 174 finished with value: 8715.75 and parameters: {'n_estimators': 200, 'learning_rate': 0.057976059448553094, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8387263007699678, 'colsample_bytree': 0.9771288656710582, 'gamma': 0.0016727992386414395, 'reg_alpha': 0.5676999801828876, 'reg_lambda': 0.9033345182235617}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:44,892] Trial 175 finished with value: 5234.0 and parameters: {'n_estimators': 450, 'learning_rate': 0.03173587295808161, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.8489840163756456, 'colsample_bytree': 0.8002571722815351, 'gamma': 0.00577868435786259, 'reg_alpha': 0.4542292937132395, 'reg_lambda': 0.8694155655215747}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:49,119] Trial 176 finished with value: 8385.75 and parameters: {'n_estimators': 300, 'learning_rate': 0.027828385636448613, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.7158935114837162, 'colsample_bytree': 0.9891699045623997, 'gamma': 0.0016389978455540325, 'reg_alpha': 0.4000354434209481, 'reg_lambda': 0.9556363491833882}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:54,667] Trial 177 finished with value: 4831.0 and parameters: {'n_estimators': 500, 'learning_rate': 0.0246702942330084, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.8810679144515856, 'colsample_bytree': 0.811948950902811, 'gamma': 0.00883288253061968, 'reg_alpha': 0.5855144584769639, 'reg_lambda': 0.9063713815012313}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:20:58,638] Trial 178 finished with value: 9522.0 and parameters: {'n_estimators': 200, 'learning_rate': 0.038286948372993894, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6702883135922317, 'colsample_bytree': 0.9177598870415102, 'gamma': 0.0001606885620225132, 'reg_alpha': 0.5337863852632139, 'reg_lambda': 0.9786737437646855}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:02,235] Trial 179 finished with value: 9469.0 and parameters: {'n_estimators': 100, 'learning_rate': 0.039895627500496085, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6761721716446716, 'colsample_bytree': 0.9241203748601575, 'gamma': 3.6400285125503276e-05, 'reg_alpha': 0.5458410250530321, 'reg_lambda': 0.9811689351891318}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:04,501] Trial 180 finished with value: 6913.25 and parameters: {'n_estimators': 100, 'learning_rate': 0.038751293263700165, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6725321979485268, 'colsample_bytree': 0.9185732899770541, 'gamma': 0.002700830478078947, 'reg_alpha': 0.6157449724794436, 'reg_lambda': 0.9809004369351272}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:05,617] Trial 171 finished with value: 8616.75 and parameters: {'n_estimators': 4850, 'learning_rate': 0.0406992440450646, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.9972517347402278, 'colsample_bytree': 0.9762170714647902, 'gamma': 0.0019354262681909428, 'reg_alpha': 0.5726379435589541, 'reg_lambda': 0.9207584036114344}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:07,618] Trial 181 finished with value: 4857.5 and parameters: {'n_estimators': 200, 'learning_rate': 0.04866296314061933, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.6635885475612296, 'colsample_bytree': 0.9294769850670936, 'gamma': 0.006185501612371054, 'reg_alpha': 0.5524801421878379, 'reg_lambda': 0.8755427072892737}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:07,706] Trial 182 finished with value: 4861.75 and parameters: {'n_estimators': 100, 'learning_rate': 0.048278991055025415, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.6646167347050658, 'colsample_bytree': 0.9379893503158766, 'gamma': 0.005673281844123869, 'reg_alpha': 0.5545940606139803, 'reg_lambda': 0.8724187189787589}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:08,091] Trial 172 finished with value: 7987.0 and parameters: {'n_estimators': 4550, 'learning_rate': 0.03070451887399176, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.623196983102034, 'colsample_bytree': 0.8474006564041039, 'gamma': 0.0017655617283014063, 'reg_alpha': 0.45162310431383534, 'reg_lambda': 0.9015098818090282}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:10,474] Trial 183 finished with value: 9515.0 and parameters: {'n_estimators': 150, 'learning_rate': 0.03609322047528053, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6780428357419112, 'colsample_bytree': 0.91119488509599, 'gamma': 0.0005957758287913982, 'reg_alpha': 0.5326684357767717, 'reg_lambda': 0.9550164743533098}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:12,768] Trial 185 finished with value: 9457.25 and parameters: {'n_estimators': 300, 'learning_rate': 0.03753551742192233, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6807420184200688, 'colsample_bytree': 0.901293701685299, 'gamma': 0.0001026372431363401, 'reg_alpha': 0.5348593412901317, 'reg_lambda': 0.9572852625443761}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:13,942] Trial 186 finished with value: 9557.0 and parameters: {'n_estimators': 200, 'learning_rate': 0.03554477509598471, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6788176323586298, 'colsample_bytree': 0.9113560877184337, 'gamma': 0.00029657695556374163, 'reg_alpha': 0.490775349118158, 'reg_lambda': 0.9500333369626341}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:14,280] Trial 184 finished with value: 9260.75 and parameters: {'n_estimators': 300, 'learning_rate': 0.03803545849980668, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.6724146132348142, 'colsample_bytree': 0.9154400120082083, 'gamma': 1.812139129445399e-05, 'reg_alpha': 0.49630132152333495, 'reg_lambda': 0.9651343431773112}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:15,356] Trial 187 finished with value: 6440.25 and parameters: {'n_estimators': 150, 'learning_rate': 0.035386538007676806, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6947698695098323, 'colsample_bytree': 0.9133796401378752, 'gamma': 0.0033532813492855454, 'reg_alpha': 0.4947065688505627, 'reg_lambda': 0.9814744670594892}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:17,051] Trial 188 finished with value: 6613.25 and parameters: {'n_estimators': 200, 'learning_rate': 0.03407779229945708, 'max_depth': 12, 'min_child_weight': 6, 'subsample': 0.6698548459391497, 'colsample_bytree': 0.9162306534613407, 'gamma': 0.0031913249789854528, 'reg_alpha': 0.487420884393028, 'reg_lambda': 0.9721660238479731}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:17,313] Trial 189 finished with value: 6297.75 and parameters: {'n_estimators': 200, 'learning_rate': 0.03393234115787429, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6577028988972397, 'colsample_bytree': 0.9255818895684805, 'gamma': 0.0032835131765386228, 'reg_alpha': 0.5081720815942717, 'reg_lambda': 0.005272322683524844}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:18,504] Trial 190 finished with value: 5760.75 and parameters: {'n_estimators': 200, 'learning_rate': 0.03321975211833173, 'max_depth': 12, 'min_child_weight': 6, 'subsample': 0.6790901744452592, 'colsample_bytree': 0.926956731525924, 'gamma': 0.0037831514797187758, 'reg_alpha': 0.5187529725840359, 'reg_lambda': 0.9399412381950027}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:19,217] Trial 191 finished with value: 5088.5 and parameters: {'n_estimators': 100, 'learning_rate': 0.042777664637703314, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.657466588659126, 'colsample_bytree': 0.9243059158213591, 'gamma': 0.00452066507175007, 'reg_alpha': 0.5116927187651277, 'reg_lambda': 0.9420737930086158}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:19,428] Trial 192 finished with value: 4859.0 and parameters: {'n_estimators': 100, 'learning_rate': 0.04214498874297923, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6762131767201703, 'colsample_bytree': 0.8972053674219885, 'gamma': 0.004901657078287643, 'reg_alpha': 0.526614253805031, 'reg_lambda': 0.9456353824808549}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:20,780] Trial 193 finished with value: 8114.25 and parameters: {'n_estimators': 100, 'learning_rate': 0.04296016666641335, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6848049209140301, 'colsample_bytree': 0.898267593241118, 'gamma': 0.0016516972525182662, 'reg_alpha': 0.586884584274918, 'reg_lambda': 0.9247381469525887}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:23,668] Trial 195 finished with value: 8129.25 and parameters: {'n_estimators': 350, 'learning_rate': 0.03975583432761473, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.683131524259452, 'colsample_bytree': 0.9090167738489923, 'gamma': 0.0016174027581232608, 'reg_alpha': 0.5893696134691195, 'reg_lambda': 0.8938943447373736}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:23,996] Trial 194 finished with value: 8451.75 and parameters: {'n_estimators': 400, 'learning_rate': 0.03867726643078262, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6911405014991158, 'colsample_bytree': 0.9469083754023249, 'gamma': 0.0015204203548108944, 'reg_alpha': 0.5468910444893545, 'reg_lambda': 0.9258494210404108}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:26,124] Trial 196 finished with value: 9411.0 and parameters: {'n_estimators': 350, 'learning_rate': 0.03738506230960986, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6967339514633553, 'colsample_bytree': 0.9075972234236377, 'gamma': 7.838008177502777e-05, 'reg_alpha': 0.5456516327360541, 'reg_lambda': 0.896856058258273}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:27,995] Trial 197 finished with value: 8594.75 and parameters: {'n_estimators': 350, 'learning_rate': 0.03723824121401774, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.7000655373093951, 'colsample_bytree': 0.9402115234331431, 'gamma': 0.0014767196657921445, 'reg_alpha': 0.5463612039910195, 'reg_lambda': 0.9824002290356207}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:29,040] Trial 198 finished with value: 9547.75 and parameters: {'n_estimators': 300, 'learning_rate': 0.021062028095748395, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.7046160309096751, 'colsample_bytree': 0.762546369116595, 'gamma': 0.0001590469461134862, 'reg_alpha': 0.6425663812672857, 'reg_lambda': 0.9825145543670799}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:30,588] Trial 199 finished with value: 9371.75 and parameters: {'n_estimators': 250, 'learning_rate': 0.03579136672639809, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.6481639789229072, 'colsample_bytree': 0.9394264989401384, 'gamma': 0.00013919473376464145, 'reg_alpha': 0.6749596948319346, 'reg_lambda': 0.9805772570287156}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:32,883] Trial 200 finished with value: 9459.5 and parameters: {'n_estimators': 250, 'learning_rate': 0.02182075568708438, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7290732276314225, 'colsample_bytree': 0.8577317035899783, 'gamma': 0.00012714910524412105, 'reg_alpha': 0.6393809441179509, 'reg_lambda': 0.8527615375501479}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:33,773] Trial 201 finished with value: 9448.0 and parameters: {'n_estimators': 250, 'learning_rate': 0.021893123737512687, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.7066616566420955, 'colsample_bytree': 0.7402952586597525, 'gamma': 0.00016406804944792708, 'reg_alpha': 0.6367456494455651, 'reg_lambda': 0.9775633522518306}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:33,971] Trial 202 finished with value: 4872.75 and parameters: {'n_estimators': 250, 'learning_rate': 0.021696240720831417, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.7185045557611088, 'colsample_bytree': 0.7651785730967928, 'gamma': 0.005847506329895022, 'reg_alpha': 0.6919225803136366, 'reg_lambda': 0.9550981832016304}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:38,798] Trial 203 finished with value: 6933.25 and parameters: {'n_estimators': 550, 'learning_rate': 0.019978328550006686, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.704533746031166, 'colsample_bytree': 0.7596485065214091, 'gamma': 0.002978016270557857, 'reg_alpha': 0.6153128845950884, 'reg_lambda': 0.961097275607785}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:39,374] Trial 204 finished with value: 6986.75 and parameters: {'n_estimators': 500, 'learning_rate': 0.019445895897724084, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.7126840330457448, 'colsample_bytree': 0.767024924112828, 'gamma': 0.002923776216377835, 'reg_alpha': 0.5668156859426327, 'reg_lambda': 0.9535650873007415}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:39,626] Trial 205 finished with value: 6920.25 and parameters: {'n_estimators': 500, 'learning_rate': 0.02033221238016852, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.7112079431047991, 'colsample_bytree': 0.7598315542998851, 'gamma': 0.0030069688469150048, 'reg_alpha': 0.6096620102661195, 'reg_lambda': 0.9173339247772195}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:43,793] Trial 206 finished with value: 6952.25 and parameters: {'n_estimators': 450, 'learning_rate': 0.04547243041477072, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.6681623785448682, 'colsample_bytree': 0.9518796640128643, 'gamma': 0.0028563061946603003, 'reg_alpha': 0.6015062930430022, 'reg_lambda': 0.915919564352761}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:44,092] Trial 207 finished with value: 7456.5 and parameters: {'n_estimators': 400, 'learning_rate': 0.04622079457884192, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6707511491926249, 'colsample_bytree': 0.884768510657262, 'gamma': 0.002097886274439207, 'reg_alpha': 0.7175444363144099, 'reg_lambda': 0.9174375440798483}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:46,308] Trial 208 finished with value: 4829.0 and parameters: {'n_estimators': 650, 'learning_rate': 0.02498568701412168, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.6693950912781965, 'colsample_bytree': 0.7819028208993142, 'gamma': 0.006771030610091781, 'reg_alpha': 0.5643031768553595, 'reg_lambda': 0.8938153236258881}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:48,457] Trial 211 finished with value: 5898.0 and parameters: {'n_estimators': 100, 'learning_rate': 0.032254606239609386, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8859950778704194, 'colsample_bytree': 0.8365099213948204, 'gamma': 0.00502481627480302, 'reg_alpha': 0.4302347445368424, 'reg_lambda': 0.9394149235562655}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:50,417] Trial 209 finished with value: 4873.25 and parameters: {'n_estimators': 650, 'learning_rate': 0.03169185907088197, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.6315583548941387, 'colsample_bytree': 0.8842750991333971, 'gamma': 0.005324520440154639, 'reg_alpha': 0.6543594111993013, 'reg_lambda': 0.8771395070898582}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:50,487] Trial 210 finished with value: 4861.25 and parameters: {'n_estimators': 650, 'learning_rate': 0.032160585035123555, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.8852294827022338, 'colsample_bytree': 0.7829669059647615, 'gamma': 0.007596903307095311, 'reg_alpha': 0.6566288890451281, 'reg_lambda': 0.8840309000223837}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:53,752] Trial 213 finished with value: 9110.5 and parameters: {'n_estimators': 200, 'learning_rate': 0.022151768461226823, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.7264902085865694, 'colsample_bytree': 0.8613283466773437, 'gamma': 0.0012039860643640447, 'reg_alpha': 0.631364718955545, 'reg_lambda': 0.8498970342984119}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:54,019] Trial 212 finished with value: 9477.0 and parameters: {'n_estimators': 350, 'learning_rate': 0.026754171500309048, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6885349655986588, 'colsample_bytree': 0.7793895457907574, 'gamma': 0.00010747407982912246, 'reg_alpha': 0.5302627445295582, 'reg_lambda': 0.8789319987828783}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:55,417] Trial 214 finished with value: 9501.25 and parameters: {'n_estimators': 300, 'learning_rate': 0.023029704158029997, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.7236611936365007, 'colsample_bytree': 0.8481481753612059, 'gamma': 0.0002142871747420202, 'reg_alpha': 0.6329381667840064, 'reg_lambda': 0.8396217533675167}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:58,234] Trial 215 finished with value: 9556.25 and parameters: {'n_estimators': 300, 'learning_rate': 0.026227190588928195, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7331206708655755, 'colsample_bytree': 0.8491011655614897, 'gamma': 0.0004357220068234201, 'reg_alpha': 0.37533094502718994, 'reg_lambda': 0.08347607664738077}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:21:59,043] Trial 216 finished with value: 9556.5 and parameters: {'n_estimators': 350, 'learning_rate': 0.02645547544510323, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6871988594262108, 'colsample_bytree': 0.7752740383115697, 'gamma': 0.00030777943215593684, 'reg_alpha': 0.5288506200161611, 'reg_lambda': 0.9795983938077215}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:22:00,668] Trial 217 finished with value: 9459.5 and parameters: {'n_estimators': 350, 'learning_rate': 0.026332611745617164, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.6993535659957807, 'colsample_bytree': 0.776145952443873, 'gamma': 0.00025566435899620804, 'reg_alpha': 0.5340397703499558, 'reg_lambda': 0.8028658989923887}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:22:03,382] Trial 219 finished with value: 8027.25 and parameters: {'n_estimators': 350, 'learning_rate': 0.027964008718890477, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.7400435860919802, 'colsample_bytree': 0.7750403738583267, 'gamma': 0.0020297900716229594, 'reg_alpha': 0.36749525227281854, 'reg_lambda': 0.20574152304278098}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:22:04,728] Trial 218 finished with value: 9420.5 and parameters: {'n_estimators': 350, 'learning_rate': 0.01730999969689349, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7353978059352508, 'colsample_bytree': 0.8538394830321454, 'gamma': 0.00012303869621595125, 'reg_alpha': 0.3654901982961108, 'reg_lambda': 0.8042743535268739}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:22:05,509] Trial 220 finished with value: 7591.0 and parameters: {'n_estimators': 400, 'learning_rate': 0.024984424708512535, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7433455647601189, 'colsample_bytree': 0.7757656007169241, 'gamma': 0.002257025111837617, 'reg_alpha': 0.3891096872176826, 'reg_lambda': 0.2573572909229541}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:22:08,077] Trial 221 finished with value: 6333.25 and parameters: {'n_estimators': 400, 'learning_rate': 0.02447476312213305, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7211270478998697, 'colsample_bytree': 0.7531087243899833, 'gamma': 0.00392345194617532, 'reg_alpha': 0.3176377280487095, 'reg_lambda': 0.04430916127761901}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:22:08,581] Trial 223 finished with value: 5905.75 and parameters: {'n_estimators': 200, 'learning_rate': 0.0240339998520188, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.7199678053723504, 'colsample_bytree': 0.788290514386499, 'gamma': 0.0039874116162638765, 'reg_alpha': 0.47752576327049395, 'reg_lambda': 0.9899634430202601}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:22:09,828] Trial 222 finished with value: 5940.75 and parameters: {'n_estimators': 450, 'learning_rate': 0.02447576054103051, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.7132099358642506, 'colsample_bytree': 0.7545632624803433, 'gamma': 0.003931716869539812, 'reg_alpha': 0.4867251744685372, 'reg_lambda': 0.8541461531646176}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:22:11,396] Trial 224 finished with value: 7628.0 and parameters: {'n_estimators': 200, 'learning_rate': 0.0230811922071526, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6832195713577196, 'colsample_bytree': 0.8426170570877891, 'gamma': 0.0020002612532988417, 'reg_alpha': 0.4734525430791031, 'reg_lambda': 0.9857414729066812}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:22:11,505] Trial 225 finished with value: 7959.5 and parameters: {'n_estimators': 150, 'learning_rate': 0.027561232953947242, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6899514804173675, 'colsample_bytree': 0.9937651294959757, 'gamma': 0.001861474890016821, 'reg_alpha': 0.503334924217602, 'reg_lambda': 0.9801817401674385}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:22:13,022] Trial 226 finished with value: 7779.5 and parameters: {'n_estimators': 200, 'learning_rate': 0.028965758307445903, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6898230751657605, 'colsample_bytree': 0.8460409634466705, 'gamma': 0.001920400834731565, 'reg_alpha': 0.5272773644566697, 'reg_lambda': 0.9758185140688073}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:22:15,091] Trial 227 finished with value: 9519.75 and parameters: {'n_estimators': 150, 'learning_rate': 0.028387248395222622, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6878416796874588, 'colsample_bytree': 0.9226574549610539, 'gamma': 9.247907681664814e-05, 'reg_alpha': 0.5062122069210808, 'reg_lambda': 0.09915246884124118}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:22:16,043] Trial 228 finished with value: 9573.75 and parameters: {'n_estimators': 300, 'learning_rate': 0.02972269932696448, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.7307238430725516, 'colsample_bytree': 0.934056698997665, 'gamma': 0.00029481181720913334, 'reg_alpha': 0.4093660739446875, 'reg_lambda': 0.9605249958731955}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:22:17,965] Trial 229 finished with value: 9477.5 and parameters: {'n_estimators': 300, 'learning_rate': 0.02625247270084548, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6521445633112326, 'colsample_bytree': 0.9234624153719239, 'gamma': 0.00013459593737616169, 'reg_alpha': 0.412067337888617, 'reg_lambda': 0.11707239098862207}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:22:19,729] Trial 231 finished with value: 5585.5 and parameters: {'n_estimators': 300, 'learning_rate': 0.029945094385308766, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.7299509379233462, 'colsample_bytree': 0.9351227197713528, 'gamma': 0.004494864342735633, 'reg_alpha': 0.4133808660102898, 'reg_lambda': 0.13609683831093175}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:22:20,207] Trial 230 finished with value: 9420.75 and parameters: {'n_estimators': 300, 'learning_rate': 0.02988643197249159, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.6994601184365415, 'colsample_bytree': 0.9321467556195709, 'gamma': 8.211482803240007e-05, 'reg_alpha': 0.4077878688301646, 'reg_lambda': 0.1019054119218662}. Best is trial 24 with value: 9579.75.\n",
      "[I 2025-06-06 19:22:20,230] Using an existing study with name 'catboost-NQ' instead of creating a new one.\n",
      "[I 2025-06-06 19:23:35,296] Trial 103 finished with value: 9352.75 and parameters: {'iterations': 1200, 'depth': 7, 'learning_rate': 0.04161084542434709, 'l2_leaf_reg': 2.132816469730266, 'random_strength': 3.9923015033009275, 'min_data_in_leaf': 99}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:23:36,068] Trial 102 finished with value: 9584.75 and parameters: {'iterations': 1200, 'depth': 7, 'learning_rate': 0.014594823265927342, 'l2_leaf_reg': 2.0968889102396786, 'random_strength': 4.027558271200793, 'min_data_in_leaf': 100}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:23:39,526] Trial 100 finished with value: 9555.0 and parameters: {'iterations': 1200, 'depth': 7, 'learning_rate': 0.012562184610165821, 'l2_leaf_reg': 1.9934733538009568, 'random_strength': 4.262365526152112, 'min_data_in_leaf': 83}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:23:41,746] Trial 101 finished with value: 9557.75 and parameters: {'iterations': 1300, 'depth': 7, 'learning_rate': 0.0141710983389181, 'l2_leaf_reg': 1.7879349631069157, 'random_strength': 4.0298055611107815, 'min_data_in_leaf': 82}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:24:49,682] Trial 104 finished with value: 9623.25 and parameters: {'iterations': 1400, 'depth': 6, 'learning_rate': 0.015465618623045374, 'l2_leaf_reg': 2.8755355060356074, 'random_strength': 4.282695514275841, 'min_data_in_leaf': 97}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:25:00,031] Trial 106 finished with value: 9559.5 and parameters: {'iterations': 1500, 'depth': 6, 'learning_rate': 0.015867205219764324, 'l2_leaf_reg': 1.7664153827333067, 'random_strength': 4.777054825876089, 'min_data_in_leaf': 97}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:25:01,432] Trial 105 finished with value: 9655.25 and parameters: {'iterations': 1700, 'depth': 6, 'learning_rate': 0.01251654765500806, 'l2_leaf_reg': 1.8040018598246426, 'random_strength': 4.273949562778437, 'min_data_in_leaf': 98}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:25:06,826] Trial 107 finished with value: 9617.5 and parameters: {'iterations': 1700, 'depth': 6, 'learning_rate': 0.015590145395366191, 'l2_leaf_reg': 2.9110463085626006, 'random_strength': 4.765993891207922, 'min_data_in_leaf': 97}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:26:07,675] Trial 108 finished with value: 9561.0 and parameters: {'iterations': 1500, 'depth': 6, 'learning_rate': 0.024696585712603525, 'l2_leaf_reg': 2.7528440432824777, 'random_strength': 4.750080818512546, 'min_data_in_leaf': 96}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:26:40,071] Trial 111 finished with value: 9553.5 and parameters: {'iterations': 2100, 'depth': 5, 'learning_rate': 0.01265249325749046, 'l2_leaf_reg': 1.3995026618855377, 'random_strength': 4.310806800712884, 'min_data_in_leaf': 94}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:26:50,726] Trial 110 finished with value: 9605.0 and parameters: {'iterations': 2200, 'depth': 6, 'learning_rate': 0.010213390537356143, 'l2_leaf_reg': 1.3772298488595154, 'random_strength': 4.343889518427015, 'min_data_in_leaf': 94}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:27:56,304] Trial 112 finished with value: 9469.5 and parameters: {'iterations': 2500, 'depth': 5, 'learning_rate': 0.01818584395686256, 'l2_leaf_reg': 1.4244038166200843, 'random_strength': 4.348401067159163, 'min_data_in_leaf': 86}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:28:12,668] Trial 115 finished with value: 9644.75 and parameters: {'iterations': 300, 'depth': 6, 'learning_rate': 0.01882739189516532, 'l2_leaf_reg': 2.4309540283231614, 'random_strength': 2.014712767522322, 'min_data_in_leaf': 38}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:28:33,006] Trial 109 finished with value: 9132.0 and parameters: {'iterations': 4300, 'depth': 6, 'learning_rate': 0.02402067702324759, 'l2_leaf_reg': 2.3630814578785446, 'random_strength': 1.94218256690535, 'min_data_in_leaf': 94}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:29:28,775] Trial 117 finished with value: 9576.5 and parameters: {'iterations': 1100, 'depth': 6, 'learning_rate': 0.019073440690318987, 'l2_leaf_reg': 1.8681167340665796, 'random_strength': 2.053176064088924, 'min_data_in_leaf': 37}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:29:39,900] Trial 118 finished with value: 9598.75 and parameters: {'iterations': 200, 'depth': 6, 'learning_rate': 0.017790710718691656, 'l2_leaf_reg': 2.2221205079226816, 'random_strength': 1.488981353096532, 'min_data_in_leaf': 53}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:30:13,882] Trial 114 finished with value: 9286.75 and parameters: {'iterations': 4000, 'depth': 6, 'learning_rate': 0.019335732921922873, 'l2_leaf_reg': 2.30812299952325, 'random_strength': 4.900327082245119, 'min_data_in_leaf': 87}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:30:56,357] Trial 113 finished with value: 9210.5 and parameters: {'iterations': 5000, 'depth': 6, 'learning_rate': 0.019344136836380026, 'l2_leaf_reg': 2.324635681117961, 'random_strength': 3.740058695654716, 'min_data_in_leaf': 36}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:31:24,986] Trial 121 finished with value: 9598.25 and parameters: {'iterations': 500, 'depth': 6, 'learning_rate': 0.01348404514840168, 'l2_leaf_reg': 2.5100440932363357, 'random_strength': 3.934367436506758, 'min_data_in_leaf': 45}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:31:37,981] Trial 116 finished with value: 9241.75 and parameters: {'iterations': 3900, 'depth': 6, 'learning_rate': 0.01910794920125615, 'l2_leaf_reg': 2.351693934545346, 'random_strength': 1.978480066692815, 'min_data_in_leaf': 37}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:31:39,086] Trial 122 finished with value: 9219.5 and parameters: {'iterations': 300, 'depth': 5, 'learning_rate': 0.1934914894296818, 'l2_leaf_reg': 1.6156573795680957, 'random_strength': 4.204596015335347, 'min_data_in_leaf': 58}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:31:44,180] Trial 120 finished with value: 9656.0 and parameters: {'iterations': 1700, 'depth': 6, 'learning_rate': 0.013522010245549882, 'l2_leaf_reg': 2.5675919801780545, 'random_strength': 4.212729099504422, 'min_data_in_leaf': 47}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:32:17,519] Trial 119 finished with value: 9414.75 and parameters: {'iterations': 3100, 'depth': 6, 'learning_rate': 0.01347544596345359, 'l2_leaf_reg': 2.5109958510533383, 'random_strength': 1.719925502696485, 'min_data_in_leaf': 28}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:32:36,659] Trial 124 finished with value: 9612.0 and parameters: {'iterations': 1100, 'depth': 6, 'learning_rate': 0.022218343639091233, 'l2_leaf_reg': 3.139938170067635, 'random_strength': 4.490125871753618, 'min_data_in_leaf': 24}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:32:55,526] Trial 123 finished with value: 9627.0 and parameters: {'iterations': 1700, 'depth': 5, 'learning_rate': 0.016093782924269655, 'l2_leaf_reg': 1.6436145059152014, 'random_strength': 4.473721425847437, 'min_data_in_leaf': 71}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:33:14,769] Trial 125 finished with value: 9490.25 and parameters: {'iterations': 1700, 'depth': 6, 'learning_rate': 0.016938014769490896, 'l2_leaf_reg': 3.087970841928412, 'random_strength': 1.751866996182183, 'min_data_in_leaf': 48}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:33:57,750] Trial 126 finished with value: 9583.5 and parameters: {'iterations': 1800, 'depth': 6, 'learning_rate': 0.017150587527672977, 'l2_leaf_reg': 2.676105439170758, 'random_strength': 4.633159068845704, 'min_data_in_leaf': 41}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:34:12,658] Trial 128 finished with value: 9663.0 and parameters: {'iterations': 1300, 'depth': 6, 'learning_rate': 0.012087190692788337, 'l2_leaf_reg': 2.735388118518113, 'random_strength': 4.649219402000784, 'min_data_in_leaf': 41}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:34:17,763] Trial 127 finished with value: 9657.5 and parameters: {'iterations': 1800, 'depth': 6, 'learning_rate': 0.011928662174288451, 'l2_leaf_reg': 2.711959707454442, 'random_strength': 4.16083719526049, 'min_data_in_leaf': 39}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:34:31,301] Trial 129 finished with value: 9630.5 and parameters: {'iterations': 1300, 'depth': 6, 'learning_rate': 0.011931168924541467, 'l2_leaf_reg': 2.723478156387617, 'random_strength': 4.636532551349321, 'min_data_in_leaf': 63}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:35:30,356] Trial 130 finished with value: 9509.5 and parameters: {'iterations': 1300, 'depth': 7, 'learning_rate': 0.011121014828842693, 'l2_leaf_reg': 2.0783065913360232, 'random_strength': 4.09887081070719, 'min_data_in_leaf': 42}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:35:42,681] Trial 132 finished with value: 9552.5 and parameters: {'iterations': 2000, 'depth': 4, 'learning_rate': 0.011955017073812874, 'l2_leaf_reg': 2.056183341762654, 'random_strength': 4.083426939731795, 'min_data_in_leaf': 41}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:35:48,047] Trial 131 finished with value: 9544.5 and parameters: {'iterations': 1300, 'depth': 7, 'learning_rate': 0.011550570625736929, 'l2_leaf_reg': 2.040004552856774, 'random_strength': 4.150195243379742, 'min_data_in_leaf': 40}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:35:52,291] Trial 133 finished with value: 9546.75 and parameters: {'iterations': 1900, 'depth': 4, 'learning_rate': 0.011712562950155377, 'l2_leaf_reg': 3.488713121207684, 'random_strength': 4.1997532179032575, 'min_data_in_leaf': 32}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:36:44,410] Trial 135 finished with value: 9658.25 and parameters: {'iterations': 1100, 'depth': 6, 'learning_rate': 0.014324101896982121, 'l2_leaf_reg': 3.044090484283144, 'random_strength': 4.210865019903101, 'min_data_in_leaf': 47}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:36:50,102] Trial 136 finished with value: 9691.25 and parameters: {'iterations': 1100, 'depth': 6, 'learning_rate': 0.014694685817089308, 'l2_leaf_reg': 2.9570035926678253, 'random_strength': 4.198917812124804, 'min_data_in_leaf': 33}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:37:08,656] Trial 137 finished with value: 9619.75 and parameters: {'iterations': 1400, 'depth': 6, 'learning_rate': 0.01438605732571658, 'l2_leaf_reg': 3.0069174580368263, 'random_strength': 4.38913553909089, 'min_data_in_leaf': 48}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:38:02,072] Trial 134 finished with value: 9592.0 and parameters: {'iterations': 1900, 'depth': 8, 'learning_rate': 0.010906697683386889, 'l2_leaf_reg': 2.959084381017627, 'random_strength': 4.184193810951201, 'min_data_in_leaf': 34}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:38:07,481] Trial 139 finished with value: 9652.25 and parameters: {'iterations': 1500, 'depth': 6, 'learning_rate': 0.014541829576745428, 'l2_leaf_reg': 2.9915098235052278, 'random_strength': 3.9373821884746807, 'min_data_in_leaf': 46}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:38:07,702] Trial 140 finished with value: 9645.5 and parameters: {'iterations': 1100, 'depth': 6, 'learning_rate': 0.012786368082070716, 'l2_leaf_reg': 2.8311719753236964, 'random_strength': 3.7984098353493687, 'min_data_in_leaf': 34}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:38:07,888] Trial 138 finished with value: 9672.0 and parameters: {'iterations': 1600, 'depth': 6, 'learning_rate': 0.010755203336362774, 'l2_leaf_reg': 2.966673418686093, 'random_strength': 4.262841705327296, 'min_data_in_leaf': 47}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:38:59,274] Trial 141 finished with value: 9647.25 and parameters: {'iterations': 1100, 'depth': 6, 'learning_rate': 0.013048925128133777, 'l2_leaf_reg': 2.804997299037335, 'random_strength': 4.254608466155541, 'min_data_in_leaf': 51}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:39:20,093] Trial 144 finished with value: 9671.5 and parameters: {'iterations': 1400, 'depth': 6, 'learning_rate': 0.010525811556368468, 'l2_leaf_reg': 3.3613532531678763, 'random_strength': 3.9794804357434246, 'min_data_in_leaf': 46}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:39:21,474] Trial 142 finished with value: 9670.0 and parameters: {'iterations': 1500, 'depth': 6, 'learning_rate': 0.010740001904899679, 'l2_leaf_reg': 3.8332248563337386, 'random_strength': 3.6282941287318287, 'min_data_in_leaf': 46}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:39:23,291] Trial 143 finished with value: 9661.25 and parameters: {'iterations': 1500, 'depth': 6, 'learning_rate': 0.014713948538270964, 'l2_leaf_reg': 3.3990039325265573, 'random_strength': 3.9743985681880485, 'min_data_in_leaf': 45}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:40:22,478] Trial 145 finished with value: 9649.0 and parameters: {'iterations': 1600, 'depth': 6, 'learning_rate': 0.010541889872258004, 'l2_leaf_reg': 3.274085283292694, 'random_strength': 4.3001978816108615, 'min_data_in_leaf': 45}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:40:37,462] Trial 146 finished with value: 9632.5 and parameters: {'iterations': 1600, 'depth': 6, 'learning_rate': 0.01051109557046163, 'l2_leaf_reg': 3.381424753828618, 'random_strength': 4.3037367682193155, 'min_data_in_leaf': 45}. Best is trial 17 with value: 9696.0.\n",
      "[I 2025-06-06 19:40:43,202] Trial 147 finished with value: 9709.75 and parameters: {'iterations': 1600, 'depth': 6, 'learning_rate': 0.010622425434521377, 'l2_leaf_reg': 3.8574967285374773, 'random_strength': 4.050919919772589, 'min_data_in_leaf': 45}. Best is trial 147 with value: 9709.75.\n",
      "[I 2025-06-06 19:40:45,525] Trial 148 finished with value: 9684.75 and parameters: {'iterations': 1600, 'depth': 6, 'learning_rate': 0.010520187917244744, 'l2_leaf_reg': 3.8844270621904804, 'random_strength': 3.6314138730280394, 'min_data_in_leaf': 43}. Best is trial 147 with value: 9709.75.\n",
      "[I 2025-06-06 19:41:33,528] Trial 149 finished with value: 9659.0 and parameters: {'iterations': 1400, 'depth': 6, 'learning_rate': 0.010158521725064573, 'l2_leaf_reg': 3.8891069626940604, 'random_strength': 4.04766092249249, 'min_data_in_leaf': 43}. Best is trial 147 with value: 9709.75.\n",
      "[I 2025-06-06 19:41:50,240] Trial 150 finished with value: 9684.0 and parameters: {'iterations': 1400, 'depth': 6, 'learning_rate': 0.01226892532882436, 'l2_leaf_reg': 4.299181990570707, 'random_strength': 3.643439367227874, 'min_data_in_leaf': 50}. Best is trial 147 with value: 9709.75.\n",
      "[I 2025-06-06 19:41:55,498] Trial 151 finished with value: 9694.5 and parameters: {'iterations': 1400, 'depth': 6, 'learning_rate': 0.010615491681315646, 'l2_leaf_reg': 4.255127770010375, 'random_strength': 4.037672987860706, 'min_data_in_leaf': 51}. Best is trial 147 with value: 9709.75.\n",
      "[I 2025-06-06 19:41:56,191] Trial 152 finished with value: 9670.75 and parameters: {'iterations': 1400, 'depth': 6, 'learning_rate': 0.010570994636257177, 'l2_leaf_reg': 3.8836137967262045, 'random_strength': 4.058209554853638, 'min_data_in_leaf': 50}. Best is trial 147 with value: 9709.75.\n",
      "[I 2025-06-06 19:42:35,860] Trial 153 finished with value: 9628.25 and parameters: {'iterations': 1400, 'depth': 5, 'learning_rate': 0.010252314277249007, 'l2_leaf_reg': 4.259975976971825, 'random_strength': 3.423580706933064, 'min_data_in_leaf': 43}. Best is trial 147 with value: 9709.75.\n",
      "[I 2025-06-06 19:43:03,184] Trial 154 finished with value: 9669.0 and parameters: {'iterations': 1400, 'depth': 6, 'learning_rate': 0.010034817833901576, 'l2_leaf_reg': 4.286659470447201, 'random_strength': 3.683040499439752, 'min_data_in_leaf': 43}. Best is trial 147 with value: 9709.75.\n",
      "[I 2025-06-06 19:43:09,383] Trial 156 finished with value: 9649.0 and parameters: {'iterations': 1400, 'depth': 6, 'learning_rate': 0.01007560264716246, 'l2_leaf_reg': 4.251979415835945, 'random_strength': 3.7907624345459365, 'min_data_in_leaf': 55}. Best is trial 147 with value: 9709.75.\n",
      "[I 2025-06-06 19:43:12,494] Trial 155 finished with value: 9657.0 and parameters: {'iterations': 1400, 'depth': 6, 'learning_rate': 0.010351062894802367, 'l2_leaf_reg': 4.3027614380429275, 'random_strength': 3.6130849104920273, 'min_data_in_leaf': 50}. Best is trial 147 with value: 9709.75.\n",
      "[I 2025-06-06 19:43:54,475] Trial 157 finished with value: 9643.5 and parameters: {'iterations': 1500, 'depth': 6, 'learning_rate': 0.010166207147560906, 'l2_leaf_reg': 3.893029401582123, 'random_strength': 3.6633230944339292, 'min_data_in_leaf': 50}. Best is trial 147 with value: 9709.75.\n",
      "[I 2025-06-06 19:44:20,581] Trial 158 finished with value: 9685.25 and parameters: {'iterations': 1500, 'depth': 6, 'learning_rate': 0.0109982921980882, 'l2_leaf_reg': 4.388954935702112, 'random_strength': 3.653682766126366, 'min_data_in_leaf': 50}. Best is trial 147 with value: 9709.75.\n",
      "[I 2025-06-06 19:44:32,339] Trial 159 finished with value: 9697.25 and parameters: {'iterations': 1600, 'depth': 6, 'learning_rate': 0.01097764622463776, 'l2_leaf_reg': 3.7396162335209717, 'random_strength': 3.2123980862738817, 'min_data_in_leaf': 51}. Best is trial 147 with value: 9709.75.\n",
      "[I 2025-06-06 19:44:34,824] Trial 160 finished with value: 9664.5 and parameters: {'iterations': 1600, 'depth': 6, 'learning_rate': 0.011223585400544188, 'l2_leaf_reg': 3.6639617471968307, 'random_strength': 3.668721726599621, 'min_data_in_leaf': 52}. Best is trial 147 with value: 9709.75.\n",
      "[I 2025-06-06 19:45:15,211] Trial 161 finished with value: 9712.0 and parameters: {'iterations': 1600, 'depth': 6, 'learning_rate': 0.011251186577619369, 'l2_leaf_reg': 4.64721398425246, 'random_strength': 3.2682753039311496, 'min_data_in_leaf': 54}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:45:24,691] Trial 162 finished with value: 9688.0 and parameters: {'iterations': 1200, 'depth': 6, 'learning_rate': 0.01109941159005204, 'l2_leaf_reg': 4.056809915707052, 'random_strength': 3.6184353441685064, 'min_data_in_leaf': 53}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:45:59,544] Trial 164 finished with value: 9640.0 and parameters: {'iterations': 1600, 'depth': 6, 'learning_rate': 0.011135263156655457, 'l2_leaf_reg': 4.612323284558511, 'random_strength': 3.332789389876818, 'min_data_in_leaf': 53}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:46:08,566] Trial 163 finished with value: 9508.5 and parameters: {'iterations': 1600, 'depth': 7, 'learning_rate': 0.01106882184187964, 'l2_leaf_reg': 4.538471932607215, 'random_strength': 3.2317042859898137, 'min_data_in_leaf': 53}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:46:26,830] Trial 166 finished with value: 9621.0 and parameters: {'iterations': 1200, 'depth': 6, 'learning_rate': 0.010999782599086917, 'l2_leaf_reg': 4.115219170061506, 'random_strength': 3.1004727557262832, 'min_data_in_leaf': 54}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:46:39,315] Trial 165 finished with value: 9649.25 and parameters: {'iterations': 1600, 'depth': 6, 'learning_rate': 0.011012600096995256, 'l2_leaf_reg': 4.6492039368831835, 'random_strength': 3.2728729284707803, 'min_data_in_leaf': 56}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:47:06,050] Trial 167 finished with value: 9663.5 and parameters: {'iterations': 1200, 'depth': 6, 'learning_rate': 0.011250117048323788, 'l2_leaf_reg': 4.010970503540374, 'random_strength': 3.1357355499896595, 'min_data_in_leaf': 54}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:47:09,332] Trial 168 finished with value: 9633.25 and parameters: {'iterations': 1200, 'depth': 6, 'learning_rate': 0.010859264305209865, 'l2_leaf_reg': 4.038952154041684, 'random_strength': 3.0235260050059116, 'min_data_in_leaf': 57}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:47:28,260] Trial 169 finished with value: 9660.75 and parameters: {'iterations': 1200, 'depth': 6, 'learning_rate': 0.012578263909845835, 'l2_leaf_reg': 4.86414177340896, 'random_strength': 3.483175980365127, 'min_data_in_leaf': 57}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:47:39,046] Trial 170 finished with value: 9691.25 and parameters: {'iterations': 1200, 'depth': 6, 'learning_rate': 0.0122798471150797, 'l2_leaf_reg': 4.868493645972768, 'random_strength': 3.542854961167958, 'min_data_in_leaf': 57}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:48:34,837] Trial 171 finished with value: 9647.5 and parameters: {'iterations': 1800, 'depth': 6, 'learning_rate': 0.012359625131666132, 'l2_leaf_reg': 3.6820756863280755, 'random_strength': 2.944210434371206, 'min_data_in_leaf': 57}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:48:42,600] Trial 173 finished with value: 9632.75 and parameters: {'iterations': 1500, 'depth': 6, 'learning_rate': 0.01230225187360201, 'l2_leaf_reg': 4.388542435924091, 'random_strength': 2.915411620635815, 'min_data_in_leaf': 49}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:48:47,117] Trial 172 finished with value: 9661.25 and parameters: {'iterations': 1800, 'depth': 6, 'learning_rate': 0.012271228381476493, 'l2_leaf_reg': 3.7521914470982436, 'random_strength': 3.5490108771737545, 'min_data_in_leaf': 49}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:49:11,204] Trial 174 finished with value: 9679.5 and parameters: {'iterations': 1800, 'depth': 6, 'learning_rate': 0.011968411460406317, 'l2_leaf_reg': 3.7906630670354486, 'random_strength': 3.545238351817016, 'min_data_in_leaf': 49}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:49:51,587] Trial 176 finished with value: 9642.5 and parameters: {'iterations': 1300, 'depth': 6, 'learning_rate': 0.01334373282182546, 'l2_leaf_reg': 3.843295947434987, 'random_strength': 3.590993256705123, 'min_data_in_leaf': 51}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:49:52,716] Trial 175 finished with value: 9635.25 and parameters: {'iterations': 1500, 'depth': 6, 'learning_rate': 0.011952209390495225, 'l2_leaf_reg': 3.7806050513981915, 'random_strength': 3.5880479398985883, 'min_data_in_leaf': 49}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:50:00,896] Trial 177 finished with value: 9669.5 and parameters: {'iterations': 1500, 'depth': 6, 'learning_rate': 0.013384898781747312, 'l2_leaf_reg': 4.158502073580125, 'random_strength': 3.4850200942022083, 'min_data_in_leaf': 51}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:50:18,331] Trial 178 finished with value: 9676.0 and parameters: {'iterations': 1300, 'depth': 6, 'learning_rate': 0.01311218454142677, 'l2_leaf_reg': 5.404118846784086, 'random_strength': 3.437377241423847, 'min_data_in_leaf': 51}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:51:01,947] Trial 179 finished with value: 9660.75 and parameters: {'iterations': 1300, 'depth': 6, 'learning_rate': 0.011854729732558392, 'l2_leaf_reg': 5.39610285635149, 'random_strength': 3.457821253257141, 'min_data_in_leaf': 51}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:51:06,076] Trial 181 finished with value: 9015.0 and parameters: {'iterations': 1300, 'depth': 6, 'learning_rate': 0.08147678559731393, 'l2_leaf_reg': 5.041368800041139, 'random_strength': 3.759002250732396, 'min_data_in_leaf': 61}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:51:16,007] Trial 182 finished with value: 9628.75 and parameters: {'iterations': 1100, 'depth': 6, 'learning_rate': 0.011652167180710762, 'l2_leaf_reg': 5.369415480412108, 'random_strength': 3.3758590303870073, 'min_data_in_leaf': 59}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:51:31,113] Trial 180 finished with value: 9643.0 and parameters: {'iterations': 1900, 'depth': 6, 'learning_rate': 0.011544158044670525, 'l2_leaf_reg': 4.476757261135941, 'random_strength': 3.4777568010542494, 'min_data_in_leaf': 47}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:52:30,063] Trial 184 finished with value: 9675.0 and parameters: {'iterations': 1600, 'depth': 6, 'learning_rate': 0.011461976800290234, 'l2_leaf_reg': 5.689244780535711, 'random_strength': 3.3996675084609245, 'min_data_in_leaf': 47}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:52:30,364] Trial 183 finished with value: 9545.5 and parameters: {'iterations': 1100, 'depth': 8, 'learning_rate': 0.011566838861896925, 'l2_leaf_reg': 5.895775407324473, 'random_strength': 3.3740319510146, 'min_data_in_leaf': 48}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:52:48,781] Trial 185 finished with value: 9642.75 and parameters: {'iterations': 1700, 'depth': 6, 'learning_rate': 0.010790752981860814, 'l2_leaf_reg': 4.895546588829492, 'random_strength': 3.3698708707210536, 'min_data_in_leaf': 47}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:53:01,303] Trial 186 finished with value: 9562.0 and parameters: {'iterations': 1100, 'depth': 8, 'learning_rate': 0.012901086661849696, 'l2_leaf_reg': 4.828553290630732, 'random_strength': 3.8414707740295375, 'min_data_in_leaf': 54}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:53:59,321] Trial 188 finished with value: 9600.5 and parameters: {'iterations': 1700, 'depth': 6, 'learning_rate': 0.013671739295392699, 'l2_leaf_reg': 6.49720102087116, 'random_strength': 3.2039504324182078, 'min_data_in_leaf': 53}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:54:14,661] Trial 189 finished with value: 9643.75 and parameters: {'iterations': 1600, 'depth': 6, 'learning_rate': 0.013009804430562176, 'l2_leaf_reg': 5.816150213852663, 'random_strength': 3.3027239712794314, 'min_data_in_leaf': 55}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:54:22,414] Trial 190 finished with value: 9630.75 and parameters: {'iterations': 1600, 'depth': 6, 'learning_rate': 0.012900624135758569, 'l2_leaf_reg': 5.741521208827649, 'random_strength': 3.302777651881922, 'min_data_in_leaf': 52}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:54:38,790] Trial 187 finished with value: 9490.0 and parameters: {'iterations': 1700, 'depth': 8, 'learning_rate': 0.01303811987557924, 'l2_leaf_reg': 5.9709618354520915, 'random_strength': 3.2889842754390632, 'min_data_in_leaf': 48}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:55:24,185] Trial 191 finished with value: 9632.5 and parameters: {'iterations': 1600, 'depth': 6, 'learning_rate': 0.012796717521467126, 'l2_leaf_reg': 5.781836696349517, 'random_strength': 3.275204561923899, 'min_data_in_leaf': 55}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:55:38,301] Trial 192 finished with value: 9612.75 and parameters: {'iterations': 1800, 'depth': 5, 'learning_rate': 0.01003946411948475, 'l2_leaf_reg': 5.206217787608879, 'random_strength': 3.7396617320561947, 'min_data_in_leaf': 25}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:55:49,954] Trial 193 finished with value: 9667.0 and parameters: {'iterations': 1800, 'depth': 6, 'learning_rate': 0.010909034213294908, 'l2_leaf_reg': 6.202775835016906, 'random_strength': 3.743243402378008, 'min_data_in_leaf': 46}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:55:50,973] Trial 194 finished with value: 9650.0 and parameters: {'iterations': 1400, 'depth': 6, 'learning_rate': 0.010850013893422345, 'l2_leaf_reg': 4.1106176869469895, 'random_strength': 3.872640125118623, 'min_data_in_leaf': 50}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:56:35,022] Trial 195 finished with value: 9631.0 and parameters: {'iterations': 1400, 'depth': 6, 'learning_rate': 0.010061546887676005, 'l2_leaf_reg': 5.52185176686294, 'random_strength': 3.737762657789747, 'min_data_in_leaf': 50}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:56:52,112] Trial 196 finished with value: 9676.5 and parameters: {'iterations': 1400, 'depth': 6, 'learning_rate': 0.010773764977812149, 'l2_leaf_reg': 3.550082870857185, 'random_strength': 3.8705579327750255, 'min_data_in_leaf': 50}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:57:00,428] Trial 197 finished with value: 9681.0 and parameters: {'iterations': 1400, 'depth': 6, 'learning_rate': 0.010767866665563822, 'l2_leaf_reg': 5.610250274653975, 'random_strength': 3.861959556553198, 'min_data_in_leaf': 50}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:57:03,924] Trial 198 finished with value: 9661.0 and parameters: {'iterations': 1400, 'depth': 6, 'learning_rate': 0.011879700374640702, 'l2_leaf_reg': 3.489637569394811, 'random_strength': 3.5176697022131744, 'min_data_in_leaf': 44}. Best is trial 161 with value: 9712.0.\n",
      "[I 2025-06-06 19:58:20,097] Trial 199 finished with value: 9628.75 and parameters: {'iterations': 2800, 'depth': 6, 'learning_rate': 0.011878536436330623, 'l2_leaf_reg': 3.5332699545951827, 'random_strength': 3.5379225559431786, 'min_data_in_leaf': 44}. Best is trial 161 with value: 9712.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with target: 0.2685\n",
      "\n",
      "Evaluation CatBoost\n",
      "\n",
      "📊 CatBoostRegressorUp Performance:\n",
      "Train MSE: 0.00000425\n",
      "Test MSE: 0.00000271\n",
      "Overfit ratio (Test / Train): 0.64\n",
      "⚠️ Possibly underfitting.\n",
      "\n",
      "Evaluation LGBM\n",
      "\n",
      "📊 XGBM Performance:\n",
      "Train MSE: 0.00001421\n",
      "Test MSE: 0.00000272\n",
      "Overfit ratio (Test / Train): 0.19\n",
      "⚠️ Possibly underfitting.\n",
      "\n",
      "🔍 Target distribution Seq:\n",
      "count    294672.000000\n",
      "mean          0.000993\n",
      "std           0.011141\n",
      "min          -0.014727\n",
      "25%          -0.000499\n",
      "50%           0.000800\n",
      "75%           0.001882\n",
      "max           5.940881\n",
      "Name: reg_value, dtype: float64\n",
      "\n",
      "🔍 Checking prediction variance:\n",
      "Min: -0.00044002\n",
      "Max: 0.00402989\n",
      "Mean: 0.00109606\n",
      "Std Dev: 0.00039652\n",
      "First 5 Predictions: [0.00082139 0.00082433 0.00083367 0.00081714 0.00079609]\n",
      "MAE: 0.0013\n",
      "RMSE: 0.0017\n",
      "R²: 0.0563\n",
      "\n",
      "🔍 Checking prediction variance:\n",
      "Min: 0.00029434\n",
      "Max: 0.00382126\n",
      "Mean: 0.00096740\n",
      "Std Dev: 0.00042701\n",
      "First 5 Predictions: [0.00063978 0.00064423 0.0006535  0.00062952 0.00060611]\n",
      "MAE: 0.0013\n",
      "RMSE: 0.0016\n",
      "R²: 0.0654\n",
      "\n",
      "🔍 Checking prediction variance:\n",
      "Min: -0.00373170\n",
      "Max: 0.00580504\n",
      "Mean: 0.00094397\n",
      "Std Dev: 0.00055080\n",
      "First 5 Predictions: [0.0006107  0.0006131  0.00062675 0.00061201 0.00058436]\n",
      "MAE: 0.0013\n",
      "RMSE: 0.0016\n",
      "R²: 0.0696\n"
     ]
    }
   ],
   "source": [
    "# Regression Training\n",
    "reg_results = []\n",
    "\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "regression_models = run_lookahead_for_session_regression()\n",
    "reg_results.append(regression_models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T01:29:01.886642Z",
     "start_time": "2025-06-04T01:28:46.711155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Predicted return range for STACK: min=-0.000440023511741, max=0.004029887263981\n",
      "\n",
      "PnL: $26818.86\n",
      "Trades: 888\n",
      "Win Rate: 26.69%\n",
      "Expectancy: 30.20\n",
      "Profit Factor: 1.19\n",
      "Average Confidence Win: 0.0014208\n",
      "Average Confidence Loss: 0.0013912\n",
      "Sharpe Ratio: 1.78\n",
      "Long Trades: 888 | Short Trades: 0\n",
      "\n",
      "Avoid Hits:\n",
      "\n",
      "🔢 Top 5 PnL trades:\n",
      "                   entry_time                 exit_time  side  entry_price  \\\n",
      "256 2025-05-08 11:30:00-04:00 2025-05-08 11:50:00-04:00  long     20193.50   \n",
      "221 2025-05-07 14:50:00-04:00 2025-05-07 15:05:00-04:00  long     19786.25   \n",
      "225 2025-05-07 15:50:00-04:00 2025-05-07 16:10:00-04:00  long     19899.75   \n",
      "254 2025-05-08 11:00:00-04:00 2025-05-08 11:15:00-04:00  long     19999.25   \n",
      "353 2025-05-12 10:30:00-04:00 2025-05-12 10:50:00-04:00  long     20718.50   \n",
      "\n",
      "       exit_price          pnl     mfe  mae    gross_pnl  vol_adj_pred  \\\n",
      "256  20311.991062  2365.841230  2460.0  0.0  2369.821230      0.001885   \n",
      "221  19886.834428  2007.708563  2055.0  0.0  2011.688563      0.002449   \n",
      "225  19991.317829  1827.376571  1980.0  0.0  1831.356571      0.003527   \n",
      "254  20084.888552  1708.791041  1795.0  0.0  1712.771041      0.001803   \n",
      "353  20803.796671  1701.953420  1790.0  0.0  1705.933420      0.002480   \n",
      "\n",
      "     confidence  position_size exit_reason  used_trailing  \n",
      "256    1.989784            1.0       TRAIL           True  \n",
      "221    2.000000            1.0          TP          False  \n",
      "225    2.000000            1.0       TRAIL           True  \n",
      "254    1.783903            1.0          TP          False  \n",
      "353    2.000000            1.0       TRAIL           True  \n",
      "\n",
      "🔻 Bottom 5 PnL trades:\n",
      "                   entry_time                 exit_time  side  entry_price  \\\n",
      "226 2025-05-07 16:10:00-04:00 2025-05-07 18:05:00-04:00  long     19979.25   \n",
      "222 2025-05-07 15:05:00-04:00 2025-05-07 15:20:00-04:00  long     19878.00   \n",
      "592 2025-05-21 14:05:00-04:00 2025-05-21 14:25:00-04:00  long     21275.50   \n",
      "223 2025-05-07 15:20:00-04:00 2025-05-07 15:35:00-04:00  long     19831.75   \n",
      "669 2025-05-23 10:10:00-04:00 2025-05-23 10:25:00-04:00  long     20969.75   \n",
      "\n",
      "       exit_price          pnl   mfe     mae    gross_pnl  vol_adj_pred  \\\n",
      "226  19918.500000 -1218.980000   0.0  1370.0 -1215.000000      0.003387   \n",
      "222  19824.254375 -1078.892495   0.0  1130.0 -1074.912495      0.002546   \n",
      "592  21221.992878 -1074.122443   0.0  1785.0 -1070.142443      0.002666   \n",
      "223  19778.329123 -1072.397548   0.0  1355.0 -1068.417548      0.002390   \n",
      "669  20917.132408 -1056.331834  95.0  1160.0 -1052.351834      0.002063   \n",
      "\n",
      "     confidence  position_size  exit_reason  used_trailing  \n",
      "226         2.0            1.0  SESSION_END          False  \n",
      "222         2.0            1.0           SL          False  \n",
      "592         2.0            1.0           SL          False  \n",
      "223         2.0            1.0           SL          False  \n",
      "669         2.0            1.0           SL          False  \n",
      "\n",
      "🏁 Top 10 Configurations Across All Lookaheads:\n",
      "            pnl    sharpe  expectancy  profit_factor  win_rate  trades  \\\n",
      "0  26818.860612  1.779171    30.20142        1.19114  0.266892     888   \n",
      "\n",
      "   avg_confidence_win  avg_confidence_loss  \n",
      "0            0.001421             0.001391  \n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for result in reg_results:\n",
    "    preds_stack = result['preds_stack']\n",
    "    X_test_combined = result['X_test']\n",
    "    y_test = result['true_values']\n",
    "    labeled = pd.read_parquet(f\"parquet/labeled_data_L12_PT2SL1VB12{market}.parquet\")\n",
    "    df_backtest = labeled.copy()\n",
    "\n",
    "    print(f\"\\n🔎 Predicted return range for STACK: min={preds_stack.min():.15f}, max={preds_stack.max():.15f}\")\n",
    "    results = evaluate_regression(\n",
    "        X_test=X_test_combined,\n",
    "        preds_stack=preds_stack,\n",
    "        labeled=labeled,\n",
    "        df=df_backtest,\n",
    "        avoid_funcs=avoid_funcs,\n",
    "        TICK_VALUE=20,\n",
    "        is_same_session=is_same_session,\n",
    "        long_thresh=0.001,\n",
    "        TRAIL_START_MULT=0.1,\n",
    "        TRAIL_STOP_MULT=0.1,\n",
    "        short_thresh=-0.0001,\n",
    "        base_contracts=1,\n",
    "        max_contracts=1,\n",
    "    )\n",
    "\n",
    "    all_results.append(results)\n",
    "    print(\n",
    "        f\"\\nPnL: ${results['pnl']:.2f}\"\n",
    "        f\"\\nTrades: {results['trades']}\"\n",
    "        f\"\\nWin Rate: {results['win_rate']:.2%}\"\n",
    "        f\"\\nExpectancy: {results['expectancy']:.2f}\"\n",
    "        f\"\\nProfit Factor: {results['profit_factor']:.2f}\"\n",
    "        f\"\\nAverage Confidence Win: {results['avg_confidence_win']:.7f}\"\n",
    "        f\"\\nAverage Confidence Loss: {results['avg_confidence_loss']:.7f}\"\n",
    "        f\"\\nSharpe Ratio: {results['sharpe']:.2f}\"\n",
    "        f\"\\nLong Trades: {results['long_trades']} | Short Trades: {results['short_trades']}\"\n",
    "        f\"\\n\"\n",
    "    )\n",
    "\n",
    "    print(\"Avoid Hits:\")\n",
    "    for name, count in results['avoid_hits'].items():\n",
    "        print(f\" - {name}: {count}\")\n",
    "\n",
    "    if not results['results'].empty and 'pnl' in results['results'].columns:\n",
    "        print(\"\\n🔢 Top 5 PnL trades:\")\n",
    "        print(results['results'].sort_values(by='pnl', ascending=False).head(5))\n",
    "\n",
    "        print(\"\\n🔻 Bottom 5 PnL trades:\")\n",
    "        print(results['results'].sort_values(by='pnl', ascending=True).head(5))\n",
    "    else:\n",
    "        print(\"\\n⚠️ No trades executed, skipping PnL trade breakdown.\")\n",
    "\n",
    "\n",
    "summary_df = pd.DataFrame([{\n",
    "    'pnl': r['pnl'],\n",
    "    'sharpe': r['sharpe'],\n",
    "    'expectancy': r['expectancy'],\n",
    "    'profit_factor': r['profit_factor'],\n",
    "    'win_rate': r['win_rate'],\n",
    "    'trades': r['trades'],\n",
    "    'avg_confidence_win': r['avg_confidence_win'],\n",
    "    'avg_confidence_loss': r['avg_confidence_loss'],\n",
    "    'results': r['results'],\n",
    "} for r in all_results])\n",
    "top = summary_df.sort_values(by='sharpe', ascending=False).head(10)\n",
    "print(\"\\n🏁 Top 10 Configurations Across All Lookaheads:\")\n",
    "print(top[['pnl', 'sharpe', 'expectancy', 'profit_factor', 'win_rate', 'trades', 'avg_confidence_win', 'avg_confidence_loss']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exit_reason\n",
      "TRAIL          535\n",
      "SL             279\n",
      "TP              69\n",
      "SESSION_END      5\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💣 Max Consecutive PnL Loss: -8567.41\n",
      "📆 Period: 2025-05-02 12:45:00-04:00 → 2025-05-07 13:55:00-04:00\n",
      "✅ Saved best_strategy_results.csv\n"
     ]
    }
   ],
   "source": [
    "best_result = None\n",
    "\n",
    "def compute_max_consecutive_loss(df):\n",
    "    \"\"\"\n",
    "    Calculates the worst cumulative loss (drawdown) from any starting point.\n",
    "    \"\"\"\n",
    "    pnl_series = df['pnl'].values\n",
    "    max_loss = 0.0\n",
    "    start_idx = 0\n",
    "    end_idx = 0\n",
    "\n",
    "    for i in range(len(pnl_series)):\n",
    "        cumulative = 0.0\n",
    "        for j in range(i, len(pnl_series)):\n",
    "            cumulative += pnl_series[j]\n",
    "            if cumulative < max_loss:\n",
    "                max_loss = cumulative\n",
    "                start_idx = i\n",
    "                end_idx = j\n",
    "\n",
    "    return max_loss, df['entry_time'].iloc[start_idx], df['entry_time'].iloc[end_idx]\n",
    "\n",
    "\n",
    "for r in all_results:\n",
    "    df = r['results'].copy()\n",
    "    df = df.sort_values(by='entry_time')\n",
    "    df['cumulative_pnl'] = df['pnl'].cumsum()\n",
    "\n",
    "    # Count how many trades exited for each reason\n",
    "    exit_counts = df['exit_reason'].value_counts(dropna=False)\n",
    "    print(exit_counts)\n",
    "\n",
    "    if (\n",
    "        df['cumulative_pnl'].iloc[-1] > 0 and\n",
    "        r['sharpe'] > 0.01 and\n",
    "        r['trades'] > 1 and\n",
    "        r['win_rate'] > 0.001 and\n",
    "        r['profit_factor'] > 0.01 and\n",
    "        r['expectancy'] > 0.01 and\n",
    "        r['pnl'] > 100\n",
    "    ):\n",
    "        if best_result is None or r['sharpe'] > best_result['sharpe']:\n",
    "            best_result = r.copy()\n",
    "            best_result['cumulative_pnl'] = df['cumulative_pnl']\n",
    "            best_result['entry_time'] = df['entry_time']\n",
    "\n",
    "            # === Calculate max drawdown (largest PnL loss from peak)\n",
    "            cumulative = df['cumulative_pnl']\n",
    "            rolling_max = cumulative.cummax()\n",
    "            drawdowns = cumulative - rolling_max\n",
    "            max_drawdown = drawdowns.min()  # Most negative drop\n",
    "            max_drawdown_start = rolling_max[drawdowns.idxmin()]\n",
    "            best_result['max_drawdown'] = max_drawdown\n",
    "\n",
    "# === Plot the best one ===\n",
    "# === After determining best_result\n",
    "if best_result:\n",
    "    df = best_result['results'].copy()\n",
    "    df = df.sort_values(by='entry_time')\n",
    "    df['cumulative_pnl'] = df['pnl'].cumsum()\n",
    "\n",
    "    max_loss, loss_start, loss_end = compute_max_consecutive_loss(df)\n",
    "\n",
    "    # === Plot\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(df['entry_time'], df['cumulative_pnl'], label='Cumulative PnL', color='green')\n",
    "    plt.axvspan(loss_start, loss_end, color='red', alpha=0.2, label='Max Loss Window')\n",
    "    plt.title(f\"Top Sharpe Strategy | Max Consecutive Loss: {max_loss:.2f} | Cumulative PnL: {best_result['pnl']:.2f}\")\n",
    "    plt.xlabel(\"Datetime\")\n",
    "    plt.ylabel(\"Cumulative PnL\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"💣 Max Consecutive PnL Loss: {max_loss:.2f}\")\n",
    "    print(f\"📆 Period: {loss_start} → {loss_end}\")\n",
    "    best_result['results'].to_csv(\"best_strategy_results.csv\", index=False)\n",
    "    print(\"✅ Saved best_strategy_results.csv\")\n",
    "else:\n",
    "    print(\"❌ No strategy met the conditions.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
