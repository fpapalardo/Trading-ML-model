{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import platform\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "from collections import defaultdict\n",
    "import joblib\n",
    "import json\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# TA Indicators\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.volatility import BollingerBands, AverageTrueRange\n",
    "from ta.trend import EMAIndicator, MACD\n",
    "from ta.volume import VolumeWeightedAveragePrice, OnBalanceVolumeIndicator\n",
    "#\n",
    "\n",
    "# Tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.base import clone, BaseEstimator, RegressorMixin, ClassifierMixin\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, root_mean_squared_error, mean_squared_error, mean_absolute_error, r2_score, accuracy_score, classification_report, f1_score\n",
    "from sklearn.preprocessing import label_binarize, StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "#\n",
    "\n",
    "# Models and Training\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from lightgbm import LGBMRegressor, early_stopping\n",
    "import optuna\n",
    "import seaborn as sns\n",
    "import shap\n",
    "#\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*There are no meaningful features.*\", category=UserWarning)\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"./../data/\"\n",
    "column_names = ['datetime', 'open', 'high', 'low', 'close', 'volume']\n",
    "df_list = []\n",
    "\n",
    "system = platform.system()\n",
    "# Set emoji-compatible font based on OS\n",
    "if system == 'Windows':\n",
    "    plt.rcParams['font.family'] = 'Segoe UI Emoji'\n",
    "elif system == 'Linux':\n",
    "    plt.rcParams['font.family'] = 'Noto Color Emoji'  # if installed\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(('.csv', '.txt')):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path, sep=';', header=None, names=column_names)\n",
    "        df['source_file'] = filename\n",
    "        df_list.append(df)\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], utc=True).dt.tz_convert('America/New_York')\n",
    "\n",
    "df = df.drop_duplicates(subset='datetime', keep='first').reset_index(drop=True)\n",
    "df = df.sort_values('datetime').reset_index(drop=True)\n",
    "df[['open', 'high', 'low', 'close', 'volume']] = df[['open', 'high', 'low', 'close', 'volume']].astype(float)\n",
    "\n",
    "# Base time features\n",
    "df['hour'] = df['datetime'].dt.hour + df['datetime'].dt.minute / 60\n",
    "df['minute'] = df['datetime'].dt.minute\n",
    "df['day_of_week'] = df['datetime'].dt.dayofweek  # 0 = Monday\n",
    "\n",
    "# Custom session flags (adjust if needed)       # Regular Trading Hours\n",
    "df['is_premarket'] = df['hour'].between(7, 9.5)\n",
    "df['is_lunch'] = df['hour'].between(11.5, 13.5)\n",
    "df['is_postmarket'] = df['hour'].between(15.5, 20)\n",
    "df['is_after_hours'] = df['hour'].between(20, 23.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize features or indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EMA / Bollinger / RSI / ATR / VWAP / OBV ===\n",
    "df['ema_9'] = EMAIndicator(df['close'], window=9).ema_indicator()\n",
    "df['ema_21'] = EMAIndicator(df['close'], window=21).ema_indicator()\n",
    "\n",
    "bb = BollingerBands(df['close'], window=20, window_dev=2)\n",
    "df['boll_upper'] = bb.bollinger_hband()\n",
    "df['boll_lower'] = bb.bollinger_lband()\n",
    "df['boll_width'] = df['boll_upper'] - df['boll_lower']\n",
    "\n",
    "df['rsi_14'] = RSIIndicator(df['close'], window=14).rsi()\n",
    "df['atr_14'] = AverageTrueRange(df['high'], df['low'], df['close'], window=14).average_true_range()\n",
    "df['atr_5'] = AverageTrueRange(df['high'], df['low'], df['close'], window=5).average_true_range()\n",
    "\n",
    "df['vwap'] = VolumeWeightedAveragePrice(\n",
    "    high=df['high'], low=df['low'], close=df['close'], volume=df['volume'], window=14\n",
    ").volume_weighted_average_price()\n",
    "\n",
    "df['obv'] = OnBalanceVolumeIndicator(df['close'], df['volume']).on_balance_volume()\n",
    "\n",
    "# === MACD and histogram ===\n",
    "macd = MACD(df['close'])\n",
    "df['macd'] = macd.macd()\n",
    "df['macd_diff'] = macd.macd_diff()\n",
    "\n",
    "# === Momentum flags ===\n",
    "df['momentum_up'] = (df['macd_diff'] > 0).astype(int)\n",
    "df['momentum_down'] = (df['macd_diff'] < 0).astype(int)\n",
    "\n",
    "# === RSI level flags ===\n",
    "df['rsi_overbought'] = (df['rsi_14'] > 70).astype(int)\n",
    "df['rsi_oversold'] = (df['rsi_14'] < 30).astype(int)\n",
    "df['rsi_midrange'] = ((df['rsi_14'] >= 30) & (df['rsi_14'] <= 70)).astype(int)\n",
    "df['rsi_neutral_around_50'] = ((df['rsi_14'] > 45) & (df['rsi_14'] < 55)).astype(int)\n",
    "\n",
    "# === Bollinger breakout ===\n",
    "df['boll_breakout_up'] = (df['close'] > df['boll_upper']).astype(int)\n",
    "df['boll_breakout_down'] = (df['close'] < df['boll_lower']).astype(int)\n",
    "\n",
    "# === VWAP crossover ===\n",
    "df['vwap_cross_above'] = (df['close'] > df['vwap']).astype(int)\n",
    "df['vwap_cross_below'] = (df['close'] < df['vwap']).astype(int)\n",
    "\n",
    "# === RSI short-term ===\n",
    "df['rsi_5'] = RSIIndicator(df['close'], window=5).rsi()\n",
    "for i in range(1, 6):\n",
    "    df[f'rsi_5_tminus{i}'] = df['rsi_5'].shift(i)\n",
    "\n",
    "# === EMA slope ===\n",
    "df['ema_9_slope'] = df['ema_9'].diff()\n",
    "for i in range(1, 6):\n",
    "    df[f'ema_9_slope_tminus{i}'] = df['ema_9_slope'].shift(i)\n",
    "\n",
    "# === Return series ===\n",
    "df['return_1'] = df['close'].pct_change(1)\n",
    "for i in range(1, 6):\n",
    "    df[f'return_1_tminus{i}'] = df['return_1'].shift(i)\n",
    "\n",
    "# === MACD histogram series ===\n",
    "for i in range(1, 6):\n",
    "    df[f'macd_diff_tminus{i}'] = df['macd_diff'].shift(i)\n",
    "\n",
    "# === Support/Resistance via rolling extremes ===\n",
    "df['resistance_lookback'] = df['high'].rolling(20).max()\n",
    "df['support_lookback'] = df['low'].rolling(20).min()\n",
    "df['dist_to_resistance'] = df['resistance_lookback'] - df['close']\n",
    "df['dist_to_support'] = df['close'] - df['support_lookback']\n",
    "\n",
    "# === Volume delta (approximate placeholder) ===\n",
    "df['volume_delta_ema'] = df['volume'].diff().ewm(span=14).mean()\n",
    "\n",
    "# === RSI z-score and normalization ===\n",
    "df['rsi_14_zscore'] = (df['rsi_14'] - df['rsi_14'].rolling(50).mean()) / df['rsi_14'].rolling(50).std()\n",
    "df['rsi_14_norm'] = df['rsi_14'] / 100.0\n",
    "\n",
    "# === MACD z-score ===\n",
    "df['macd_z'] = (df['macd'] - df['macd'].rolling(50).mean()) / df['macd'].rolling(50).std()\n",
    "\n",
    "# === Return demeaned ===\n",
    "df['return_1_demeaned'] = df['return_1'] - df['return_1'].rolling(50).mean()\n",
    "\n",
    "tree_based_features = [\n",
    "    'ema_9', 'ema_21',\n",
    "    'boll_upper', 'boll_lower', 'boll_width',\n",
    "    'rsi_14', 'macd', 'macd_diff',\n",
    "    'vwap', 'obv', 'atr_14',\n",
    "    'momentum_up', 'momentum_down',\n",
    "    'rsi_overbought', 'rsi_oversold', 'rsi_midrange', 'rsi_neutral_around_50',\n",
    "    'boll_breakout_up', 'boll_breakout_down',\n",
    "    'vwap_cross_above', 'vwap_cross_below'\n",
    "]\n",
    "\n",
    "sequential_features = [\n",
    "    # RSI over time\n",
    "    'rsi_5_tminus1', 'rsi_5_tminus2', 'rsi_5_tminus3', 'rsi_5_tminus4', 'rsi_5_tminus5',\n",
    "    \n",
    "    # EMA slope over time\n",
    "    'ema_9_slope_tminus1', 'ema_9_slope_tminus2', 'ema_9_slope_tminus3', 'ema_9_slope_tminus4', 'ema_9_slope_tminus5',\n",
    "    \n",
    "    # Raw returns over time\n",
    "    'return_1_tminus1', 'return_1_tminus2', 'return_1_tminus3', 'return_1_tminus4', 'return_1_tminus5',\n",
    "\n",
    "    # MACD histogram series\n",
    "    'macd_diff_tminus1', 'macd_diff_tminus2', 'macd_diff_tminus3', 'macd_diff_tminus4', 'macd_diff_tminus5',\n",
    "\n",
    "    # Support/Resistance proximity\n",
    "    'dist_to_resistance', 'dist_to_support',\n",
    "\n",
    "    # Volume delta placeholder (e.g. volume_diff or custom calc)\n",
    "    'volume_delta_ema'\n",
    "]\n",
    "\n",
    "linear_features = [\n",
    "    'rsi_14_zscore', 'rsi_14_norm',\n",
    "    'macd_z',  # z-score of MACD\n",
    "    'boll_width',  # could also use boll_pct (price position in bands)\n",
    "    'return_1_demeaned',\n",
    "    \n",
    "    # One-hot style binary flags\n",
    "    'momentum_up', 'momentum_down',\n",
    "    'rsi_overbought', 'rsi_oversold', 'rsi_neutral_around_50'\n",
    "]\n",
    "all_features = []\n",
    "all_features += linear_features\n",
    "all_features += sequential_features\n",
    "all_features += tree_based_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_key(ts: pd.Timestamp) -> pd.Timestamp:\n",
    "    # shift back 18 h, then floor to midnight to get a unique session “date”\n",
    "    return (ts - timedelta(hours=18)).normalize()\n",
    "\n",
    "def is_same_session(start_time: pd.Timestamp, end_time: pd.Timestamp) -> bool:\n",
    "    return session_key(start_time) == session_key(end_time)\n",
    "\n",
    "param_grid_strategy = {\n",
    "    'SL_ATR_MULT': [1.0, 1.5, 0.5],\n",
    "    'TP_ATR_MULT': [2.0, 3.0, 4.0],\n",
    "    'TRAIL_START_MULT': [0.5, 1.0],\n",
    "    'TRAIL_STOP_MULT': [0.5, 1.0],\n",
    "    'TICK_VALUE': [5], \n",
    "}\n",
    "\n",
    "keys, values = zip(*param_grid_strategy.items())\n",
    "combinations = [dict(zip(keys, v)) for v in product(*values)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avoid functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avoid_news(row):\n",
    "    ts = row[\"datetime\"]\n",
    "    return any(start <= ts <= end for (start, end) in news_windows)\n",
    "\n",
    "def avoid_hour_18_19(row):\n",
    "    \"\"\"\n",
    "    Avoid trading in the first hour of the session (18:00 to 19:00 inclusive).\n",
    "    \"\"\"\n",
    "    if not pd.api.types.is_datetime64_any_dtype(row['datetime']):\n",
    "        return False\n",
    "    hour = row['datetime'].hour\n",
    "    return hour == 18\n",
    "\n",
    "avoid_funcs = {\n",
    "    #'avoid_hour_18_19': avoid_hour_18_19\n",
    "    #'news_window': avoid_news,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regression Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression(\n",
    "    X_test, preds_stack, preds_cnn, labeled, df,\n",
    "    avoid_funcs,\n",
    "    SL_ATR_MULT, TP_ATR_MULT, TRAIL_START_MULT, TRAIL_STOP_MULT, TICK_VALUE,\n",
    "    is_same_session,\n",
    "    long_thresh,\n",
    "    short_thresh,\n",
    "    base_contracts=1,\n",
    "    max_contracts=5,\n",
    "    skip_weak_conf=False,\n",
    "    weak_conf_zscore=0.2,\n",
    "    stack_weight=0.4,\n",
    "    cnn_weight=0.3\n",
    "):\n",
    "    temp_trades_data = []\n",
    "    skipped_trades = 0\n",
    "    avoid_hits = defaultdict(int)\n",
    "    long_trades = 0\n",
    "    short_trades = 0\n",
    "\n",
    "    i = 0\n",
    "    X_test_idx = X_test.index.to_list()\n",
    "    combined_preds = stack_weight * np.array(preds_stack) + cnn_weight * np.array(preds_cnn)\n",
    "    preds_array = combined_preds\n",
    "\n",
    "    # === Calculate z-score confidence ===\n",
    "    zscores = (preds_array - preds_array.mean()) / (preds_array.std() + 1e-9)\n",
    "    zscores = np.clip(zscores, -3.0, 3.0)\n",
    "    conf_scores = np.clip(np.abs(zscores), 0, 2.0)\n",
    "    position_sizes = base_contracts + (max_contracts - base_contracts) * (conf_scores / 2.0)\n",
    "    position_sizes = np.round(position_sizes, 2)\n",
    "\n",
    "\n",
    "    for i, idx in enumerate(X_test_idx):\n",
    "        if idx not in labeled.index:\n",
    "            skipped_trades += 1\n",
    "            continue\n",
    "        row = labeled.loc[idx]\n",
    "\n",
    "        if idx + 1 >= len(df):\n",
    "            skipped_trades += 1\n",
    "            continue\n",
    "\n",
    "        vol_adj_pred = preds_array[i]\n",
    "        conf = conf_scores[i]\n",
    "        size = position_sizes[i]\n",
    "        \n",
    "        # # Skip weak confidence signals if enabled\n",
    "        # if skip_weak_conf and conf < weak_conf_zscore:\n",
    "        #     skipped_trades += 1\n",
    "        #     continue\n",
    "\n",
    "        if vol_adj_pred >= long_thresh:  # TP or Strong TP\n",
    "            side = 'long'\n",
    "            long_trades += 1\n",
    "        elif vol_adj_pred <= short_thresh:  # SL side match\n",
    "            side = 'short'\n",
    "            short_trades += 1\n",
    "        else:\n",
    "            skipped_trades += 1\n",
    "            continue  # classifier disagrees\n",
    "\n",
    "        # Trade filters\n",
    "        skip_trade = False\n",
    "        for name, f in avoid_funcs.items():\n",
    "            try:\n",
    "                if f(row):\n",
    "                    avoid_hits[name] += 1\n",
    "                    skip_trade = True\n",
    "            except:\n",
    "                continue\n",
    "        if skip_trade:\n",
    "            skipped_trades += 1\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # --- Trade Simulation ---\n",
    "        entry_price = df.loc[idx + 1, 'open']\n",
    "        entry_time = df.loc[idx + 1, 'datetime']\n",
    "        atr = row['atr_14']\n",
    "\n",
    "        # Stop Loss (fixed volatility-based)\n",
    "        sl_price = entry_price - SL_ATR_MULT * atr if side == 'long' else entry_price + SL_ATR_MULT * atr\n",
    "\n",
    "        # Take Profit (dynamic, from model prediction, clipped)\n",
    "        expected_move = abs(vol_adj_pred) * entry_price\n",
    "        min_tp = 0.001 * entry_price  # minimum 0.1% move\n",
    "        max_tp = TP_ATR_MULT * atr\n",
    "        tp_move = np.clip(expected_move, min_tp, max_tp)\n",
    "        tp_price = entry_price + tp_move if side == 'long' else entry_price - tp_move\n",
    "\n",
    "        # Trailing logic\n",
    "        trail_trigger = entry_price + TRAIL_START_MULT * atr if side == 'long' else entry_price - TRAIL_START_MULT * atr\n",
    "        trail_stop = None\n",
    "\n",
    "        max_price, min_price = entry_price, entry_price\n",
    "        exit_price, exit_time = None, None\n",
    "\n",
    "        fwd_idx = idx + 1\n",
    "        while fwd_idx < len(df):\n",
    "            fwd_row = df.loc[fwd_idx]\n",
    "            max_price = max(max_price, fwd_row['high'])\n",
    "            min_price = min(min_price, fwd_row['low'])\n",
    "\n",
    "            if (side == 'long' and fwd_row['low'] <= sl_price) or (side == 'short' and fwd_row['high'] >= sl_price):\n",
    "                exit_price = sl_price\n",
    "                exit_time = fwd_row['datetime']\n",
    "                break\n",
    "\n",
    "            if (side == 'long' and fwd_row['high'] >= tp_price) or (side == 'short' and fwd_row['low'] <= tp_price):\n",
    "                exit_price = tp_price\n",
    "                exit_time = fwd_row['datetime']\n",
    "                break\n",
    "\n",
    "            if side == 'long' and fwd_row['high'] >= trail_trigger:\n",
    "                trail_stop = fwd_row['close'] - TRAIL_STOP_MULT * atr\n",
    "            if side == 'short' and fwd_row['low'] <= trail_trigger:\n",
    "                trail_stop = fwd_row['close'] + TRAIL_STOP_MULT * atr\n",
    "\n",
    "            if trail_stop:\n",
    "                if (side == 'long' and fwd_row['low'] <= trail_stop) or (side == 'short' and fwd_row['high'] >= trail_stop):\n",
    "                    exit_price = trail_stop\n",
    "                    exit_time = fwd_row['datetime']\n",
    "                    break\n",
    "\n",
    "            fwd_idx += 1\n",
    "\n",
    "        if exit_price is None:\n",
    "            exit_price = df.loc[len(df) - 1, 'close']\n",
    "            exit_time = df.loc[len(df) - 1, 'datetime']\n",
    "\n",
    "        if not is_same_session(entry_time, exit_time):\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        GROSS_PNL = (exit_price - entry_price) * TICK_VALUE * size if side == 'long' else (entry_price - exit_price) * TICK_VALUE * size\n",
    "        COMMISSION = 3.98 * size\n",
    "        pnl = GROSS_PNL - COMMISSION\n",
    "\n",
    "        mfe = max_price - entry_price if side == 'long' else entry_price - min_price\n",
    "        mae = entry_price - min_price if side == 'long' else max_price - entry_price\n",
    "\n",
    "        temp_trades_data.append({\n",
    "            'entry_time': entry_time,\n",
    "            'exit_time': exit_time,\n",
    "            'side': side,\n",
    "            'entry_price': entry_price,\n",
    "            'exit_price': exit_price,\n",
    "            'pnl': pnl,\n",
    "            'mfe': mfe,\n",
    "            'mae': mae,\n",
    "            'gross_pnl': GROSS_PNL,\n",
    "            'vol_adj_pred': vol_adj_pred,\n",
    "            'confidence': conf,\n",
    "            'position_size': size,\n",
    "        })\n",
    "\n",
    "        while i < len(X_test_idx) and labeled.loc[X_test_idx[i]]['datetime'] <= exit_time:\n",
    "            i += 1\n",
    "        continue\n",
    "\n",
    "    # === Metrics ===\n",
    "    results = pd.DataFrame(temp_trades_data)\n",
    "    pnl_total = results['pnl'].sum() if not results.empty else 0\n",
    "    trades = len(results)\n",
    "    win_rate = (results['pnl'] > 0).mean() if not results.empty else 0\n",
    "    expectancy = results['pnl'].mean() if not results.empty else 0\n",
    "    profit_factor = results[results['pnl'] > 0]['pnl'].sum() / abs(results[results['pnl'] < 0]['pnl'].sum()) if not results.empty and (results['pnl'] < 0).any() else np.nan\n",
    "    sharpe = results['pnl'].mean() / (results['pnl'].std() + 1e-9) * np.sqrt(trades) if trades > 1 else 0\n",
    "\n",
    "    return {\n",
    "        'pnl': pnl_total,\n",
    "        'trades': trades,\n",
    "        'win_rate': win_rate,\n",
    "        'expectancy': expectancy,\n",
    "        'profit_factor': profit_factor,\n",
    "        'sharpe': sharpe,\n",
    "        'long_trades': long_trades,\n",
    "        'short_trades': short_trades,\n",
    "        'avoid_hits': dict(avoid_hits),\n",
    "        'threshold': long_thresh,\n",
    "        'results': results\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(\n",
    "    X_test, preds_stack, preds_xgboost, labeled, df,\n",
    "    avoid_funcs,\n",
    "    SL_ATR_MULT, TP_ATR_MULT, TRAIL_START_MULT, TRAIL_STOP_MULT, TICK_VALUE,\n",
    "    is_same_session,\n",
    "    base_contracts=1,\n",
    "    max_contracts=5,\n",
    "    skip_weak_conf=False,\n",
    "    weak_conf_zscore=0.2,\n",
    "    stack_weight=0.6,\n",
    "    xboost_weight=0.4\n",
    "):\n",
    "    temp_trades_data = []\n",
    "    skipped_trades = 0\n",
    "    avoid_hits = defaultdict(int)\n",
    "    long_trades = 0\n",
    "    short_trades = 0\n",
    "\n",
    "    i = 0\n",
    "    X_test_idx = X_test.index.to_list()\n",
    "    combined_preds = stack_weight * np.array(preds_stack) + xboost_weight * np.array(preds_xgboost)\n",
    "    preds_array = np.round(combined_preds).astype(int)\n",
    "\n",
    "    # === Calculate z-score confidence ===\n",
    "    zscores = (combined_preds - combined_preds.mean()) / (combined_preds.std() + 1e-9)\n",
    "    zscores = np.clip(zscores, -3.0, 3.0)\n",
    "    conf_scores = np.clip(np.abs(zscores), 0, 2.0)\n",
    "    position_sizes = base_contracts + (max_contracts - base_contracts) * (conf_scores / 2.0)\n",
    "    position_sizes = np.round(position_sizes, 2)\n",
    "\n",
    "    for i, idx in enumerate(X_test_idx):\n",
    "        #idx = X_test_idx[i]\n",
    "        row = labeled.loc[idx]\n",
    "\n",
    "        if idx + 1 >= len(df):\n",
    "            skipped_trades += 1\n",
    "            continue\n",
    "\n",
    "        pred_class = preds_array[i]\n",
    "        conf = conf_scores[i]\n",
    "        size = position_sizes[i]\n",
    "\n",
    "        # Skip weak confidence signals if enabled\n",
    "        if skip_weak_conf and conf < weak_conf_zscore:\n",
    "            skipped_trades += 1\n",
    "            continue\n",
    "\n",
    "        if pred_class > 0:\n",
    "            side = 'long'\n",
    "            long_trades += 1\n",
    "        elif pred_class < 0:\n",
    "            side = 'short'\n",
    "            short_trades += 1\n",
    "        else:\n",
    "            skipped_trades += 1\n",
    "            continue\n",
    "\n",
    "        # Trade filters\n",
    "        skip_trade = False\n",
    "        for name, f in avoid_funcs.items():\n",
    "            try:\n",
    "                if f(row):\n",
    "                    avoid_hits[name] += 1\n",
    "                    skip_trade = True\n",
    "            except:\n",
    "                continue\n",
    "        if skip_trade:\n",
    "            skipped_trades += 1\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # --- Trade Simulation ---\n",
    "        entry_price = df.loc[idx + 1, 'open']\n",
    "        entry_time = df.loc[idx + 1, 'datetime']\n",
    "        atr = row['atr_5']\n",
    "\n",
    "        # Stop Loss (fixed volatility-based)\n",
    "        sl_price = entry_price - SL_ATR_MULT * atr if side == 'long' else entry_price + SL_ATR_MULT * atr\n",
    "\n",
    "        sl_price = entry_price - SL_ATR_MULT * atr if side == 'long' else entry_price + SL_ATR_MULT * atr\n",
    "        tp_price = entry_price + TP_ATR_MULT * atr if side == 'long' else entry_price - TP_ATR_MULT * atr\n",
    "        trail_trigger = entry_price + TRAIL_START_MULT * atr if side == 'long' else entry_price - TRAIL_START_MULT * atr\n",
    "        trail_stop = None\n",
    "\n",
    "        max_price, min_price = entry_price, entry_price\n",
    "        exit_price, exit_time = None, None\n",
    "\n",
    "        fwd_idx = idx + 1\n",
    "        while fwd_idx < len(df):\n",
    "            fwd_row = df.loc[fwd_idx]\n",
    "            max_price = max(max_price, fwd_row['high'])\n",
    "            min_price = min(min_price, fwd_row['low'])\n",
    "\n",
    "            if (side == 'long' and fwd_row['low'] <= sl_price) or (side == 'short' and fwd_row['high'] >= sl_price):\n",
    "                exit_price = sl_price\n",
    "                exit_time = fwd_row['datetime']\n",
    "                break\n",
    "\n",
    "            if (side == 'long' and fwd_row['high'] >= tp_price) or (side == 'short' and fwd_row['low'] <= tp_price):\n",
    "                exit_price = tp_price\n",
    "                exit_time = fwd_row['datetime']\n",
    "                break\n",
    "\n",
    "            if side == 'long' and fwd_row['high'] >= trail_trigger:\n",
    "                trail_stop = fwd_row['close'] - TRAIL_STOP_MULT * atr\n",
    "            if side == 'short' and fwd_row['low'] <= trail_trigger:\n",
    "                trail_stop = fwd_row['close'] + TRAIL_STOP_MULT * atr\n",
    "\n",
    "            if trail_stop:\n",
    "                if (side == 'long' and fwd_row['low'] <= trail_stop) or (side == 'short' and fwd_row['high'] >= trail_stop):\n",
    "                    exit_price = trail_stop\n",
    "                    exit_time = fwd_row['datetime']\n",
    "                    break\n",
    "\n",
    "            fwd_idx += 1\n",
    "\n",
    "        if exit_price is None:\n",
    "            exit_price = df.loc[len(df) - 1, 'close']\n",
    "            exit_time = df.loc[len(df) - 1, 'datetime']\n",
    "\n",
    "        if not is_same_session(entry_time, exit_time):\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        GROSS_PNL = (exit_price - entry_price) * TICK_VALUE * size if side == 'long' else (entry_price - exit_price) * TICK_VALUE * size\n",
    "        COMMISSION = 3.98 * size\n",
    "        pnl = GROSS_PNL - COMMISSION\n",
    "\n",
    "        mfe = max_price - entry_price if side == 'long' else entry_price - min_price\n",
    "        mae = entry_price - min_price if side == 'long' else max_price - entry_price\n",
    "\n",
    "        temp_trades_data.append({\n",
    "            'entry_time': entry_time,\n",
    "            'exit_time': exit_time,\n",
    "            'side': side,\n",
    "            'entry_price': entry_price,\n",
    "            'exit_price': exit_price,\n",
    "            'pnl': pnl,\n",
    "            'mfe': mfe,\n",
    "            'mae': mae,\n",
    "            'gross_pnl': GROSS_PNL,\n",
    "            'pred_class': pred_class,\n",
    "            'confidence': conf,\n",
    "            'position_size': size,\n",
    "        })\n",
    "\n",
    "        while i < len(X_test_idx) and labeled.loc[X_test_idx[i]]['datetime'] <= exit_time:\n",
    "            i += 1\n",
    "        continue\n",
    "\n",
    "    # === Metrics ===\n",
    "    results = pd.DataFrame(temp_trades_data)\n",
    "    pnl_total = results['pnl'].sum() if not results.empty else 0\n",
    "    trades = len(results)\n",
    "    win_rate = (results['pnl'] > 0).mean() if not results.empty else 0\n",
    "    expectancy = results['pnl'].mean() if not results.empty else 0\n",
    "    profit_factor = results[results['pnl'] > 0]['pnl'].sum() / abs(results[results['pnl'] < 0]['pnl'].sum()) if not results.empty and (results['pnl'] < 0).any() else np.nan\n",
    "    sharpe = results['pnl'].mean() / (results['pnl'].std() + 1e-9) * np.sqrt(trades) if trades > 1 else 0\n",
    "\n",
    "    return {\n",
    "        'pnl': pnl_total,\n",
    "        'trades': trades,\n",
    "        'win_rate': win_rate,\n",
    "        'expectancy': expectancy,\n",
    "        'profit_factor': profit_factor,\n",
    "        'sharpe': sharpe,\n",
    "        'long_trades': long_trades,\n",
    "        'short_trades': short_trades,\n",
    "        'avoid_hits': dict(avoid_hits),\n",
    "        'results': results\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combo Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_combo(\n",
    "    X_test, preds_reg_stack, preds_reg_cnn,\n",
    "    preds_class_stack, preds_class_xgboost,\n",
    "    labeled, df,\n",
    "    avoid_funcs,\n",
    "    SL_ATR_MULT, TP_ATR_MULT, TRAIL_START_MULT, TRAIL_STOP_MULT, TICK_VALUE,\n",
    "    is_same_session,\n",
    "    long_threshold,\n",
    "    short_threshold,\n",
    "    base_contracts=1,\n",
    "    max_contracts=5,\n",
    "    skip_weak_conf=False,\n",
    "    weak_conf_zscore=0.2,\n",
    "    reg_weights=(0.5, 0.5),  # stack, cnn, lgbm\n",
    "    class_weights=(0.6, 0.4)     # stack, xgboost\n",
    "):\n",
    "    temp_trades_data = []\n",
    "    skipped_trades = 0\n",
    "    avoid_hits = defaultdict(int)\n",
    "    long_trades = 0\n",
    "    short_trades = 0\n",
    "\n",
    "    X_test_idx = X_test.index.to_list()\n",
    "\n",
    "    # Regression ensemble\n",
    "    reg_ensemble = (\n",
    "        reg_weights[0] * np.array(preds_reg_stack) +\n",
    "        reg_weights[1] * np.array(preds_reg_cnn)\n",
    "    )\n",
    "\n",
    "    # Classification ensemble\n",
    "    class_ensemble = np.round(\n",
    "        class_weights[0] * np.array(preds_class_stack) +\n",
    "        class_weights[1] * np.array(preds_class_xgboost)\n",
    "    ).astype(int)\n",
    "\n",
    "    # Confidence and sizing\n",
    "    zscores = (reg_ensemble - reg_ensemble.mean()) / (reg_ensemble.std() + 1e-9)\n",
    "    zscores = np.clip(zscores, -3.0, 3.0)\n",
    "    conf_scores = np.clip(np.abs(zscores), 0, 2.0)\n",
    "    position_sizes = base_contracts + (max_contracts - base_contracts) * (conf_scores / 2.0)\n",
    "    position_sizes = np.round(position_sizes, 2)\n",
    "\n",
    "    for i, idx in enumerate(X_test_idx):\n",
    "        row = labeled.loc[idx]\n",
    "        if idx + 1 >= len(df):\n",
    "            skipped_trades += 1\n",
    "            continue\n",
    "\n",
    "        reg_pred = reg_ensemble[i]\n",
    "        class_pred = class_ensemble[i]\n",
    "        conf = conf_scores[i]\n",
    "        size = position_sizes[i]\n",
    "\n",
    "        # if skip_weak_conf and conf < weak_conf_zscore:\n",
    "        #     skipped_trades += 1\n",
    "        #     continue\n",
    "\n",
    "        if any(f(row) for name, f in avoid_funcs.items()):\n",
    "            skipped_trades += 1\n",
    "            continue\n",
    "\n",
    "        # 1. Classifier decides direction (but don't update counters yet)\n",
    "        if class_pred > 0:\n",
    "            side = 'long'\n",
    "        elif class_pred < 0:\n",
    "            side = 'short'\n",
    "        else:\n",
    "            skipped_trades += 1\n",
    "            continue\n",
    "\n",
    "        # 2. Check if regression agrees\n",
    "        reg_agrees = (side == 'long' and reg_pred > long_threshold) or (side == 'short' and reg_pred < short_threshold)\n",
    "        if not reg_agrees:\n",
    "            skipped_trades += 1\n",
    "            continue\n",
    "\n",
    "        # 3. Now it's safe to count the trade\n",
    "        if side == 'long':\n",
    "            long_trades += 1\n",
    "        else:\n",
    "            short_trades += 1\n",
    "\n",
    "        entry_price = df.loc[idx + 1, 'open']\n",
    "        entry_time = df.loc[idx + 1, 'datetime']\n",
    "        atr = row['atr_5']\n",
    "\n",
    "        sl_price = entry_price - SL_ATR_MULT * atr if side == 'long' else entry_price + SL_ATR_MULT * atr\n",
    "        expected_move = abs(reg_pred) * entry_price\n",
    "        tp_move = np.clip(expected_move, 0.001 * entry_price, TP_ATR_MULT * atr)\n",
    "        tp_price = entry_price + tp_move if side == 'long' else entry_price - tp_move\n",
    "        trail_trigger = entry_price + TRAIL_START_MULT * atr if side == 'long' else entry_price - TRAIL_START_MULT * atr\n",
    "\n",
    "        max_price, min_price = entry_price, entry_price\n",
    "        exit_price, exit_time = None, None\n",
    "        trail_stop = None\n",
    "\n",
    "        fwd_idx = idx + 1\n",
    "        while fwd_idx < len(df):\n",
    "            fwd_row = df.loc[fwd_idx]\n",
    "            max_price = max(max_price, fwd_row['high'])\n",
    "            min_price = min(min_price, fwd_row['low'])\n",
    "\n",
    "            if (side == 'long' and fwd_row['low'] <= sl_price) or (side == 'short' and fwd_row['high'] >= sl_price):\n",
    "                exit_price = sl_price\n",
    "                exit_time = fwd_row['datetime']\n",
    "                break\n",
    "\n",
    "            if (side == 'long' and fwd_row['high'] >= tp_price) or (side == 'short' and fwd_row['low'] <= tp_price):\n",
    "                exit_price = tp_price\n",
    "                exit_time = fwd_row['datetime']\n",
    "                break\n",
    "\n",
    "            if side == 'long' and fwd_row['high'] >= trail_trigger:\n",
    "                trail_stop = fwd_row['close'] - TRAIL_STOP_MULT * atr\n",
    "            if side == 'short' and fwd_row['low'] <= trail_trigger:\n",
    "                trail_stop = fwd_row['close'] + TRAIL_STOP_MULT * atr\n",
    "\n",
    "            if trail_stop:\n",
    "                if (side == 'long' and fwd_row['low'] <= trail_stop) or (side == 'short' and fwd_row['high'] >= trail_stop):\n",
    "                    exit_price = trail_stop\n",
    "                    exit_time = fwd_row['datetime']\n",
    "                    break\n",
    "\n",
    "            fwd_idx += 1\n",
    "\n",
    "        if exit_price is None:\n",
    "            exit_price = df.loc[len(df) - 1, 'close']\n",
    "            exit_time = df.loc[len(df) - 1, 'datetime']\n",
    "\n",
    "        if not is_same_session(entry_time, exit_time):\n",
    "            continue\n",
    "\n",
    "        gross_pnl = (exit_price - entry_price) * TICK_VALUE * size if side == 'long' else (entry_price - exit_price) * TICK_VALUE * size\n",
    "        commission = 3.98 * size\n",
    "        pnl = gross_pnl - commission\n",
    "        mfe = max_price - entry_price if side == 'long' else entry_price - min_price\n",
    "        mae = entry_price - min_price if side == 'long' else max_price - entry_price\n",
    "\n",
    "        temp_trades_data.append({\n",
    "            'entry_time': entry_time,\n",
    "            'exit_time': exit_time,\n",
    "            'side': side,\n",
    "            'entry_price': entry_price,\n",
    "            'exit_price': exit_price,\n",
    "            'pnl': pnl,\n",
    "            'mfe': mfe,\n",
    "            'mae': mae,\n",
    "            'gross_pnl': gross_pnl,\n",
    "            'reg_pred': reg_pred,\n",
    "            'class_pred': class_pred,\n",
    "            'confidence': conf,\n",
    "            'position_size': size,\n",
    "        })\n",
    "\n",
    "    results = pd.DataFrame(temp_trades_data)\n",
    "    pnl_total = results['pnl'].sum() if not results.empty else 0\n",
    "    trades = len(results)\n",
    "    win_rate = (results['pnl'] > 0).mean() if not results.empty else 0\n",
    "    expectancy = results['pnl'].mean() if not results.empty else 0\n",
    "    profit_factor = results[results['pnl'] > 0]['pnl'].sum() / abs(results[results['pnl'] < 0]['pnl'].sum()) if not results.empty and (results['pnl'] < 0).any() else np.nan\n",
    "    sharpe = results['pnl'].mean() / (results['pnl'].std() + 1e-9) * np.sqrt(trades) if trades > 1 else 0\n",
    "\n",
    "    return {\n",
    "        'pnl': pnl_total,\n",
    "        'trades': trades,\n",
    "        'win_rate': win_rate,\n",
    "        'expectancy': expectancy,\n",
    "        'profit_factor': profit_factor,\n",
    "        'sharpe': sharpe,\n",
    "        'long_trades': long_trades,\n",
    "        'short_trades': short_trades,\n",
    "        'avoid_hits': dict(avoid_hits),\n",
    "        'results': results\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_return_labels(\n",
    "    df: pd.DataFrame,\n",
    "    lookahead: int,\n",
    "    is_same_session_fn,\n",
    "    use_vol_norm: bool = True,\n",
    "    vol_col: str = 'atr_14',\n",
    "    cap_outliers: bool = True,\n",
    "    cap_percentile: float = 99.9\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Computes log-returns and optionally volatility-adjusted returns for regression modeling.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with at least ['datetime', 'close', vol_col]\n",
    "    - lookahead: Number of bars to look ahead\n",
    "    - is_same_session_fn: function that returns True if two timestamps are in the same session\n",
    "    - use_vol_norm: whether to normalize return by volatility (ATR or std)\n",
    "    - vol_col: column to use for volatility adjustment\n",
    "    - cap_outliers: whether to cap large return outliers (Winsorize)\n",
    "    - cap_percentile: percentile threshold for capping\n",
    "\n",
    "    Returns:\n",
    "    - df_labeled: DataFrame with columns: ['log_return', 'vol_adj_return']\n",
    "    \"\"\"\n",
    "    log_returns = []\n",
    "    vol_adj_returns = []\n",
    "    valid_idxs = []\n",
    "\n",
    "    for i in range(len(df) - lookahead):\n",
    "        t0 = df['datetime'].iloc[i]\n",
    "        t1 = df['datetime'].iloc[i + lookahead]\n",
    "\n",
    "        if not is_same_session_fn(t0, t1):\n",
    "            continue\n",
    "\n",
    "        entry_price = df['close'].iloc[i]\n",
    "        future_price = df['close'].iloc[i + lookahead]\n",
    "        vol = df[vol_col].iloc[i] if use_vol_norm else 1.0\n",
    "\n",
    "        if entry_price <= 0 or pd.isna(future_price) or pd.isna(vol) or vol <= 0:\n",
    "            continue\n",
    "\n",
    "        log_ret = np.log(future_price / entry_price)\n",
    "        vol_adj_ret = log_ret / vol\n",
    "\n",
    "        log_returns.append(log_ret)\n",
    "        vol_adj_returns.append(vol_adj_ret)\n",
    "        valid_idxs.append(i)\n",
    "\n",
    "    df_labeled = df.iloc[valid_idxs].copy()\n",
    "    df_labeled['log_return'] = log_returns\n",
    "    df_labeled['vol_adj_return'] = vol_adj_returns\n",
    "\n",
    "    # Winsorize if needed\n",
    "    if cap_outliers:\n",
    "        upper = np.percentile(df_labeled['log_return'], cap_percentile)\n",
    "        lower = np.percentile(df_labeled['log_return'], 100 - cap_percentile)\n",
    "        df_labeled['log_return'] = df_labeled['log_return'].clip(lower, upper)\n",
    "\n",
    "        upper_vol = np.percentile(df_labeled['vol_adj_return'], cap_percentile)\n",
    "        lower_vol = np.percentile(df_labeled['vol_adj_return'], 100 - cap_percentile)\n",
    "        df_labeled['vol_adj_return'] = df_labeled['vol_adj_return'].clip(lower_vol, upper_vol)\n",
    "\n",
    "    return df_labeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_triple_barrier_labels(\n",
    "    df: pd.DataFrame,\n",
    "    lookahead: int,\n",
    "    is_same_session_fn,\n",
    "    atr_col: str = 'atr_14',\n",
    "    sl_atr_mult: float = 1.0,\n",
    "    tp_atr_mult: float = 1.0,\n",
    "    strong_tp_mult: float = 2.0,\n",
    "    strong_sl_mult: float = 2.0,\n",
    "    min_atr_threshold: float = 0.01  # optional filter to skip low-volatility bars\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Assigns classification labels using the triple-barrier method:\n",
    "    - +2: Strong take-profit hit (e.g., 2x ATR)\n",
    "    - +1: Normal take-profit hit (1x ATR)\n",
    "    -  0: Neither barrier hit within lookahead window\n",
    "    - -1: Normal stop-loss hit (1x ATR)\n",
    "    - -2: Strong SL hit (2x ATR)\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with ['datetime', 'close', 'high', 'low', atr_col]\n",
    "    - lookahead: number of bars to look ahead (the vertical barrier)\n",
    "    - is_same_session_fn: function that validates two datetime values are in same trading session\n",
    "    - atr_col: column name to use for ATR values\n",
    "    - *_mult: multipliers to define barrier thresholds\n",
    "    - min_atr_threshold: skip labeling if ATR is too low (prevents noise from low-vol zones)\n",
    "\n",
    "    Returns:\n",
    "    - df_out: DataFrame with an additional column: 'triple_barrier_label'\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    valid_idxs = []\n",
    "\n",
    "    for i in range(len(df) - lookahead):\n",
    "        entry_time = df['datetime'].iloc[i]\n",
    "        exit_time = df['datetime'].iloc[i + lookahead]\n",
    "\n",
    "        if not is_same_session_fn(entry_time, exit_time):\n",
    "            continue\n",
    "\n",
    "        entry_price = df['close'].iloc[i]\n",
    "        atr = df[atr_col].iloc[i]\n",
    "\n",
    "        # Filter out low volatility regimes\n",
    "        if pd.isna(entry_price) or pd.isna(atr) or atr < min_atr_threshold:\n",
    "            continue\n",
    "\n",
    "        # Define price barriers\n",
    "        tp = entry_price + tp_atr_mult * atr\n",
    "        sl = entry_price - sl_atr_mult * atr\n",
    "        strong_tp = entry_price + strong_tp_mult * atr\n",
    "        strong_sl = entry_price - strong_sl_mult * atr\n",
    "\n",
    "        future = df.iloc[i+1 : i+1+lookahead]\n",
    "        label = 0  # default: vertical barrier hit first\n",
    "\n",
    "        for _, row in future.iterrows():\n",
    "            high = row['high']\n",
    "            low = row['low']\n",
    "\n",
    "            if low <= strong_sl:\n",
    "                label = -2\n",
    "                break\n",
    "            elif high >= strong_tp:\n",
    "                label = +2\n",
    "                break\n",
    "            elif low <= sl:\n",
    "                label = -1\n",
    "                break\n",
    "            elif high >= tp:\n",
    "                label = +1\n",
    "                break\n",
    "\n",
    "        labels.append(label)\n",
    "        valid_idxs.append(i)\n",
    "\n",
    "    df_out = df.iloc[valid_idxs].copy()\n",
    "    df_out['triple_barrier_label'] = labels\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ File labeled_data_5_session_less.parquet already exists. Skipping...\n",
      "⏭️ File labeled_data_10_session_less.parquet already exists. Skipping...\n",
      "⏭️ File labeled_data_20_session_less.parquet already exists. Skipping...\n"
     ]
    }
   ],
   "source": [
    "lookahead_values = [5, 10, 20]\n",
    "\n",
    "def label_and_save(lookahead):\n",
    "    df_session = df.copy()\n",
    "    print(f\"Initial rows: {len(df_session)}\")\n",
    "\n",
    "    labeled_regression = compute_log_return_labels(\n",
    "        df=df_session,\n",
    "        lookahead=lookahead,\n",
    "        is_same_session_fn=is_same_session,\n",
    "        use_vol_norm= True,\n",
    "        vol_col='atr_14',\n",
    "        cap_outliers=True,\n",
    "        cap_percentile=99.9\n",
    "    )\n",
    "    print(f\"➤ Rows after future_return: {len(labeled_regression)} | Dropped: {len(df_session) - len(labeled_regression)}\")\n",
    "\n",
    "\n",
    "    labeled_class = compute_triple_barrier_labels(\n",
    "        df=df_session,\n",
    "        lookahead=lookahead,\n",
    "        is_same_session_fn=is_same_session,\n",
    "        atr_col='atr_14',\n",
    "        sl_atr_mult=1.0,\n",
    "        tp_atr_mult=1.0,\n",
    "        strong_tp_mult=2.0,\n",
    "        strong_sl_mult=2.0,\n",
    "        min_atr_threshold=0.01\n",
    "    )\n",
    "    print(f\"➤ Rows after triple_barrier_label: {len(labeled_class)} | Dropped: {len(df_session) - len(labeled_class)}\")\n",
    "\n",
    "\n",
    "    df_combined = labeled_regression.merge(labeled_class[['datetime', 'triple_barrier_label']], on='datetime', how='left')\n",
    "    print(f\"➤ Rows after merging: {len(df_combined)}\")\n",
    "    print(f\"➤ triple_barrier_label NaNs after merge: {df_combined['triple_barrier_label'].isna().sum()}\")\n",
    "\n",
    "    rows_before_final = len(df_combined)\n",
    "    df_final = df_combined.dropna(subset=['vol_adj_return', 'log_return', 'triple_barrier_label'] + all_features)\n",
    "    print(f\"➤ Rows after final drop: {len(df_final)} | Dropped: {rows_before_final - len(df_final)}\")\n",
    "\n",
    "    # Step 5: Save parquet\n",
    "    df_final.to_parquet(f\"labeled_data_{lookahead}_session_less.parquet\")\n",
    "    print(f\"✅ Saved labeled_data_{lookahead}_session_less.parquet with {len(df_final)} rows\")\n",
    "\n",
    "for lookahead in lookahead_values:\n",
    "    fname = f\"labeled_data_{lookahead}_session_less.parquet\"\n",
    "    if os.path.exists(fname):\n",
    "        print(f\"⏭️ File {fname} already exists. Skipping...\")\n",
    "        continue\n",
    "    print(f\"📦 Labeling {fname}...\")\n",
    "    label_and_save(lookahead)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, input_shape, units=32, dropout=0.2, lr=0.001, epochs=10, batch_size=32, verbose=0):\n",
    "        self.input_shape = input_shape\n",
    "        self.units = units\n",
    "        self.dropout = dropout\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.model = None\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(self.units, input_shape=(self.input_shape, 1)))\n",
    "        model.add(Dropout(self.dropout))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer=Adam(learning_rate=self.lr), loss='mse')\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        print(f\"🧠 [ImprovedLSTMWrapper] Starting training with {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "        X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "        self.model = self.build_model()\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose)\n",
    "        print(f\"✅ [LSTMWrapper] Finished training.\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "        return self.model.predict(X).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1DWrapper:\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = self.build_model()\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=self.input_shape))\n",
    "        model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "        model.add(GlobalAveragePooling1D())\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(1, activation='tanh'))  # outputs in [-1, 1]\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='mae')\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y, epochs=20, batch_size=128, verbose=1):\n",
    "        print(f\"\\n🔧 [CNN1DWrapper] Scaling target and starting training...\")\n",
    "        y_scaled = self.scaler.fit_transform(y.reshape(-1, 1)).ravel()\n",
    "        start = time.time()\n",
    "        self.model.fit(X, y_scaled, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "        print(f\"✅ [CNN1DWrapper] Training complete in {time.time() - start:.2f} seconds.\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        print(f\"\\n🔮 [CNN1DWrapper] Predicting on {X.shape}...\")\n",
    "        start = time.time()\n",
    "        y_scaled_pred = self.model.predict(X).ravel()\n",
    "        y_pred = self.scaler.inverse_transform(y_scaled_pred.reshape(-1, 1)).ravel()\n",
    "        print(f\"✅ [CNN1DWrapper] Prediction done in {time.time() - start:.2f} seconds.\")\n",
    "\n",
    "        print(\"🔍 Prediction Stats:\")\n",
    "        print(f\"Min: {y_pred.min():.6f} | Max: {y_pred.max():.6f}\")\n",
    "        print(f\"Mean: {y_pred.mean():.6f} | Std: {y_pred.std():.6f}\")\n",
    "\n",
    "        # Safety check for wild predictions\n",
    "        if abs(y_pred).max() > 1:\n",
    "            print(\"⚠️ Warning: Some predictions exceed ±1 — consider checking target scaling or model output activation.\")\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifierWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, input_shape, num_classes=5, epochs=10, batch_size=32, verbose=0):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.model = None\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(32, input_shape=(self.input_shape, 1)))  # fixed 32 units\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(self.num_classes, activation=\"softmax\"))\n",
    "        model.compile(\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        print(f\"🧠 [LSTMClassifierWrapper] Training on {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "        X = np.array(X).reshape((len(X), self.input_shape, 1))\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        # If multiclass and y is integer labels, one-hot encode\n",
    "        if self.num_classes > 2 and y.ndim == 1:\n",
    "            y = to_categorical(y, num_classes=self.num_classes)\n",
    "\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose)\n",
    "        print(f\"✅ [LSTMClassifierWrapper] Training complete.\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X).reshape((len(X), self.input_shape, 1))\n",
    "        probs = self.model.predict(X)\n",
    "        return np.argmax(probs, axis=1)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.array(X).reshape((len(X), self.input_shape, 1))\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overfit(model, X_tr, X_te, y_tr, y_te):\n",
    "    train_preds = model.predict(X_tr)\n",
    "    test_preds = model.predict(X_te)\n",
    "    train_mse = mean_squared_error(y_tr, train_preds)\n",
    "    test_mse = mean_squared_error(y_te, test_preds)\n",
    "    ratio = test_mse / train_mse if train_mse != 0 else float('inf')\n",
    "\n",
    "    print(f\"\\n📉 Overfitting check:\")\n",
    "    print(f\"Train MSE: {train_mse:.8f}\")\n",
    "    print(f\"Test MSE:  {test_mse:.8f}\")\n",
    "    print(f\"Overfit ratio (Test / Train): {ratio:.2f}\")\n",
    "\n",
    "    if ratio > 2.0:\n",
    "        print(\"🚨 Overfitting: Model performs poorly on unseen data.\")\n",
    "    elif ratio > 1.2:\n",
    "        print(\"⚠️ Mild overfitting: Model may be too complex.\")\n",
    "    elif ratio < 0.8:\n",
    "        print(\"⚠️ Possible underfitting: Model may be too simple.\")\n",
    "    else:\n",
    "        print(\"✅ Good generalization between train and test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_oof_predictions(models, X, y, splits):\n",
    "    \"\"\"\n",
    "    Generates out-of-fold predictions for a list of models using TimeSeriesSplit.\n",
    "\n",
    "    Parameters:\n",
    "    - models: list of sklearn-style models (will be cloned per fold)\n",
    "    - X: feature DataFrame\n",
    "    - y: target Series\n",
    "    - n_splits: number of TSCV splits\n",
    "\n",
    "    Returns:\n",
    "    - oof_df: DataFrame of shape (len(X), len(models)) with OOF predictions\n",
    "    \"\"\"\n",
    "    oof_preds = np.zeros((len(X), len(models)))\n",
    "    tscv = TimeSeriesSplit(n_splits=splits)\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        for train_idx, val_idx in tscv.split(X):\n",
    "            X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "\n",
    "            fold_model = clone(model)\n",
    "            fold_model.fit(X_train, y_train)\n",
    "            oof_preds[val_idx, i] = fold_model.predict(X_val)\n",
    "\n",
    "    return pd.DataFrame(oof_preds, index=X.index, columns=[f'model_{i}' for i in range(len(models))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_oof_cnn(model_class, X_seq, y, splits):\n",
    "    \"\"\"\n",
    "    Generate OOF predictions for a CNN1DWrapper-style model.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_class: class (not instance) of your CNN model\n",
    "    - X_seq: DataFrame or ndarray to be reshaped to 3D\n",
    "    - y: Series or array\n",
    "    - n_splits: number of TSCV folds\n",
    "    \n",
    "    Returns:\n",
    "    - oof_preds: np.array of predictions (same length as X_seq)\n",
    "    \"\"\"\n",
    "    X_array = X_seq.values.reshape((len(X_seq), X_seq.shape[1], 1))\n",
    "    y_array = y.values if hasattr(y, 'values') else y\n",
    "\n",
    "    oof_preds = np.zeros(len(X_seq))\n",
    "    tscv = TimeSeriesSplit(n_splits=splits)\n",
    "\n",
    "    for train_idx, val_idx in tscv.split(X_array):\n",
    "        X_tr, X_val = X_array[train_idx], X_array[val_idx]\n",
    "        y_tr = y_array[train_idx]\n",
    "\n",
    "        model = model_class(input_shape=(X_tr.shape[1], 1))\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        oof_preds[val_idx] = model.predict(X_val)\n",
    "\n",
    "    return oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_oof_lstm(model_class, X_seq, y, splits):\n",
    "    \"\"\"\n",
    "    Generate OOF predictions for an LSTMWrapper-style model.\n",
    "\n",
    "    Parameters:\n",
    "    - model_class: class (not instance) of your LSTM wrapper (e.g. LSTMWrapper)\n",
    "    - X_seq: numpy array or DataFrame (2D: samples x features)\n",
    "    - y: numpy array or Series\n",
    "    - n_splits: number of TSCV folds\n",
    "\n",
    "    Returns:\n",
    "    - oof_preds: 1D numpy array of out-of-fold predictions\n",
    "    \"\"\"\n",
    "    if hasattr(X_seq, \"values\"):\n",
    "        X_seq = X_seq.values\n",
    "    if hasattr(y, \"values\"):\n",
    "        y = y.values\n",
    "\n",
    "    oof_preds = np.zeros(len(X_seq))\n",
    "    tscv = TimeSeriesSplit(n_splits=splits)\n",
    "\n",
    "    for train_idx, val_idx in tscv.split(X_seq):\n",
    "        X_tr, X_val = X_seq[train_idx], X_seq[val_idx]\n",
    "        y_tr = y[train_idx]\n",
    "\n",
    "        model = model_class(input_shape=X_tr.shape[1])\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        oof_preds[val_idx] = model.predict(X_val)\n",
    "\n",
    "    return oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_oof_lstm_classifier(model_class, X_seq, y, splits=5, num_classes=3):\n",
    "    \"\"\"\n",
    "    Generate OOF predictions for an LSTM-based classifier model.\n",
    "\n",
    "    Parameters:\n",
    "    - model_class: your LSTM wrapper class (e.g. LSTMClassifierWrapper)\n",
    "    - X_seq: numpy array or DataFrame (2D: samples x features)\n",
    "    - y: target labels (array-like)\n",
    "    - splits: number of folds\n",
    "    - num_classes: for multi-class, how many output neurons\n",
    "\n",
    "    Returns:\n",
    "    - oof_preds: 1D array of predicted classes (or probabilities)\n",
    "    \"\"\"\n",
    "    if hasattr(X_seq, \"values\"):\n",
    "        X_seq = X_seq.values\n",
    "    if hasattr(y, \"values\"):\n",
    "        y = y.values\n",
    "\n",
    "    oof_preds = np.zeros(len(X_seq), dtype=int)  # or float if using probabilities\n",
    "    tscv = TimeSeriesSplit(n_splits=splits)\n",
    "\n",
    "    for train_idx, val_idx in tscv.split(X_seq):\n",
    "        X_tr, X_val = X_seq[train_idx], X_seq[val_idx]\n",
    "        y_tr = y[train_idx]\n",
    "\n",
    "        model = model_class(input_shape=X_tr.shape[1], num_classes=num_classes)\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        preds = model.predict(X_val)  # returns classes\n",
    "        oof_preds[val_idx] = preds\n",
    "\n",
    "    return oof_preds\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree-Based Models (XGBoost, LightGBM, CatBoost, RF)\n",
    "Sequential Models (LSTM, 1D CNN)\n",
    "Linear Models (ElasticNet, Logistic Regression)\n",
    "\n",
    "Regression:\n",
    "[XGBRegressor\n",
    "LSTMWrapper\n",
    "CatBoostRegressor]\n",
    "MetaRegressor: XGBoostRegressor\n",
    "+1: 1D CNN\n",
    "\n",
    "Classifier:\n",
    "[CatBoostClassifier\n",
    "RandomForest\n",
    "LSTM]\n",
    "MetaClassifier:\n",
    "+1: XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lookahead_for_session_regression(LOOKAHEAD, cutoff, splits):\n",
    "    labeled = pd.read_parquet(f\"labeled_data_{LOOKAHEAD}_session_less.parquet\")\n",
    "\n",
    "    cutoff_date = pd.Timestamp(cutoff, tz=\"America/New_York\")\n",
    "    train = labeled[labeled['datetime'] < cutoff_date]\n",
    "    test = labeled[labeled['datetime'] >= cutoff_date]\n",
    "\n",
    "    X_train_tree = train[tree_based_features]\n",
    "    X_test_tree = test[tree_based_features]\n",
    "\n",
    "    X_train_seq  = train[sequential_features]\n",
    "    X_test_seq = test[sequential_features]\n",
    "\n",
    "    y_train_tree = train['log_return']\n",
    "    y_test_tree = test['log_return']\n",
    "\n",
    "    y_train_seq = train['vol_adj_return']\n",
    "    y_test_seq = test['vol_adj_return']\n",
    "\n",
    "    y_train_transformed = np.sign(y_train_seq) * np.log1p(np.abs(y_train_seq))\n",
    "\n",
    "    print(f\"Train range: {train['datetime'].min()} to {train['datetime'].max()} | Rows: {len(train)}\")\n",
    "    print(f\"Test range: {test['datetime'].min()} to {test['datetime'].max()} | Rows: {len(test)}\")\n",
    "\n",
    "    ###########################\n",
    "    ########## Models #########\n",
    "    ###########################\n",
    "\n",
    "    def tune_xgboost(X_train, y_train):\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'n_estimators': 2000,\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.3, log=True),  # tighten low end\n",
    "                'max_depth': trial.suggest_int('max_depth', 6, 14),  # more complex trees\n",
    "                'subsample': trial.suggest_float('subsample', 0.7, 1.0),  # prevent underfitting\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),  # prevent weak splits\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),  # reduce L1 regularization\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),  # reduce L2 regularization\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 6),  # avoid pruning all splits\n",
    "                'gamma': trial.suggest_float('gamma', 0.0, 1.0),  # allow moderate split pruning\n",
    "                'tree_method': 'hist',\n",
    "            }\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=splits)\n",
    "            scores = []\n",
    "\n",
    "            for train_idx, val_idx in tscv.split(X_train):\n",
    "                X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "                model = XGBRegressor(**params, random_state=42, eval_metric='rmse', early_stopping_rounds=20)\n",
    "                model.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    verbose=False\n",
    "                )\n",
    "                preds = model.predict(X_val)\n",
    "                rmse = root_mean_squared_error(y_val, preds)\n",
    "                scores.append(rmse)\n",
    "\n",
    "            return np.mean(scores)\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction='minimize',\n",
    "            study_name=f'xgb_opt_reg_{LOOKAHEAD}',\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.SuccessiveHalvingPruner(min_resource=50, reduction_factor=4),\n",
    "            storage=f'sqlite:///xgb_opt_study_session_less.db',\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=50)\n",
    "        return study.best_params\n",
    "\n",
    "    def tune_lightgbm(X_train, y_train):\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 1500, step=100),\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.05, log=True),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 3, 5),\n",
    "                \"num_leaves\": trial.suggest_int(\"num_leaves\", 10, 30),\n",
    "                \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 40),\n",
    "                \"subsample\": trial.suggest_float(\"subsample\", 0.6, 0.9),\n",
    "                \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.9),\n",
    "                \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0.05, 1.0),\n",
    "                \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1.0, 10.0),\n",
    "                \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1.0, 10.0),\n",
    "                \"min_split_gain\": trial.suggest_float(\"min_split_gain\", 0.0, 0.2),\n",
    "                \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 50, 200),\n",
    "                \"boosting_type\": \"gbdt\",\n",
    "                \"verbosity\": -1,\n",
    "                \"metric\": \"rmse\"\n",
    "            }\n",
    "            tscv = TimeSeriesSplit(n_splits=splits)\n",
    "            scores = []\n",
    "            for train_idx, val_idx in tscv.split(X_train):\n",
    "                X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "                model = LGBMRegressor(**params, random_state=42, n_jobs=-2)\n",
    "                model.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    eval_metric=\"rmse\",\n",
    "                    callbacks=[early_stopping(stopping_rounds=50)]\n",
    "                )\n",
    "                preds = model.predict(X_val)\n",
    "                rmse = root_mean_squared_error(y_val, preds)\n",
    "                scores.append(rmse)\n",
    "                print(f\"Trial {trial.number} RMSE: {np.mean(scores):.6f} | Params: {params}\")\n",
    "            return np.mean(scores)\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction=\"minimize\",\n",
    "            study_name=f\"lgbm_opt_reg_{LOOKAHEAD}\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.SuccessiveHalvingPruner(min_resource=50, reduction_factor=4),\n",
    "            storage=f\"sqlite:///lgbm_opt_study_session_less.db\",\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=50)\n",
    "        return study.best_params\n",
    "\n",
    "    def tune_catboost(X_train, y_train):\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'iterations': 2000,\n",
    "                'depth': trial.suggest_int('depth', 4, 8),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05, log=True),\n",
    "                'loss_function': 'RMSE',\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 3.0, 10.0),\n",
    "                'random_strength': trial.suggest_float('random_strength', 1.0, 5.0),\n",
    "                'bootstrap_type': 'Bayesian',\n",
    "                'bagging_temperature': trial.suggest_float('bagging_temperature', 0.1, 1.0),\n",
    "                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
    "            }\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=splits)\n",
    "            scores = []\n",
    "\n",
    "            for train_idx, val_idx in tscv.split(X_train):\n",
    "                X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "                model = CatBoostRegressor(**params, random_state=42)\n",
    "                model.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    eval_set=(X_val, y_val),\n",
    "                    use_best_model=True,\n",
    "                    verbose=False,\n",
    "                    early_stopping_rounds=30\n",
    "                )\n",
    "                preds = model.predict(X_val)\n",
    "                rmse = root_mean_squared_error(y_val, preds)\n",
    "                scores.append(rmse)\n",
    "\n",
    "            return np.mean(scores)\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction='minimize',\n",
    "            study_name=f'catboost_opt_reg_{LOOKAHEAD}',\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.SuccessiveHalvingPruner(min_resource=50, reduction_factor=4),\n",
    "            storage=f'sqlite:///catboost_opt_study_session_less.db',\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=50)\n",
    "        return study.best_params\n",
    "\n",
    "    def tune_meta_xgb(X_meta, y_meta):\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'n_estimators': 1000,\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 2, 8),  # allow deeper if needed\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 0.5),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 0.5),\n",
    "                'gamma': trial.suggest_float('gamma', 0.0, 1.0),  # extra regularization\n",
    "            }\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=splits)\n",
    "            scores = []\n",
    "\n",
    "            for train_idx, val_idx in tscv.split(X_meta):\n",
    "                X_tr, X_val = X_meta.iloc[train_idx], X_meta.iloc[val_idx]\n",
    "                y_tr, y_val = y_meta.iloc[train_idx], y_meta.iloc[val_idx]\n",
    "\n",
    "                model = XGBRegressor(**params, random_state=42, n_jobs=-2, eval_metric='rmse')\n",
    "                model.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    eval_set=[(X_val, y_val)]\n",
    "                )\n",
    "                preds = model.predict(X_val)\n",
    "                rmse = root_mean_squared_error(y_val, preds)\n",
    "                scores.append(rmse)\n",
    "\n",
    "            return np.mean(scores)\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction='minimize',\n",
    "            study_name=f'meta_xgb_reg_{LOOKAHEAD}',\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=5),\n",
    "            storage=f'sqlite:///meta_xgb_session_less.db',\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=50)\n",
    "        return study.best_params\n",
    "\n",
    "    def inverse_log_signed(x):\n",
    "        return np.sign(x) * (np.expm1(np.abs(x)))\n",
    "    ################################################\n",
    "    ####### Ensure index consistency\n",
    "    ####### Sequential #######\n",
    "    y_train_seq = y_train_seq.loc[X_train_seq.index]\n",
    "    y_test_seq = y_test_seq.loc[X_test_seq.index]\n",
    "\n",
    "    ################################################\n",
    "    ####### Tune models\n",
    "    ####### Tree Based #######\n",
    "    catboost_params     = tune_catboost(X_train_tree, y_train_transformed)\n",
    "    xgboost_params      = tune_xgboost(X_train_tree, y_train_transformed)\n",
    "   # lgbm_params         = tune_lightgbm(X_train_tree, y_train_transformed)\n",
    "    ####### Sequential #######\n",
    "    # N/A\n",
    "\n",
    "    ################################################\n",
    "    ####### Train models\n",
    "    ####### Tree Based #######\n",
    "    catboost    = CatBoostRegressor(**catboost_params, random_state=42, verbose=0)\n",
    "    xgboost     = XGBRegressor(**xgboost_params, random_state=42)\n",
    "   # lgbm        = LGBMRegressor(**lgbm_params, random_state=42)\n",
    "    catboost.fit(X_train_tree, y_train_transformed)\n",
    "    xgboost.fit(X_train_tree, y_train_transformed)\n",
    "  #  lgbm.fit(X_train_tree, y_train_transformed)\n",
    "    ####### Sequential #######\n",
    "    X_lstm = X_train_seq.values\n",
    "    y_lstm = y_train_transformed.values\n",
    "    lstm_model = LSTMWrapper(input_shape=X_lstm.shape[1])\n",
    "    lstm_model.fit(X_lstm, y_lstm)  # wrapper does the reshaping\n",
    "    X_lstm_test = X_test_seq.values\n",
    "    lstm_preds = lstm_model.predict(X_lstm_test)\n",
    "\n",
    "    X_cnn = X_train_seq.values.reshape((len(X_train_seq), X_train_seq.shape[1], 1))\n",
    "    y_cnn = y_train_seq.values\n",
    "    cnn_model = CNN1DWrapper(input_shape=(X_cnn.shape[1], 1))\n",
    "    cnn_model.fit(X_cnn, y_cnn)\n",
    "    X_cnn_test = X_test_seq.values.reshape((len(X_test_seq), X_test_seq.shape[1], 1))\n",
    "    cnn_preds = cnn_model.predict(X_cnn_test)\n",
    "\n",
    "    ################################################\n",
    "    ####### OOF Predicition\n",
    "    ####### Tree Based #######\n",
    "    oof_tree = generate_oof_predictions([catboost, xgboost], X_train_tree, y_train_transformed, splits)\n",
    "\n",
    "    print(\"\\n🔍 Checking variance in OOF base model predictions Base model:\")\n",
    "    print(oof_tree.describe())\n",
    "    print(\"Std per model:\\n\", oof_tree.std())\n",
    "    ####### Sequential #######\n",
    "    oof_preds_cnn = generate_oof_cnn(CNN1DWrapper, X_train_seq, y_train_seq, splits)\n",
    "\n",
    "    print(\"\\n🔍 Checking variance in OOF base model predictions for CNN:\")\n",
    "    print(pd.Series(oof_preds_cnn).describe())\n",
    "    print(\"Std:\", np.std(oof_preds_cnn))\n",
    "\n",
    "    ################################################\n",
    "    ####### Meta Params and Training\n",
    "    ####### Tree Based #######\n",
    "    X_seq_np = X_train_seq.values\n",
    "    lstm_oof = generate_oof_lstm(LSTMWrapper, X_seq_np, y_train_transformed, splits)  # <- I can give you this\n",
    "\n",
    "    X_meta_train = pd.DataFrame({\n",
    "        'cat': oof_tree.iloc[:, 0],\n",
    "        'xgb': oof_tree.iloc[:, 1],\n",
    "        'lstm': lstm_oof\n",
    "    })\n",
    "\n",
    "    X_test_meta = pd.DataFrame({\n",
    "        'cat': catboost.predict(X_test_tree),\n",
    "        'xgb': xgboost.predict(X_test_tree),\n",
    "        'lstm': lstm_model.predict(X_test_seq.values)\n",
    "    })\n",
    "\n",
    "    meta_params = tune_meta_xgb(X_meta_train, y_train_transformed)\n",
    "    meta_model = XGBRegressor(**meta_params, random_state=42)\n",
    "    meta_model.fit(X_meta_train, y_train_transformed)\n",
    "\n",
    "    ################################################\n",
    "    ####### Evaluate Model\n",
    "    def evaluate_model(name, model, Xtr, Xte, ytr, yte, transformed=False):\n",
    "        train_preds = model.predict(Xtr)\n",
    "        test_preds = model.predict(Xte)\n",
    "\n",
    "        if transformed:\n",
    "        # Inverse-transform predictions\n",
    "            train_preds = np.sign(train_preds) * (np.expm1(np.abs(train_preds)))\n",
    "            test_preds = np.sign(test_preds) * (np.expm1(np.abs(test_preds)))\n",
    "            ytr = np.sign(ytr) * (np.expm1(np.abs(ytr)))\n",
    "        \n",
    "        train_mse = mean_squared_error(ytr, train_preds)\n",
    "        test_mse = mean_squared_error(yte, test_preds)\n",
    "        overfit_ratio = test_mse / train_mse if train_mse != 0 else float('inf')\n",
    "\n",
    "        print(f\"\\n📊 {name} Performance:\")\n",
    "        print(f\"Train MSE: {train_mse:.8f}\")\n",
    "        print(f\"Test MSE: {test_mse:.8f}\")\n",
    "        print(f\"Overfit ratio (Test / Train): {overfit_ratio:.2f}\")\n",
    "        if overfit_ratio > 1.5:\n",
    "            print(\"⚠️ Potential overfitting detected.\")\n",
    "        elif overfit_ratio < 0.7:\n",
    "            print(\"⚠️ Possibly underfitting.\")\n",
    "        else:\n",
    "            print(\"✅ Generalization looks reasonable.\")\n",
    "        return test_preds\n",
    "    \n",
    "    ####### Tree Based #######\n",
    "    print(\"\\nEvaluation XGBoost\")\n",
    "    preds_xgboost   = evaluate_model(\"XGBoostRegressor\", xgboost, X_train_tree, X_test_tree, y_train_transformed, y_test_seq, transformed=True)\n",
    "    print(\"\\nEvaluation CatBoost\")\n",
    "    preds_catboost  = evaluate_model(\"CatBoostRegressor\", catboost, X_train_tree, X_test_tree, y_train_transformed, y_test_seq, transformed=True)\n",
    "    print(\"\\nEvaluation Stack\")\n",
    "    preds_stack     = evaluate_model(\"StackingRegressor\", meta_model, X_meta_train, X_test_meta, y_train_transformed.values, y_test_seq.values, transformed=True)\n",
    " #   print(\"\\nEvaluation LGBM\")\n",
    "#    preds_lgbm      = evaluate_model(\"LightGBM\", lgbm, X_train_tree, X_test_tree, y_train_transformed, y_test_tree, transformed=True)\n",
    "    ####### Sequential #######\n",
    "    X_cnn_train = X_train_seq.values.reshape((len(X_train_seq), X_train_seq.shape[1], 1))\n",
    "    X_cnn_test = X_test_seq.values.reshape((len(X_test_seq), X_test_seq.shape[1], 1))\n",
    "\n",
    "    print(\"\\nEvaluation LSTM\")\n",
    "    preds_lstm       = evaluate_model(\"LSTM\", lstm_model, X_train_seq.values, X_test_seq.values, y_train_transformed.values, y_test_seq.values, transformed=True)\n",
    "    print(\"\\nEvaluation CNN\")\n",
    "    preds_cnn      = evaluate_model(\"CNN\", cnn_model, X_cnn_train, X_cnn_test, y_train_seq.values, y_test_seq.values)\n",
    "\n",
    "    ################################################\n",
    "    ####### Target Distribution\n",
    "    ####### Tree based #######\n",
    "    print(\"\\n🔍 Target distribution Tree:\")\n",
    "    print(y_train_tree.describe())\n",
    "    ####### Sequential #######\n",
    "    print(\"\\n🔍 Target distribution Seq:\")\n",
    "    print(y_train_seq.describe())\n",
    "    \n",
    "    ################################################\n",
    "    ####### Choose final model\n",
    "    ####### Tree Based #######\n",
    "    # print(\"\\n🔍 Checking prediction variance from LGBM model:\")\n",
    "    # print(f\"Min: {preds_lgbm.min():.8f}\")\n",
    "    # print(f\"Max: {preds_lgbm.max():.8f}\")\n",
    "    # print(f\"Mean: {preds_lgbm.mean():.8f}\")\n",
    "    # print(f\"Std Dev: {preds_lgbm.std():.8f}\")\n",
    "    # print(f\"First 5 Predictions: {preds_lgbm[:5]}\")\n",
    "\n",
    "    # mae_lgbm = mean_absolute_error(y_test_tree, preds_lgbm)\n",
    "    # rmse_lgbm = np.sqrt(mean_squared_error(y_test_tree, preds_lgbm))\n",
    "    # r2_lgbm = r2_score(y_test_tree, preds_lgbm)\n",
    "\n",
    "    # print(f\"MAE: {mae_lgbm:.4f}\")\n",
    "    # print(f\"RMSE: {rmse_lgbm:.4f}\")\n",
    "    # print(f\"R²: {r2_lgbm:.4f}\")\n",
    "    ####### Stacked Model #######\n",
    "    print(\"\\n🔍 Checking prediction variance from Stack model:\")\n",
    "    print(f\"Min: {preds_stack.min():.8f}\")\n",
    "    print(f\"Max: {preds_stack.max():.8f}\")\n",
    "    print(f\"Mean: {preds_stack.mean():.8f}\")\n",
    "    print(f\"Std Dev: {preds_stack.std():.8f}\")\n",
    "    print(f\"First 5 Predictions: {preds_stack[:5]}\")\n",
    "\n",
    "    mae = mean_absolute_error(y_test_seq, preds_stack)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_seq, preds_stack))\n",
    "    r2 = r2_score(y_test_seq, preds_stack)\n",
    "\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    ####### Sequential Solo #######\n",
    "    print(\"\\n🔍 Checking prediction variance from CNN model:\")\n",
    "    print(f\"Min: {preds_cnn.min():.8f}\")\n",
    "    print(f\"Max: {preds_cnn.max():.8f}\")\n",
    "    print(f\"Mean: {preds_cnn.mean():.8f}\")\n",
    "    print(f\"Std Dev: {preds_cnn.std():.8f}\")\n",
    "    print(f\"First 5 Predictions: {preds_cnn[:5]}\")\n",
    "\n",
    "    mae_cnn = mean_absolute_error(y_test_seq, preds_cnn)\n",
    "    rmse_cnn = np.sqrt(mean_squared_error(y_test_seq, preds_cnn))\n",
    "    r2_cnn = r2_score(y_test_seq, preds_cnn)\n",
    "\n",
    "    print(f\"MAE: {mae_cnn:.4f}\")\n",
    "    print(f\"RMSE: {rmse_cnn:.4f}\")\n",
    "    print(f\"R²: {r2_cnn:.4f}\")\n",
    "\n",
    "    metadata = {\n",
    "        \"lookahead\": LOOKAHEAD,\n",
    "        \"xgboost_params\": xgboost_params,\n",
    "        \"catboost_params\": catboost_params,\n",
    "        \"meta_params\": meta_params,\n",
    "        \"lgbm_params\": lgbm_params\n",
    "    }\n",
    "    with open(f\"regression_metadata_{LOOKAHEAD}.json\", \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "        \n",
    "    joblib.dump(meta_model, f\"stack_model_regression_LOOKAHEAD_{LOOKAHEAD}_session_less.pkl\")\n",
    "    joblib.dump(cnn_model, f\"cnn_model_regression_LOOKAHEAD_{LOOKAHEAD}_session_less.pkl\")\n",
    "   #joblib.dump(lgbm, f\"lgbm_model_regression_LOOKAHEAD_{LOOKAHEAD}_session_less.pkl\")\n",
    "\n",
    "    return {\n",
    "        'lookahead': LOOKAHEAD,\n",
    "        'preds_stack': preds_stack,\n",
    "        'preds_cnn': preds_cnn,\n",
    "     #   'preds_lgbm': preds_lgbm,\n",
    "        'X_test_seq': X_test_seq,\n",
    "        'X_test_meta': X_test_meta,\n",
    "        'true_values': y_test_seq.values\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lookahead_for_session_classification(LOOKAHEAD, cutoff, splits):\n",
    "    labeled = pd.read_parquet(f\"labeled_data_{LOOKAHEAD}_session_less.parquet\")\n",
    "\n",
    "    cutoff_date = pd.Timestamp(cutoff, tz=\"America/New_York\")\n",
    "    train = labeled[labeled['datetime'] < cutoff_date]\n",
    "    test = labeled[labeled['datetime'] >= cutoff_date]\n",
    "\n",
    "    X_train_tree = train[tree_based_features]\n",
    "    X_test_tree = test[tree_based_features]\n",
    "    X_train_seq  = train[sequential_features]\n",
    "    X_test_seq = test[sequential_features]\n",
    "    X_train_linear  = train[linear_features]\n",
    "    X_test_linear = test[linear_features]\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_train_class = pd.Series(le.fit_transform(train['triple_barrier_label']), index=train.index)\n",
    "    y_test_class = pd.Series(le.transform(test['triple_barrier_label']), index=test.index)\n",
    "\n",
    "    print(f\"Train range: {train['datetime'].min()} to {train['datetime'].max()} | Rows: {len(train)}\")\n",
    "    print(f\"Test range: {test['datetime'].min()} to {test['datetime'].max()} | Rows: {len(test)}\")\n",
    "\n",
    "    ###########################\n",
    "    ########## Models #########\n",
    "    ###########################\n",
    "\n",
    "    def tune_xgboost(X_train, y_train):\n",
    "        def objective(trial):\n",
    "\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "                'gamma': trial.suggest_float('gamma', 0.0, 5.0),\n",
    "                'eval_metric': 'logloss'\n",
    "            }\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=splits)\n",
    "            model = XGBClassifier(**params, random_state=42, n_jobs=-1)\n",
    "\n",
    "            scores = cross_val_score(model, X_train, y_train, cv=tscv, scoring=\"f1_macro\", n_jobs=-1)\n",
    "            print(f\"Trial {trial.number} F1 Score: {scores.mean():.5f} | Params: {params}\")\n",
    "            return scores.mean()\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction='maximize',\n",
    "            study_name=f'xgb_opt_class_{lookahead}',\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=5),\n",
    "            storage=f'sqlite:///xgb_opt_study_session_less.db',\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=1)\n",
    "        return study.best_params\n",
    "\n",
    "    def tune_rf(X_train, y_train):\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000, step=100),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "                \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "                \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "                \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None]),\n",
    "                \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "                \"class_weight\": trial.suggest_categorical(\"class_weight\", [None, \"balanced\", \"balanced_subsample\"]),\n",
    "                \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\", \"log_loss\"]),\n",
    "            }\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=splits)\n",
    "            model = RandomForestClassifier(**params, random_state=42, n_jobs=-1)\n",
    "\n",
    "            scores = cross_val_score(model, X_train, y_train, cv=tscv, scoring=\"f1_macro\", n_jobs=-1)\n",
    "            print(f\"Trial {trial.number} F1 Score: {scores.mean():.5f} | Params: {params}\")\n",
    "            return scores.mean()\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\",\n",
    "            study_name=f\"rf_opt_class_{lookahead}\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=5),\n",
    "            storage=f\"sqlite:///rf_opt_study_session_less.db\",\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=1)\n",
    "        return study.best_params\n",
    "\n",
    "    def tune_catboost(X_train, y_train):\n",
    "        def objective(trial):\n",
    "            bootstrap_type = trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli'])\n",
    "\n",
    "            params = {\n",
    "                'iterations': trial.suggest_int('iterations', 300, 1500, step=100),\n",
    "                'depth': trial.suggest_int('depth', 4, 10),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0),\n",
    "                'random_strength': trial.suggest_float('random_strength', 0.5, 5.0),\n",
    "                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
    "                'bootstrap_type': bootstrap_type,\n",
    "                'loss_function': 'MultiClass',\n",
    "                'eval_metric': 'TotalF1',\n",
    "                'verbose': 0\n",
    "            }\n",
    "\n",
    "            if bootstrap_type == 'Bayesian':\n",
    "                params['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0.0, 1.0)\n",
    "\n",
    "            model = CatBoostClassifier(**params, random_state=42)\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=splits)\n",
    "            scores = cross_val_score(model, X_train, y_train, cv=tscv, scoring='f1_macro', n_jobs=-1)\n",
    "            print(f\"Trial {trial.number} F1 Score: {scores.mean():.5f} | Params: {params}\")\n",
    "            return scores.mean()\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction='maximize',\n",
    "            study_name=f'catboost_opt_class_{lookahead}',\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=5),\n",
    "            storage=f'sqlite:///catboost_opt_study_session_less.db',\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=1)\n",
    "        return study.best_params\n",
    "\n",
    "    def tune_meta_logreg(X_meta, y_meta):\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                \"penalty\": trial.suggest_categorical(\"penalty\", [\"l2\", \"none\"]),\n",
    "                \"C\": trial.suggest_float(\"C\", 1e-4, 10.0, log=True),\n",
    "                \"solver\": \"lbfgs\",\n",
    "                \"max_iter\": 1000\n",
    "            }\n",
    "\n",
    "            model = LogisticRegression(**params, random_state=42)\n",
    "            tscv = TimeSeriesSplit(n_splits=splits)\n",
    "\n",
    "            scores = cross_val_score(model, X_meta, y_meta, cv=tscv, scoring=\"f1_macro\", n_jobs=-1)\n",
    "            print(f\"Trial {trial.number} F1 Score: {scores.mean():.5f} | Params: {params}\")\n",
    "            return scores.mean()\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\",\n",
    "            study_name=f\"meta_logreg_class_{lookahead}\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=5),\n",
    "            storage=f\"sqlite:///meta_logreg_stack_session_less.db\",\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=1)  # adjust trial count as needed\n",
    "        return study.best_params\n",
    "\n",
    "    def tune_lstm_classifier_with_optuna(X, y, splits, lookahead, num_classes=2):\n",
    "        def objective(trial):\n",
    "            units = trial.suggest_int(\"units\", 16, 128, step=16)\n",
    "            lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "            batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "            epochs = trial.suggest_int(\"epochs\", 5, 30)\n",
    "\n",
    "            scores = []\n",
    "            tscv = TimeSeriesSplit(n_splits=splits)\n",
    "\n",
    "            for train_idx, val_idx in tscv.split(X):\n",
    "                X_tr, X_val = X[train_idx], X[val_idx]\n",
    "                y_tr, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "                model = LSTMClassifierWrapper(\n",
    "                    input_shape=X.shape[1],\n",
    "                    units=units,\n",
    "                    lr=lr,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    verbose=0,\n",
    "                    num_classes=num_classes\n",
    "                )\n",
    "                model.fit(X_tr, y_tr)\n",
    "                preds = model.predict(X_val)\n",
    "                acc = accuracy_score(y_val, preds)\n",
    "                scores.append(acc)\n",
    "\n",
    "            mean_acc = np.mean(scores)\n",
    "            print(f\"Trial {trial.number} Accuracy: {mean_acc:.5f} | Params: units={units}, lr={lr}, batch={batch_size}, epochs={epochs}\")\n",
    "            return mean_acc\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\",\n",
    "            study_name=\"lstm_class_opt\",\n",
    "            storage=f\"sqlite:///lstm_class_opt_study{lookahead}_session_less.db\",\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=2)\n",
    "        print(\"Best trial:\", study.best_trial.params)\n",
    "        return study.best_trial.params\n",
    "    ################################################\n",
    "    ####### Ensure index consistency\n",
    "    ####### Sequential #######\n",
    "    y_train_seq = y_train_class.loc[X_train_seq.index]\n",
    "    y_test_seq = y_test_class.loc[X_test_seq.index]\n",
    "\n",
    "    ################################################\n",
    "    ####### Tune models\n",
    "    ####### Tree Based #######\n",
    "    catboost_params     = tune_catboost(X_train_tree, y_train_class)\n",
    "    xgboost_params      = tune_xgboost(X_train_tree, y_train_class)\n",
    "    rf_params         = tune_rf(X_train_tree, y_train_class)\n",
    "    ####### Sequential #######\n",
    "    X_lstm = X_train_seq.values\n",
    "    y_lstm = y_train_class.values\n",
    "\n",
    "    ################################################\n",
    "    ####### Train models\n",
    "    ####### Tree Based #######\n",
    "    catboost    = CatBoostClassifier(**catboost_params, random_state=42, verbose=0)\n",
    "    xgboost     = XGBClassifier(**xgboost_params, random_state=42)\n",
    "    rf          = RandomForestClassifier(**rf_params, random_state=42)\n",
    "    catboost.fit(X_train_tree, y_train_class)\n",
    "    xgboost.fit(X_train_tree, y_train_class)\n",
    "    rf.fit(X_train_tree, y_train_class)\n",
    "    ####### Sequential #######\n",
    "    lstm_model = LSTMClassifierWrapper(input_shape=X_lstm.shape[1])\n",
    "    lstm_model.fit(X_lstm, y_lstm)  # wrapper does the reshaping\n",
    "    X_lstm_test = X_test_seq.values\n",
    "    lstm_preds = lstm_model.predict(X_lstm_test)\n",
    "    ################################################\n",
    "    ####### OOF Predicition\n",
    "    ####### Tree Based #######\n",
    "    oof_tree = generate_oof_predictions([catboost, rf], X_train_tree, y_train_class, splits)\n",
    "    oof_lstm = generate_oof_lstm_classifier(LSTMClassifierWrapper, X_lstm, y_lstm, splits)  # <- Uses sequential input\n",
    "\n",
    "    ################################################\n",
    "    ####### Train Meta Model\n",
    "    ####### Tree Based #######\n",
    "    X_meta_train = pd.DataFrame({\n",
    "        'cat': oof_tree.iloc[:, 0],\n",
    "        'rf': oof_tree.iloc[:, 1],\n",
    "        \"lstm\": oof_lstm\n",
    "    })\n",
    "\n",
    "    X_meta_test = pd.DataFrame({\n",
    "        \"cat\": catboost.predict(X_test_tree),\n",
    "        \"rf\": rf.predict(X_test_tree),\n",
    "        \"lstm\": lstm_model.predict(X_test_seq.values)\n",
    "    })\n",
    "\n",
    "    X_meta_train_combined = pd.concat([X_meta_train.reset_index(drop=True), X_train_linear.reset_index(drop=True)], axis=1)\n",
    "    X_meta_test_combined = pd.concat([X_meta_test.reset_index(drop=True), X_test_linear.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    meta_params = tune_meta_logreg(X_meta_train_combined, y_train_class)\n",
    "    meta_model = LogisticRegression(**meta_params, random_state=42)\n",
    "    meta_model.fit(X_meta_train_combined, y_train_class)\n",
    "\n",
    "    ################################################\n",
    "    ####### Evaluate Model\n",
    "    def evaluate_model(name, model, Xtr, Xte, ytr, yte):\n",
    "        train_preds = model.predict(Xtr)\n",
    "        test_preds = model.predict(Xte)\n",
    "\n",
    "        train_acc = accuracy_score(ytr, train_preds)\n",
    "        test_acc = accuracy_score(yte, test_preds)\n",
    "\n",
    "        print(f\"\\n📊 {name} Classification Accuracy:\")\n",
    "        print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "        print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "        return test_preds\n",
    "    \n",
    "    ####### Tree Based #######\n",
    "    print(\"\\nXGBoost\")\n",
    "    preds_xgboost   = evaluate_model(\"XGBoostRegressor\", xgboost, X_train_tree, X_test_tree, y_train_seq, y_test_seq)\n",
    "    print(\"\\nCatboost\")\n",
    "    preds_catboost  = evaluate_model(\"CatBoostRegressor\", catboost, X_train_tree, X_test_tree, y_train_seq, y_test_seq)\n",
    "    print(\"\\nRF\")\n",
    "    preds_rf        = evaluate_model(\"RandomForest\", rf, X_train_tree, X_test_tree, y_train_seq, y_test_seq)\n",
    "    print(\"\\nLSTM\")\n",
    "    preds_lstm       = evaluate_model(\"LSTM\", lstm_model, X_train_seq.values, X_test_seq.values, y_train_seq.values, y_test_seq.values)\n",
    "    print(\"\\nMeta Model\")\n",
    "    preds_stack     = evaluate_model(\"StackingRegressor\", meta_model, X_meta_train_combined, X_meta_test_combined, y_train_class.values, y_test_class.values)\n",
    "\n",
    "    ################################################\n",
    "    ####### Target Distribution\n",
    "    print(\"\\n🔍 Target distribution:\")\n",
    "    print(y_train_class.describe())\n",
    "    \n",
    "    ################################################\n",
    "    ####### Choose final model\n",
    "    ####### Tree Based #######\n",
    "    preds_xgboost = xgboost.predict(X_test_tree)\n",
    "    print(\"\\n🔍 Checking XGBoost prediction distribution (classification):\")\n",
    "    print(f\"Classes predicted: {np.unique(preds_xgboost)}\")\n",
    "    print(f\"Prediction counts:\\n{pd.Series(preds_xgboost).value_counts()}\")\n",
    "\n",
    "    # Classification metrics\n",
    "    acc = accuracy_score(y_test_class, preds_xgboost)\n",
    "    f1 = f1_score(y_test_class, preds_xgboost, average='macro')\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Score (macro): {f1:.4f}\")\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_test_class, preds_xgboost))\n",
    "\n",
    "    ####### Stacked Model #######\n",
    "    preds_meta_model = meta_model.predict(X_test_tree)\n",
    "    print(\"\\n🔍 Checking Meta Model prediction distribution (classification):\")\n",
    "    print(f\"Classes predicted: {np.unique(preds_meta_model)}\")\n",
    "    print(f\"Prediction counts:\\n{pd.Series(preds_meta_model).value_counts()}\")\n",
    "\n",
    "    # Classification metrics\n",
    "    acc = accuracy_score(y_test_class, preds_meta_model)\n",
    "    f1 = f1_score(y_test_class, preds_meta_model, average='macro')\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Score (macro): {f1:.4f}\")\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_test_class, preds_meta_model))\n",
    "\n",
    "    metadata = {\n",
    "        \"lookahead\": LOOKAHEAD,\n",
    "        \"xgboost_params\": xgboost_params,\n",
    "        \"catboost_params\": catboost_params,\n",
    "        \"rf_params\": rf_params,\n",
    "        \"meta_params\": meta_params,\n",
    "    }\n",
    "    with open(f\"classifier_metadata_{LOOKAHEAD}.json\", \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "        \n",
    "    joblib.dump(meta_model, f\"stack_model_classifier_LOOKAHEAD_{LOOKAHEAD}_session_less.pkl\")\n",
    "    joblib.dump(xgboost, f\"xgboost_model_classifier_LOOKAHEAD_{LOOKAHEAD}_session_less.pkl\")\n",
    "\n",
    "    return {\n",
    "        'lookahead': LOOKAHEAD,\n",
    "        'preds_stack': preds_stack,\n",
    "        'preds_xgboost': preds_xgboost,\n",
    "        'X_test_tree': X_test_tree,\n",
    "        'X_test_linear': X_test_linear,\n",
    "        'X_meta_test_combined': X_meta_test_combined,\n",
    "        'true_values': y_test_class.values\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Training\n",
    "lookahead_values = [5, 10]\n",
    "reg_results = []\n",
    "\n",
    "for val in lookahead_values:\n",
    "    cutoff = \"2025-04-01\"\n",
    "    splits=4\n",
    "    regression_models = run_lookahead_for_session_regression(val, cutoff, splits)\n",
    "    reg_results.append(regression_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 21:28:43,658] Using an existing study with name 'catboost_opt_class_5' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train range: 2024-09-12 02:13:00-04:00 to 2025-03-31 23:59:00-04:00 | Rows: 192175\n",
      "Test range: 2025-04-01 00:00:00-04:00 to 2025-05-20 19:35:00-04:00 | Rows: 47801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 21:30:10,778] Trial 4 finished with value: 0.1654895506024548 and parameters: {'bootstrap_type': 'Bernoulli', 'iterations': 1200, 'depth': 8, 'learning_rate': 0.01700037298921102, 'l2_leaf_reg': 2.403950683025824, 'random_strength': 0.7613762547568976, 'min_data_in_leaf': 88}. Best is trial 0 with value: 0.1654895506024548.\n",
      "[I 2025-05-24 21:30:10,803] Using an existing study with name 'xgb_opt_class_5' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 F1 Score: 0.16549 | Params: {'iterations': 1200, 'depth': 8, 'learning_rate': 0.01700037298921102, 'l2_leaf_reg': 2.403950683025824, 'random_strength': 0.7613762547568976, 'min_data_in_leaf': 88, 'bootstrap_type': 'Bernoulli', 'loss_function': 'MultiClass', 'eval_metric': 'TotalF1', 'verbose': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-24 21:30:19,500] Trial 4 finished with value: 0.17252798591591784 and parameters: {'n_estimators': 400, 'learning_rate': 0.2536999076681771, 'max_depth': 10, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.5780093202212182, 'reg_alpha': 0.15599452033620265, 'reg_lambda': 0.05808361216819946, 'min_child_weight': 9, 'gamma': 3.005575058716044}. Best is trial 0 with value: 0.17252798591591784.\n",
      "[I 2025-05-24 21:30:19,522] Using an existing study with name 'rf_opt_class_5' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 F1 Score: 0.17253 | Params: {'n_estimators': 400, 'learning_rate': 0.2536999076681771, 'max_depth': 10, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.5780093202212182, 'reg_alpha': 0.15599452033620265, 'reg_lambda': 0.05808361216819946, 'min_child_weight': 9, 'gamma': 3.005575058716044, 'eval_metric': 'logloss'}\n"
     ]
    }
   ],
   "source": [
    "# Classification Training\n",
    "lookahead_values = [5, 10, 20]\n",
    "class_results = []\n",
    "\n",
    "for val in lookahead_values:\n",
    "    cutoff = \"2025-04-01\"\n",
    "    splits=4\n",
    "    classification_models = run_lookahead_for_session_classification(val, cutoff, splits)\n",
    "    class_results.append(classification_models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regression StandAlone Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "thresholds = [0.000002]\n",
    "\n",
    "for result in reg_results:\n",
    "    lookahead = result['lookahead']\n",
    "    preds_stack = result['preds_stack']  # or 'preds_cnn'\n",
    "    preds_cnn = result['preds_cnn']\n",
    "    preds_lgbm = result['preds_lgbm']\n",
    "    X_test_combined = result['X_test_meta']  # or 'X_test_seq'\n",
    "    y_test = result['true_values']\n",
    "    labeled = pd.read_parquet(f\"labeled_data_{lookahead}_session_less.parquet\")\n",
    "    df_backtest = labeled.copy()\n",
    "\n",
    "    print(f\"\\n🔎 Predicted return range for LOOKAHEAD={lookahead}: STACK: min={preds_stack.min():.8f}, max={preds_stack.max():.8f} | CNN: min={preds_cnn.min():.8f}, max={preds_cnn.max():.8f}\")\n",
    "    for params in combinations:\n",
    "        for thresh in thresholds:\n",
    "            results = evaluate_regression(\n",
    "                X_test=X_test_combined,\n",
    "                preds_stack=preds_stack,\n",
    "                preds_cnn=preds_cnn,\n",
    "                labeled=labeled,\n",
    "                df=df_backtest,\n",
    "                avoid_funcs=avoid_funcs,\n",
    "                SL_ATR_MULT=params['SL_ATR_MULT'],\n",
    "                TP_ATR_MULT=params['TP_ATR_MULT'],\n",
    "                TRAIL_START_MULT=params['TRAIL_START_MULT'],\n",
    "                TRAIL_STOP_MULT=params['TRAIL_STOP_MULT'],\n",
    "                TICK_VALUE=params['TICK_VALUE'],\n",
    "                is_same_session=is_same_session,\n",
    "                long_thresh=thresh,\n",
    "                short_thresh=-thresh,\n",
    "                base_contracts=1,\n",
    "                max_contracts=5,\n",
    "                skip_weak_conf=True,\n",
    "                weak_conf_zscore=0.2\n",
    "            )\n",
    "\n",
    "            results['params'] = params\n",
    "            results['threshold'] = thresh\n",
    "            all_results.append(results)\n",
    "\n",
    "            print(f\"\\n\\n🔍 Evaluating with params: {params}\")\n",
    "\n",
    "            print(\n",
    "                f\"\\n✅ LOOKAHEAD={lookahead} | Threshold={thresh}\"\n",
    "                f\"\\nPnL: ${results['pnl']:.2f}\"\n",
    "                f\"\\nTrades: {results['trades']}\"\n",
    "                f\"\\nWin Rate: {results['win_rate']:.2%}\"\n",
    "                f\"\\nExpectancy: {results['expectancy']:.2f}\"\n",
    "                f\"\\nProfit Factor: {results['profit_factor']:.2f}\"\n",
    "                f\"\\nSharpe Ratio: {results['sharpe']:.2f}\"\n",
    "                f\"\\nLong Trades: {results['long_trades']} | Short Trades: {results['short_trades']}\"\n",
    "            )\n",
    "\n",
    "            print(\"Avoid Hits:\")\n",
    "            for name, count in results['avoid_hits'].items():\n",
    "                print(f\" - {name}: {count}\")\n",
    "\n",
    "            if not results['results'].empty and 'pnl' in results['results'].columns:\n",
    "                print(\"\\n🔢 Top 5 PnL trades:\")\n",
    "                print(results['results'].sort_values(by='pnl', ascending=False).head(5))\n",
    "\n",
    "                print(\"\\n🔻 Bottom 5 PnL trades:\")\n",
    "                print(results['results'].sort_values(by='pnl', ascending=True).head(5))\n",
    "            else:\n",
    "                print(\"\\n⚠️ No trades executed, skipping PnL trade breakdown.\")\n",
    "\n",
    "\n",
    "summary_df = pd.DataFrame([{\n",
    "    'pnl': r['pnl'],\n",
    "    'sharpe': r['sharpe'],\n",
    "    'expectancy': r['expectancy'],\n",
    "    'profit_factor': r['profit_factor'],\n",
    "    'win_rate': r['win_rate'],\n",
    "    'trades': r['trades'],\n",
    "    **r['params']\n",
    "} for r in all_results])\n",
    "top = summary_df.sort_values(by='sharpe', ascending=False).head(10)\n",
    "print(\"\\n🏁 Top 10 Configurations Across All Lookaheads:\")\n",
    "print(top)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification StandAlone Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classification_results = []\n",
    "\n",
    "for result in class_results:\n",
    "    lookahead = result['lookahead']\n",
    "    preds_stack = result['preds_stack']  # or 'preds_cnn'\n",
    "    preds_xgboost = result['preds_xgboost']\n",
    "    X_test_combined = result['X_meta_test_combined']  # or 'X_test_seq'\n",
    "    y_test = result['true_values']\n",
    "    labeled = pd.read_parquet(f\"labeled_data_{lookahead}_session_less.parquet\")\n",
    "    df_backtest = labeled.copy()\n",
    "\n",
    "    print(f\"\\n🔎 Predicted return range for LOOKAHEAD={lookahead}: STACK: min={preds_stack.min():.6f}, max={preds_stack.max():.6f} | XGBoost: min={preds_xgboost.min():.6f}, max={preds_xgboost.max():.6f}\")\n",
    "    for params in combinations:\n",
    "        # X_test, preds_stack, preds_cnn, preds_lgbm, \n",
    "        results = evaluate_classification(\n",
    "            X_test=X_test_combined,\n",
    "            preds_stack=preds_stack,\n",
    "            preds_xgboost=preds_xgboost,\n",
    "            labeled=labeled,\n",
    "            df=df_backtest,\n",
    "            avoid_funcs=avoid_funcs,\n",
    "            SL_ATR_MULT=params['SL_ATR_MULT'],\n",
    "            TP_ATR_MULT=params['TP_ATR_MULT'],\n",
    "            TRAIL_START_MULT=params['TRAIL_START_MULT'],\n",
    "            TRAIL_STOP_MULT=params['TRAIL_STOP_MULT'],\n",
    "            TICK_VALUE=params['TICK_VALUE'],\n",
    "            is_same_session=is_same_session,\n",
    "            base_contracts=1,\n",
    "            max_contracts=5,\n",
    "            skip_weak_conf=True,\n",
    "            weak_conf_zscore=0.2\n",
    "        )\n",
    "\n",
    "        results['params'] = params\n",
    "        all_classification_results.append(results)\n",
    "\n",
    "        print(f\"\\n\\n🔍 Evaluating with params: {params}\")\n",
    "\n",
    "        print(\n",
    "            f\"\\n✅ LOOKAHEAD={lookahead} | Threshold={thresh}\"\n",
    "            f\"\\nPnL: ${results['pnl']:.2f}\"\n",
    "            f\"\\nTrades: {results['trades']}\"\n",
    "            f\"\\nWin Rate: {results['win_rate']:.2%}\"\n",
    "            f\"\\nExpectancy: {results['expectancy']:.2f}\"\n",
    "            f\"\\nProfit Factor: {results['profit_factor']:.2f}\"\n",
    "            f\"\\nSharpe Ratio: {results['sharpe']:.2f}\"\n",
    "            f\"\\nLong Trades: {results['long_trades']} | Short Trades: {results['short_trades']}\"\n",
    "        )\n",
    "\n",
    "        print(\"Avoid Hits:\")\n",
    "        for name, count in results['avoid_hits'].items():\n",
    "            print(f\" - {name}: {count}\")\n",
    "\n",
    "        if not results['results'].empty and 'pnl' in results['results'].columns:\n",
    "            print(\"\\n🔢 Top 5 PnL trades:\")\n",
    "            print(results['results'].sort_values(by='pnl', ascending=False).head(5))\n",
    "\n",
    "            print(\"\\n🔻 Bottom 5 PnL trades:\")\n",
    "            print(results['results'].sort_values(by='pnl', ascending=True).head(5))\n",
    "        else:\n",
    "            print(\"\\n⚠️ No trades executed, skipping PnL trade breakdown.\")\n",
    "\n",
    "\n",
    "summary_df = pd.DataFrame([{\n",
    "    'pnl': r['pnl'],\n",
    "    'sharpe': r['sharpe'],\n",
    "    'expectancy': r['expectancy'],\n",
    "    'profit_factor': r['profit_factor'],\n",
    "    'win_rate': r['win_rate'],\n",
    "    'trades': r['trades'],\n",
    "    **r['params']\n",
    "} for r in all_results])\n",
    "top = summary_df.sort_values(by='sharpe', ascending=False).head(10)\n",
    "print(\"\\n🏁 Top 10 Configurations Across All Lookaheads:\")\n",
    "print(top)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combo Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combo_results = []\n",
    "thresholds = [0.0000004, 0.0000003, 0.0000002, 0.0000001]\n",
    "\n",
    "for reg_result, class_result in zip(reg_results, class_results):\n",
    "    lookahead = reg_result['lookahead']\n",
    "    preds_stack_reg = reg_result['preds_stack']\n",
    "    preds_cnn_reg = reg_result['preds_cnn']\n",
    "    X_test_combo = reg_result['X_test_meta']\n",
    "    y_test = reg_result['true_values']\n",
    "\n",
    "    preds_stack_class = class_result['preds_stack']\n",
    "    preds_xgb_class   = class_result['preds_xgboost']\n",
    "    labeled = pd.read_parquet(f\"labeled_data_{lookahead}_session_less.parquet\")\n",
    "    df_backtest = labeled.copy()\n",
    "\n",
    "    print(f\"\\n🔎 LOOKAHEAD={lookahead} Regression Prediction Range:\")\n",
    "    print(f\"Stack Min: {np.min(preds_stack_reg):.6f} | Max: {np.max(preds_stack_reg):.6f}\")\n",
    "    print(f\"CNN   Min: {np.min(preds_cnn_reg):.6f} | Max: {np.max(preds_cnn_reg):.6f}\")\n",
    "    print(f\"Classification Unique Labels: {np.unique(preds_stack_class)}\")\n",
    "\n",
    "    for params in combinations:\n",
    "        for thresh in thresholds:\n",
    "            results = evaluate_combo(\n",
    "                X_test=X_test_combo,\n",
    "                preds_stack=preds_stack_reg,\n",
    "                preds_cnn=preds_cnn_reg,\n",
    "                preds_class=preds_stack_class,\n",
    "                preds_class_xgboost=preds_xgb_class,\n",
    "                labeled=labeled,\n",
    "                df=df_backtest,\n",
    "                avoid_funcs=avoid_funcs,\n",
    "                SL_ATR_MULT=params['SL_ATR_MULT'],\n",
    "                TP_ATR_MULT=params['TP_ATR_MULT'],\n",
    "                TRAIL_START_MULT=params['TRAIL_START_MULT'],\n",
    "                TRAIL_STOP_MULT=params['TRAIL_STOP_MULT'],\n",
    "                TICK_VALUE=params['TICK_VALUE'],\n",
    "                is_same_session=is_same_session,\n",
    "                long_thresh=thresh,\n",
    "                short_thresh=-thresh,\n",
    "                base_contracts=1,\n",
    "                max_contracts=5,\n",
    "                skip_weak_conf=True,\n",
    "                weak_conf_zscore=0.2\n",
    "            )\n",
    "\n",
    "            results['params'] = params\n",
    "            results['threshold'] = thresh\n",
    "            results['lookahead'] = lookahead\n",
    "            all_combo_results.append(results)\n",
    "\n",
    "            print(f\"\\n✅ LOOKAHEAD={lookahead} | Threshold={thresh}\")\n",
    "            print(f\"PnL: ${results['pnl']:.2f}\")\n",
    "            print(f\"Trades: {results['trades']}\")\n",
    "            print(f\"Win Rate: {results['win_rate']:.2%}\")\n",
    "            print(f\"Expectancy: {results['expectancy']:.2f}\")\n",
    "            print(f\"Profit Factor: {results['profit_factor']:.2f}\")\n",
    "            print(f\"Sharpe Ratio: {results['sharpe']:.2f}\")\n",
    "            print(f\"Long Trades: {results['long_trades']} | Short Trades: {results['short_trades']}\")\n",
    "\n",
    "            print(\"Avoid Hits:\")\n",
    "            for name, count in results['avoid_hits'].items():\n",
    "                print(f\" - {name}: {count}\")\n",
    "\n",
    "            if not results['results'].empty and 'pnl' in results['results'].columns:\n",
    "                print(\"\\n🔢 Top 5 PnL trades:\")\n",
    "                print(results['results'].sort_values(by='pnl', ascending=False).head(5))\n",
    "\n",
    "                print(\"\\n🔻 Bottom 5 PnL trades:\")\n",
    "                print(results['results'].sort_values(by='pnl', ascending=True).head(5))\n",
    "            else:\n",
    "                print(\"\\n⚠️ No trades executed, skipping PnL trade breakdown.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for result in lookahead_results:\n",
    "#     stack_preds = result['stack'].predict(X_test_scaled)\n",
    "#     rf_preds = result['models']['rf'].predict(X_test_scaled)\n",
    "#     xgb_preds = result['models']['xgb'].predict(X_test_scaled)\n",
    "#     enet_preds = result['models']['elasticnet'].predict(X_test_scaled)\n",
    "    \n",
    "#     plt.figure(figsize=(12, 4))\n",
    "#     plt.plot(rf_preds[:100], label='RF')\n",
    "#     plt.plot(xgb_preds[:100], label='XGB')\n",
    "#     plt.plot(enet_preds[:100], label='ElasticNet')\n",
    "#     plt.plot(stack_preds[:100], label='Stack', linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for run in lookahead_results:\n",
    "#     for r in run['results']:\n",
    "#         print(r)\n",
    "#         df = r['results'].copy()\n",
    "#         df = df.sort_values(by='entry_time')\n",
    "#         df['cumulative_pnl'] = df['pnl'].cumsum()\n",
    "\n",
    "#         if df['cumulative_pnl'].iloc[-1] > 0 and r['sharpe'] > 10 and r['trades'] > 150 and r['win_rate'] > 0.55 and r['profit_factor'] > 1.5 and r['expectancy'] > 0.5 and r['pnl'] > 50000:\n",
    "#                 plt.figure(figsize=(12, 4))\n",
    "#                 plt.plot(df['entry_time'], df['cumulative_pnl'], label='Cumulative PnL', color='green')\n",
    "#                 plt.title(f\"PnL | Lookahead={run['lookahead']} | Sharpe={r['sharpe']:.2f}\")\n",
    "#                 plt.xlabel(\"Datetime\")\n",
    "#                 plt.ylabel(\"PnL\")\n",
    "#                 plt.grid(True)\n",
    "#                 plt.legend()\n",
    "#                 plt.tight_layout()\n",
    "#                 plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best result holder by lookahead value\n",
    "# best_by_lookahead = {\n",
    "#     5: {'win_rate': float('-inf'), 'result': None},\n",
    "#     15: {'win_rate': float('-inf'), 'result': None}\n",
    "# }\n",
    "\n",
    "# # Fill best_by_lookahead from results\n",
    "# for run in lookahead_results:\n",
    "#     lookahead = run['lookahead']\n",
    "#     if lookahead in best_by_lookahead:\n",
    "#         for r in run['results']:\n",
    "#             if r['win_rate'] > best_by_lookahead[lookahead]['win_rate']:\n",
    "#                 best_by_lookahead[lookahead] = {\n",
    "#                     'win_rate': r['win_rate'],\n",
    "#                     'result': r,\n",
    "#                     'lookahead': lookahead\n",
    "#                 }\n",
    "\n",
    "# # Display results nicely\n",
    "# for lookahead in [5]:\n",
    "#     best = best_by_lookahead[lookahead]\n",
    "#     if best['result']:\n",
    "#         df = best['result']['results'].copy()\n",
    "#         df = df.sort_values(by='entry_time')\n",
    "#         df['cumulative_pnl'] = df['pnl'].cumsum()\n",
    "\n",
    "#         # Set float format for readable output\n",
    "#         pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "#         print(f\"\\n🏆 Best Win Rate Result for Lookahead={lookahead}\")\n",
    "#         print(f\"Win Rate: {best['win_rate']:.2%}\")\n",
    "#         print(f\"PnL: {best['result']['pnl']:.2f}\")\n",
    "#         print(f\"Trades: {best['result']['trades']}\")\n",
    "#         print(f\"Sharpe: {best['result']['sharpe']:.2f}\")\n",
    "#         print(f\"Expectancy: {best['result']['expectancy']:.2f}\")\n",
    "#         print(f\"Profit Factor: {best['result']['profit_factor']:.2f}\")\n",
    "#         print(f\"Params: {best['result']['params']}\")\n",
    "\n",
    "#         print(\"\\n🧾 All Trades from Best Win Rate Result:\")\n",
    "#         print(df[['entry_time', 'exit_time', 'side', 'entry_price', 'exit_price',\n",
    "#                   'pnl', 'mfe', 'mae', 'cumulative_pnl']].to_string(index=False))\n",
    "\n",
    "#         # Plot cumulative PnL\n",
    "#         plt.figure(figsize=(12, 4))\n",
    "#         plt.plot(df['entry_time'], df['cumulative_pnl'], label='Cumulative PnL', color='blue')\n",
    "#         plt.title(f\"Best Win Rate Run | Lookahead={lookahead} | Win Rate={best['win_rate']:.2%}\")\n",
    "#         plt.xlabel(\"Datetime\")\n",
    "#         plt.ylabel(\"Cumulative PnL\")\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         print(f\"No valid result found for Lookahead={lookahead}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.corrcoef([lookahead_results['preds_rf'], lookahead_results['preds_xgb'], lookahead_results['preds_elasticnet']])\n",
    "# preds_matrix = np.vstack([lookahead_results['preds_rf'], lookahead_results['preds_xgb'], lookahead_results['preds_elasticnet']])\n",
    "# corr_matrix = np.corrcoef(preds_matrix)\n",
    "\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# sns.heatmap(corr_matrix, annot=True, xticklabels=['RF', 'XGB', 'ENet'], yticklabels=['RF', 'XGB', 'ENet'], cmap='coolwarm', fmt=\".2f\")\n",
    "# plt.title(\"Correlation Between Base Model Predictions\")\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predictions\n",
    "# # y_pred = best_lookahead.predict(X_test)\n",
    "# best_lookahead = max(lookahead_results, key=lambda x: max(r['pnl'] for r in x['results']))\n",
    "# y_pred = best_lookahead['stack'].predict(X_test_scaled)\n",
    "\n",
    "# # Confusion Matrix\n",
    "# labels = sorted(class_mapping)  # Make sure the order matches\n",
    "# cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "\n",
    "# # Display Confusion Matrix\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "# plt.xlabel(\"Predicted\")\n",
    "# plt.ylabel(\"True\")\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "# plt.show()\n",
    "\n",
    "# # Classification Report\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred, labels=labels, digits=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
