{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import platform\n",
    "import numpy as np\n",
    "from ta.volatility import AverageTrueRange\n",
    "from ta.momentum    import RSIIndicator\n",
    "from ta.trend       import MACD, EMAIndicator, ADXIndicator\n",
    "from ta.volatility  import AverageTrueRange, BollingerBands\n",
    "from itertools import product\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, root_mean_squared_error, mean_squared_error, mean_absolute_error, r2_score, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.inspection import permutation_importance\n",
    "import optuna\n",
    "import joblib\n",
    "import json\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*There are no meaningful features.*\", category=UserWarning)\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "# === Load Data ===\n",
    "folder_path = \"./../data/\"\n",
    "column_names = ['datetime', 'open', 'high', 'low', 'close', 'volume']\n",
    "df_list = []\n",
    "\n",
    "system = platform.system()\n",
    "# Set emoji-compatible font based on OS\n",
    "if system == 'Windows':\n",
    "    plt.rcParams['font.family'] = 'Segoe UI Emoji'\n",
    "elif system == 'Linux':\n",
    "    plt.rcParams['font.family'] = 'Noto Color Emoji'  # if installed\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(('.csv', '.txt')):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path, sep=';', header=None, names=column_names)\n",
    "        df['source_file'] = filename\n",
    "        df_list.append(df)\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], utc=True).dt.tz_convert('America/New_York')\n",
    "\n",
    "df = df.drop_duplicates(subset='datetime', keep='first').reset_index(drop=True)\n",
    "df = df.sort_values('datetime').reset_index(drop=True)\n",
    "df[['open', 'high', 'low', 'close', 'volume']] = df[['open', 'high', 'low', 'close', 'volume']].astype(float)\n",
    "\n",
    "# Base time features\n",
    "df['hour'] = df['datetime'].dt.hour + df['datetime'].dt.minute / 60\n",
    "df['minute'] = df['datetime'].dt.minute\n",
    "df['day_of_week'] = df['datetime'].dt.dayofweek  # 0 = Monday\n",
    "\n",
    "# Custom session flags (adjust if needed)       # Regular Trading Hours\n",
    "df['is_premarket'] = df['hour'].between(7, 9.5)\n",
    "df['is_lunch'] = df['hour'].between(11.5, 13.5)\n",
    "df['is_postmarket'] = df['hour'].between(15.5, 20)\n",
    "df['is_after_hours'] = df['hour'].between(20, 23.5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize features or indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ATR + Volatility Context ===\n",
    "df['atr_5'] = AverageTrueRange(df['high'], df['low'], df['close'], window=5).average_true_range()\n",
    "df['atr_pct'] = df['atr_5'] / df['close']  # normalized ATR\n",
    "\n",
    "df['candle_range'] = (df['high'] - df['low'])\n",
    "\n",
    "# === Choppiness Index (Trend vs. Noise) ===\n",
    "def choppiness_index(high, low, close, length=14):\n",
    "    tr = AverageTrueRange(high=high, low=low, close=close, window=length).average_true_range()\n",
    "    atr_sum = tr.rolling(length).sum()\n",
    "    high_max = high.rolling(length).max()\n",
    "    low_min = low.rolling(length).min()\n",
    "    return 100 * np.log10(atr_sum / (high_max - low_min)) / np.log10(length)\n",
    "\n",
    "df['chop_index'] = choppiness_index(df['high'], df['low'], df['close'], length=14)\n",
    "\n",
    "# === EMA-Based Features ===\n",
    "df['ema_9'] = df['close'].ewm(span=9, adjust=False).mean()\n",
    "df['ema_dist'] = (df['close'] - df['ema_9'])\n",
    "\n",
    "# === Time Features ===\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['is_afternoon'] = (df['hour'] >= 12).astype(int)\n",
    "df['is_morning'] = (df['hour'] < 12).astype(int)\n",
    "\n",
    "# === Volume-based features ===\n",
    "df['volume'] = df['volume'].astype(float)\n",
    "df['volume_delta'] = df['volume'].diff()\n",
    "df['volume_delta_ema'] = df['volume_delta'].ewm(span=10, adjust=False).mean()\n",
    "\n",
    "# === Bollinger Band metrics ===\n",
    "bb = BollingerBands(close=df['close'], window=20, window_dev=2)\n",
    "df['bollinger_width'] = (bb.bollinger_hband() - bb.bollinger_lband())\n",
    "\n",
    "# === EMA slope ===\n",
    "ema = EMAIndicator(close=df['close'], window=21)\n",
    "df['ema_21'] = ema.ema_indicator()\n",
    "df['ema_slope'] = df['ema_21'].diff()\n",
    "\n",
    "# === VWAP (Volume Weighted Average Price)\n",
    "vwap_numerator = (df['volume'] * (df['high'] + df['low'] + df['close']) / 3).cumsum()\n",
    "vwap_denominator = df['volume'].cumsum()\n",
    "df['vwap'] = vwap_numerator / (vwap_denominator + 1e-9)\n",
    "\n",
    "# === Candlestick features\n",
    "df['body_pct'] = np.abs(df['close'] - df['open']) / (df['high'] - df['low'] + 1e-9)\n",
    "df['price_vs_vwap'] = df['close'] - df['vwap']\n",
    "\n",
    "# # === Strategy Setup ===\n",
    "param_grid_strategy = {\n",
    "    'SL_ATR_MULT': [1.0, 1.5, 0.5],\n",
    "    'TP_ATR_MULT': [2.0, 3.0, 4.0],\n",
    "    'TRAIL_START_MULT': [0.5, 1.0],\n",
    "    'TRAIL_STOP_MULT': [0.5, 1.0],\n",
    "    'TICK_VALUE': [5], \n",
    "}\n",
    "\n",
    "keys, values = zip(*param_grid_strategy.items())\n",
    "combinations = [dict(zip(keys, v)) for v in product(*values)]\n",
    "\n",
    "features = [\n",
    "    'atr_5', 'atr_pct', 'ema_dist',\n",
    "    'chop_index',\n",
    "    'volume', 'volume_delta_ema',\n",
    "    'bollinger_width',\n",
    "    'ema_slope', 'body_pct',\n",
    "    'price_vs_vwap', 'vwap',\n",
    "]\n",
    "\n",
    "\n",
    "# Load CSV of high-impact events\n",
    "# Load news data\n",
    "# news_df = pd.read_csv(\"high_impact_us_news.csv\", parse_dates=[\"datetime\"])\n",
    "\n",
    "# # Localize datetime to New York timezone\n",
    "# news_df[\"start_time\"] = pd.to_datetime(news_df[\"datetime\"]).dt.tz_localize(\"America/New_York\")\n",
    "\n",
    "# # Assume each news event blocks 30 minutes after its start\n",
    "# news_df[\"end_time\"] = news_df[\"start_time\"] + pd.Timedelta(minutes=15)\n",
    "\n",
    "# # Now create list of blackout windows\n",
    "# news_windows = list(zip(news_df[\"start_time\"], news_df[\"end_time\"]))\n",
    "\n",
    "def avoid_news(row):\n",
    "    ts = row[\"datetime\"]\n",
    "    return any(start <= ts <= end for (start, end) in news_windows)\n",
    "\n",
    "def avoid_hour_18_19(row):\n",
    "    \"\"\"\n",
    "    Avoid trading in the first hour of the session (18:00 to 19:00 inclusive).\n",
    "    \"\"\"\n",
    "    if not pd.api.types.is_datetime64_any_dtype(row['datetime']):\n",
    "        return False\n",
    "    hour = row['datetime'].hour\n",
    "    return hour == 18\n",
    "\n",
    "avoid_funcs = {\n",
    "    #'avoid_hour_18_19': avoid_hour_18_19\n",
    "    #'news_window': avoid_news,\n",
    "}\n",
    "\n",
    "def session_key(ts: pd.Timestamp) -> pd.Timestamp:\n",
    "    # shift back 18 h, then floor to midnight to get a unique session ‚Äúdate‚Äù\n",
    "    return (ts - timedelta(hours=18)).normalize()\n",
    "\n",
    "def is_same_session(start_time: pd.Timestamp, end_time: pd.Timestamp) -> bool:\n",
    "    return session_key(start_time) == session_key(end_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare Combo function for serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression_combo(\n",
    "    X_test, preds, labeled, df,\n",
    "    avoid_funcs,\n",
    "    SL_ATR_MULT, TP_ATR_MULT, TRAIL_START_MULT, TRAIL_STOP_MULT, TICK_VALUE,\n",
    "    is_same_session,\n",
    "    long_thresh=0.003,\n",
    "    short_thresh=-0.003,\n",
    "    base_contracts=1,\n",
    "    max_contracts=5,\n",
    "    skip_weak_conf=False,\n",
    "    weak_conf_zscore=0.2\n",
    "):\n",
    "    temp_trades_data = []\n",
    "    skipped_trades = 0\n",
    "    avoid_hits = defaultdict(int)\n",
    "    long_trades = 0\n",
    "    short_trades = 0\n",
    "\n",
    "    i = 0\n",
    "    X_test_idx = X_test.index.to_list()\n",
    "    preds_array = np.array(preds)\n",
    "\n",
    "    # === Calculate z-score confidence ===\n",
    "    zscores = (preds_array - preds_array.mean()) / (preds_array.std() + 1e-9)\n",
    "    conf_scores = np.clip(np.abs(zscores), 0, 2.0)\n",
    "    position_sizes = base_contracts + (max_contracts - base_contracts) * (conf_scores / 2.0)\n",
    "    position_sizes = np.round(position_sizes, 2)\n",
    "\n",
    "\n",
    "    for i, idx in enumerate(X_test_idx):\n",
    "        #idx = X_test_idx[i]\n",
    "        row = labeled.loc[idx]\n",
    "\n",
    "        if idx + 1 >= len(df):\n",
    "            skipped_trades += 1\n",
    "            continue\n",
    "\n",
    "        pred_return = preds_array[i]\n",
    "        conf = conf_scores[i]\n",
    "        size = position_sizes[i]\n",
    "\n",
    "        # Skip weak confidence signals if enabled\n",
    "        if skip_weak_conf and conf < weak_conf_zscore:\n",
    "            skipped_trades += 1\n",
    "            continue\n",
    "\n",
    "        if pred_return >= long_thresh:\n",
    "            side = 'long'\n",
    "            long_trades += 1\n",
    "        elif pred_return <= short_thresh:\n",
    "            side = 'short'\n",
    "            short_trades += 1\n",
    "        else:\n",
    "            i += 1\n",
    "            continue  # skip neutral signals\n",
    "\n",
    "        # Trade filters\n",
    "        skip_trade = False\n",
    "        for name, f in avoid_funcs.items():\n",
    "            try:\n",
    "                if f(row):\n",
    "                    avoid_hits[name] += 1\n",
    "                    skip_trade = True\n",
    "            except:\n",
    "                continue\n",
    "        if skip_trade:\n",
    "            skipped_trades += 1\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # --- Trade Simulation ---\n",
    "        entry_price = df.loc[idx + 1, 'open']\n",
    "        entry_time = df.loc[idx + 1, 'datetime']\n",
    "        atr = row['atr_5']\n",
    "\n",
    "        # Stop Loss (fixed volatility-based)\n",
    "        sl_price = entry_price - SL_ATR_MULT * atr if side == 'long' else entry_price + SL_ATR_MULT * atr\n",
    "\n",
    "        # Take Profit (dynamic, from model prediction, clipped)\n",
    "        expected_move = abs(pred_return) * entry_price\n",
    "        min_tp = 0.001 * entry_price  # minimum 0.1% move\n",
    "        max_tp = TP_ATR_MULT * atr\n",
    "        tp_move = np.clip(expected_move, min_tp, max_tp)\n",
    "        tp_price = entry_price + tp_move if side == 'long' else entry_price - tp_move\n",
    "\n",
    "        # Trailing logic\n",
    "        trail_trigger = entry_price + TRAIL_START_MULT * atr if side == 'long' else entry_price - TRAIL_START_MULT * atr\n",
    "        trail_stop = None\n",
    "\n",
    "        max_price, min_price = entry_price, entry_price\n",
    "        exit_price, exit_time = None, None\n",
    "\n",
    "        fwd_idx = idx + 1\n",
    "        while fwd_idx < len(df):\n",
    "            fwd_row = df.loc[fwd_idx]\n",
    "            max_price = max(max_price, fwd_row['high'])\n",
    "            min_price = min(min_price, fwd_row['low'])\n",
    "\n",
    "            if (side == 'long' and fwd_row['low'] <= sl_price) or (side == 'short' and fwd_row['high'] >= sl_price):\n",
    "                exit_price = sl_price\n",
    "                exit_time = fwd_row['datetime']\n",
    "                break\n",
    "\n",
    "            if (side == 'long' and fwd_row['high'] >= tp_price) or (side == 'short' and fwd_row['low'] <= tp_price):\n",
    "                exit_price = tp_price\n",
    "                exit_time = fwd_row['datetime']\n",
    "                break\n",
    "\n",
    "            if side == 'long' and fwd_row['high'] >= trail_trigger:\n",
    "                trail_stop = fwd_row['close'] - TRAIL_STOP_MULT * atr\n",
    "            if side == 'short' and fwd_row['low'] <= trail_trigger:\n",
    "                trail_stop = fwd_row['close'] + TRAIL_STOP_MULT * atr\n",
    "\n",
    "            if trail_stop:\n",
    "                if (side == 'long' and fwd_row['low'] <= trail_stop) or (side == 'short' and fwd_row['high'] >= trail_stop):\n",
    "                    exit_price = trail_stop\n",
    "                    exit_time = fwd_row['datetime']\n",
    "                    break\n",
    "\n",
    "            fwd_idx += 1\n",
    "\n",
    "        if exit_price is None:\n",
    "            exit_price = df.loc[len(df) - 1, 'close']\n",
    "            exit_time = df.loc[len(df) - 1, 'datetime']\n",
    "\n",
    "        if not is_same_session(entry_time, exit_time):\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        GROSS_PNL = (exit_price - entry_price) * TICK_VALUE * size if side == 'long' else (entry_price - exit_price) * TICK_VALUE * size\n",
    "        COMMISSION = 3.98 * size\n",
    "        pnl = GROSS_PNL - COMMISSION\n",
    "\n",
    "        mfe = max_price - entry_price if side == 'long' else entry_price - min_price\n",
    "        mae = entry_price - min_price if side == 'long' else max_price - entry_price\n",
    "\n",
    "        temp_trades_data.append({\n",
    "            'entry_time': entry_time,\n",
    "            'exit_time': exit_time,\n",
    "            'side': side,\n",
    "            'entry_price': entry_price,\n",
    "            'exit_price': exit_price,\n",
    "            'pnl': pnl,\n",
    "            'mfe': mfe,\n",
    "            'mae': mae,\n",
    "            'gross_pnl': GROSS_PNL,\n",
    "            'pred_return': pred_return,\n",
    "            'confidence': conf,\n",
    "            'position_size': size,\n",
    "        })\n",
    "\n",
    "        while i < len(X_test_idx) and labeled.loc[X_test_idx[i]]['datetime'] <= exit_time:\n",
    "            i += 1\n",
    "        continue\n",
    "\n",
    "    # === Metrics ===\n",
    "    results = pd.DataFrame(temp_trades_data)\n",
    "    pnl_total = results['pnl'].sum() if not results.empty else 0\n",
    "    trades = len(results)\n",
    "    win_rate = (results['pnl'] > 0).mean() if not results.empty else 0\n",
    "    expectancy = results['pnl'].mean() if not results.empty else 0\n",
    "    profit_factor = results[results['pnl'] > 0]['pnl'].sum() / abs(results[results['pnl'] < 0]['pnl'].sum()) if not results.empty and (results['pnl'] < 0).any() else np.nan\n",
    "    sharpe = results['pnl'].mean() / (results['pnl'].std() + 1e-9) * np.sqrt(trades) if trades > 1 else 0\n",
    "\n",
    "    return {\n",
    "        'pnl': pnl_total,\n",
    "        'trades': trades,\n",
    "        'win_rate': win_rate,\n",
    "        'expectancy': expectancy,\n",
    "        'profit_factor': profit_factor,\n",
    "        'sharpe': sharpe,\n",
    "        'long_trades': long_trades,\n",
    "        'short_trades': short_trades,\n",
    "        'avoid_hits': dict(avoid_hits),\n",
    "        'threshold': long_thresh,\n",
    "        'results': results\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_future_return_labels(df: pd.DataFrame, lookahead: int, is_same_session_fn) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Computes future return (regression label) and trade direction for a given lookahead period.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with at least ['datetime', 'close']\n",
    "    - lookahead: How many bars ahead to evaluate performance\n",
    "    - is_same_session_fn: Function that checks if two datetimes are in the same session\n",
    "\n",
    "    Returns:\n",
    "    - df_labeled: DataFrame with ['future_return', 'trade_dir'] added\n",
    "    \"\"\"\n",
    "    future_returns = []\n",
    "    trade_dirs = []\n",
    "\n",
    "    for idx in range(len(df) - lookahead):\n",
    "        entry_price = df['close'].iloc[idx]\n",
    "        future_price = df['close'].iloc[idx + lookahead]\n",
    "\n",
    "        if pd.isna(entry_price) or pd.isna(future_price):\n",
    "            future_returns.append(np.nan)\n",
    "            trade_dirs.append(None)\n",
    "            continue\n",
    "\n",
    "        future_return = (future_price / entry_price) - 1\n",
    "        future_returns.append(future_return)\n",
    "        trade_dirs.append('long' if future_return > 0 else 'short')\n",
    "\n",
    "    # Align output with original df\n",
    "    df_labeled = df.iloc[:len(future_returns)].copy()\n",
    "    df_labeled['future_return'] = future_returns\n",
    "    df_labeled['trade_dir'] = trade_dirs\n",
    "\n",
    "    # Drop NaNs\n",
    "    df_labeled = df_labeled.dropna(subset=['future_return'])\n",
    "\n",
    "    return df_labeled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tp_sl_labels_with_strength(df: pd.DataFrame, lookahead: int, is_same_session_fn,\n",
    "    sl_atr_mult: float = 1.0,\n",
    "    tp_atr_mult: float = 2.0,\n",
    "    strong_tp_mult: float = 4.0  # e.g., 2x ATR SL (twice as far as SL)\n",
    ") -> pd.DataFrame:\n",
    "    labels = []\n",
    "    valid_idxs = []\n",
    "\n",
    "    for i in range(len(df) - lookahead):\n",
    "        entry_time = df['datetime'].iloc[i]\n",
    "        end_time = df['datetime'].iloc[i + lookahead]\n",
    "\n",
    "        if not is_same_session_fn(entry_time, end_time):\n",
    "            continue\n",
    "\n",
    "        entry_price = df['close'].iloc[i]\n",
    "        atr = df['atr_5'].iloc[i]\n",
    "\n",
    "        sl = entry_price - sl_atr_mult * atr\n",
    "        tp = entry_price + tp_atr_mult * atr\n",
    "        strong_tp = entry_price + strong_tp_mult * atr\n",
    "\n",
    "        future = df.iloc[i+1:i+1+lookahead]\n",
    "        label = 0\n",
    "\n",
    "        for _, row in future.iterrows():\n",
    "            if row['low'] <= sl:\n",
    "                label = -1\n",
    "                break\n",
    "            if row['high'] >= strong_tp:\n",
    "                label = 2\n",
    "                break\n",
    "            if row['high'] >= tp:\n",
    "                label = 1\n",
    "                break\n",
    "\n",
    "        labels.append(label)\n",
    "        valid_idxs.append(i)\n",
    "\n",
    "    df_out = df.iloc[valid_idxs].copy()\n",
    "    df_out['tp_sl_label'] = labels\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookahead_values = [5, 15]\n",
    "\n",
    "def label_and_save(lookahead):\n",
    "    df_session = df.copy()\n",
    "    print(f\"Initial rows: {len(df_session)}\")\n",
    "\n",
    "    df_labeled = compute_future_return_labels(\n",
    "        df_session,\n",
    "        lookahead=lookahead,\n",
    "        is_same_session_fn=is_same_session\n",
    "    )\n",
    "    print(f\"‚û§ Rows after future_return: {len(df_labeled)} | Dropped: {len(df_session) - len(df_labeled)}\")\n",
    "\n",
    "\n",
    "    df_exec = compute_tp_sl_labels_with_strength(df_session, lookahead, is_same_session_fn=is_same_session)\n",
    "    print(f\"‚û§ Rows after tp_sl_label: {len(df_exec)} | Dropped: {len(df_session) - len(df_exec)}\")\n",
    "\n",
    "\n",
    "    df_combined = df_labeled.merge(df_exec[['datetime', 'tp_sl_label']], on='datetime', how='left')\n",
    "    print(f\"‚û§ Rows after merging: {len(df_combined)}\")\n",
    "    print(f\"‚û§ tp_sl_label NaNs after merge: {df_combined['tp_sl_label'].isna().sum()}\")\n",
    "\n",
    "    rows_before_final = len(df_combined)\n",
    "    df_final = df_combined.dropna(subset=['future_return', 'tp_sl_label'] + features)\n",
    "    print(f\"‚û§ Rows after final drop: {len(df_final)} | Dropped: {rows_before_final - len(df_final)}\")\n",
    "\n",
    "    # Step 5: Save parquet\n",
    "    df_final.to_parquet(f\"labeled_data_{lookahead}_session_less.parquet\")\n",
    "    print(f\"‚úÖ Saved labeled_data_{lookahead}_session_less.parquet with {len(df_final)} rows\")\n",
    "\n",
    "for lookahead in lookahead_values:\n",
    "    fname = f\"labeled_data_{lookahead}_session_less.parquet\"\n",
    "    if os.path.exists(fname):\n",
    "        print(f\"‚è≠Ô∏è File {fname} already exists. Skipping...\")\n",
    "        continue\n",
    "    print(f\"üì¶ Labeling {fname}...\")\n",
    "    label_and_save(lookahead)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overfit(model, X_tr, X_te, y_tr, y_te):\n",
    "    train_preds = model.predict(X_tr)\n",
    "    test_preds = model.predict(X_te)\n",
    "    train_mse = mean_squared_error(y_tr, train_preds)\n",
    "    test_mse = mean_squared_error(y_te, test_preds)\n",
    "    ratio = test_mse / train_mse if train_mse != 0 else float('inf')\n",
    "\n",
    "    print(f\"\\nüìâ Overfitting check:\")\n",
    "    print(f\"Train MSE: {train_mse:.8f}\")\n",
    "    print(f\"Test MSE: {test_mse:.8f}\")\n",
    "    print(f\"Overfit ratio (Test / Train): {ratio:.2f}\")\n",
    "    if ratio > 1.5:\n",
    "        print(\"‚ö†Ô∏è Potential overfitting detected.\")\n",
    "    elif ratio < 0.7:\n",
    "        print(\"‚ö†Ô∏è Possibly underfitting (too simple).\")\n",
    "    else:\n",
    "        print(\"‚úÖ Generalization looks reasonable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_oof_predictions(models, X, y, n_splits=3):\n",
    "    oof_preds = np.zeros((X.shape[0], len(models)))\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        for train_idx, val_idx in tscv.split(X):\n",
    "            model.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "            oof_preds[val_idx, i] = model.predict(X.iloc[val_idx])\n",
    "    \n",
    "    return pd.DataFrame(oof_preds, index=y.index)  # ‚úÖ FIX is here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lookahead_for_session(LOOKAHEAD):\n",
    "    labeled = pd.read_parquet(f\"labeled_data_{LOOKAHEAD}_session_less.parquet\")\n",
    "    labeled = labeled.replace([np.inf, -np.inf], np.nan)\n",
    "    labeled = labeled.dropna(subset=features + ['future_return', 'tp_sl_label'])\n",
    "\n",
    "    cutoff_date = pd.Timestamp(\"2025-01-01\", tz=\"America/New_York\")\n",
    "    train = labeled[labeled['datetime'] < cutoff_date]\n",
    "    test = labeled[labeled['datetime'] >= cutoff_date]\n",
    "\n",
    "    y_train_class = train['tp_sl_label']\n",
    "    y_test_class = test['tp_sl_label']\n",
    "\n",
    "    X_train_full, y_train_reg = train[features], train['future_return']\n",
    "    X_test_full, y_test_reg = test[features], test['future_return']\n",
    "\n",
    "    print(f\"Train range: {train['datetime'].min()} to {train['datetime'].max()} | Rows: {len(train)}\")\n",
    "    print(f\"Test range: {test['datetime'].min()} to {test['datetime'].max()} | Rows: {len(test)}\")\n",
    "\n",
    "    ###########################\n",
    "    ###### Classifiers ########\n",
    "    ###########################\n",
    "\n",
    "    def tune_catboost_classifier(X_train, y_train):\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'iterations': 1000,\n",
    "                'depth': trial.suggest_int('depth', 4, 8),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 5.0),\n",
    "                'bootstrap_type': 'Bayesian',\n",
    "                'random_strength': trial.suggest_float('random_strength', 1.0, 5.0),\n",
    "                'bagging_temperature': trial.suggest_float('bagging_temperature', 0.1, 1.0),\n",
    "                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100)\n",
    "            }\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=3)\n",
    "            scores = []\n",
    "\n",
    "            for train_idx, val_idx in tscv.split(X_train):\n",
    "                X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "                model = CatBoostClassifier(**params, random_state=42)\n",
    "                model.fit(X_tr, y_tr, eval_set=(X_val, y_val))\n",
    "\n",
    "                probs = model.predict_proba(X_val)\n",
    "                y_val_bin = label_binarize(y_val, classes=model.classes_)\n",
    "\n",
    "                score = roc_auc_score(y_val_bin, probs, multi_class='ovr', average='macro')\n",
    "                scores.append(score)\n",
    "\n",
    "            return -np.mean(scores)\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction=\"minimize\",\n",
    "            study_name=\"catboost_classifier_opt\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=5),\n",
    "            storage=f\"sqlite:///catboost_classifier_opt_study{LOOKAHEAD}_session_less.db\",\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=25)\n",
    "        return study.best_params\n",
    "    \n",
    "    def tune_lgbm_classifier(X_train, y_train):\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                \"n_estimators\": 1000,\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
    "                \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 256),\n",
    "                \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "                \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.7, 1.0),\n",
    "                \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "                \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 1.0)\n",
    "            }\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=3)\n",
    "            scores = []\n",
    "\n",
    "            for train_idx, val_idx in tscv.split(X_train):\n",
    "                X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "                model = LGBMClassifier(**params, random_state=42)\n",
    "                model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)])\n",
    "\n",
    "                probs = model.predict_proba(X_val)\n",
    "                y_val_bin = label_binarize(y_val, classes=model.classes_)\n",
    "\n",
    "                score = roc_auc_score(y_val_bin, probs, multi_class='ovr', average='macro')\n",
    "                scores.append(score)\n",
    "\n",
    "            return -np.mean(scores)\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction=\"minimize\",\n",
    "            study_name=\"lgbm_classifier_opt\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=5),\n",
    "            storage=f\"sqlite:///lgbm_classifier_opt_study{LOOKAHEAD}_session_less.db\",\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=5)\n",
    "        return study.best_params\n",
    "\n",
    "    def tune_xgb_classifier(X_train, y_train):\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                \"n_estimators\": 1000,\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
    "                \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "                \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "                \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "                \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 1.0)\n",
    "            }\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=3)\n",
    "            scores = []\n",
    "\n",
    "            for train_idx, val_idx in tscv.split(X_train):\n",
    "                X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "                model = XGBClassifier(**params, eval_metric=\"auc\", random_state=42, use_label_encoder=False)\n",
    "                model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)])\n",
    "                preds = model.predict_proba(X_val)[:, 1]\n",
    "                score = roc_auc_score(y_val, preds)\n",
    "                scores.append(score)\n",
    "\n",
    "            return -np.mean(scores)\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction=\"minimize\",\n",
    "            study_name=\"xgb_classifier_opt\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=5),\n",
    "            storage=f\"sqlite:///xgb_classifier_opt_study{LOOKAHEAD}_session_less.db\",\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=25)\n",
    "        return study.best_params\n",
    "\n",
    "    def tune_rf_classifier(X_train, y_train):\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'n_estimators': 500,\n",
    "                'max_depth': trial.suggest_int('max_depth', 4, 20),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "                'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "            }\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=3)\n",
    "            scores = []\n",
    "\n",
    "            for train_idx, val_idx in tscv.split(X_train):\n",
    "                X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "                model = RandomForestClassifier(**params, random_state=42)\n",
    "                model.fit(X_tr, y_tr)\n",
    "                preds = model.predict_proba(X_val)[:, 1]\n",
    "                score = roc_auc_score(y_val, preds)\n",
    "                scores.append(score)\n",
    "\n",
    "            return -np.mean(scores)\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction=\"minimize\",\n",
    "            study_name=\"rf_classifier_opt\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=5),\n",
    "            storage=f\"sqlite:///rf_classifier_opt_study{LOOKAHEAD}_session_less.db\",\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=25)\n",
    "        return study.best_params\n",
    "\n",
    "    def tune_logreg_classifier(X_train, y_train):\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                \"C\": trial.suggest_float(\"C\", 1e-3, 10.0, log=True),\n",
    "                \"penalty\": \"l2\",\n",
    "                \"solver\": \"lbfgs\",\n",
    "                \"max_iter\": 1000\n",
    "            }\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=3)\n",
    "            scores = []\n",
    "\n",
    "            for train_idx, val_idx in tscv.split(X_train):\n",
    "                X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "                model = LogisticRegression(**params, random_state=42)\n",
    "                model.fit(X_tr, y_tr)\n",
    "                preds = model.predict_proba(X_val)[:, 1]\n",
    "                score = roc_auc_score(y_val, preds)\n",
    "                scores.append(score)\n",
    "\n",
    "            return -np.mean(scores)\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction=\"minimize\",\n",
    "            study_name=\"logreg_classifier_opt\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=5),\n",
    "            storage=f\"sqlite:///logreg_classifier_opt_study{LOOKAHEAD}_session_less.db\",\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=25)\n",
    "        return study.best_params\n",
    "\n",
    "    def tune_meta_classifier(X_meta, y_meta):\n",
    "        \"\"\"\n",
    "        Optuna-tune Logistic Regression meta-classifier for stacking.\n",
    "        Works on out-of-fold predicted probabilities from base classifiers.\n",
    "        \"\"\"\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                \"C\": trial.suggest_float(\"C\", 1e-4, 100.0, log=True),\n",
    "                \"penalty\": trial.suggest_categorical(\"penalty\", [\"l2\"]),\n",
    "                \"solver\": \"lbfgs\",\n",
    "                \"max_iter\": 1000\n",
    "            }\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=3)\n",
    "            scores = []\n",
    "\n",
    "            for train_idx, val_idx in tscv.split(X_meta):\n",
    "                X_tr, X_val = X_meta.iloc[train_idx], X_meta.iloc[val_idx]\n",
    "                y_tr, y_val = y_meta.iloc[train_idx], y_meta.iloc[val_idx]\n",
    "\n",
    "                model = LogisticRegression(**params, random_state=42)\n",
    "                model.fit(X_tr, y_tr)\n",
    "                preds = model.predict(X_val)\n",
    "                f1 = f1_score(y_val, preds, average=\"macro\")\n",
    "                scores.append(f1)\n",
    "\n",
    "            return np.mean(scores)\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\",\n",
    "            study_name=\"meta_logreg_stack_cls\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=5),\n",
    "            storage=\"sqlite:///meta_logreg_stack_cls.db\",\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=50)\n",
    "        return study.best_params\n",
    "\n",
    "    ###########################\n",
    "    ###### Regressors #########\n",
    "    ###########################\n",
    "\n",
    "    def tune_lightgbm(X_train, y_train):\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                \"n_estimators\": 2000,\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
    "                \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 256),\n",
    "                \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 1, 30),\n",
    "                \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "                \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.7, 1.0),\n",
    "                \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "                \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 1.0),\n",
    "                \"min_split_gain\": trial.suggest_float(\"min_split_gain\", 0.0, 0.01),\n",
    "                \"force_col_wise\": trial.suggest_categorical(\"force_col_wise\", [True, False])\n",
    "            }\n",
    "            tscv = TimeSeriesSplit(n_splits=3)\n",
    "            scores = []\n",
    "            for train_idx, val_idx in tscv.split(X_train):\n",
    "                X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "                model = LGBMRegressor(**params, random_state=42, n_jobs=-5)\n",
    "                model.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    eval_metric=\"rmse\"\n",
    "                )\n",
    "                preds = model.predict(X_val)\n",
    "                rmse = root_mean_squared_error(y_val, preds)\n",
    "                scores.append(rmse)\n",
    "            return np.mean(scores)\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction=\"minimize\",\n",
    "            study_name=\"lgbm_opt\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.SuccessiveHalvingPruner(min_resource=50, reduction_factor=4),\n",
    "            storage=f\"sqlite:///lgbm_opt_study{LOOKAHEAD}_session_less.db\",\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=5)\n",
    "        return study.best_params\n",
    "\n",
    "    def tune_catboost(X_train, y_train):\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'iterations': 2000,\n",
    "                'depth': trial.suggest_int('depth', 4, 8),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05, log=True),\n",
    "                'loss_function': 'RMSE',\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 3.0, 10.0),\n",
    "                'random_strength': trial.suggest_float('random_strength', 1.0, 5.0),\n",
    "                'bootstrap_type': 'Bayesian',\n",
    "                'bagging_temperature': trial.suggest_float('bagging_temperature', 0.1, 1.0),\n",
    "                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
    "            }\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=3)\n",
    "            scores = []\n",
    "\n",
    "            for train_idx, val_idx in tscv.split(X_train):\n",
    "                X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "                model = CatBoostRegressor(**params, random_state=42)\n",
    "                model.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    eval_set=(X_val, y_val),\n",
    "                    use_best_model=True,\n",
    "                    verbose=False,\n",
    "                    early_stopping_rounds=30\n",
    "                )\n",
    "                preds = model.predict(X_val)\n",
    "                rmse = root_mean_squared_error(y_val, preds)\n",
    "                scores.append(rmse)\n",
    "\n",
    "            return np.mean(scores)\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction='minimize',\n",
    "            study_name='catboost_opt',\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.SuccessiveHalvingPruner(min_resource=50, reduction_factor=4),\n",
    "            storage=f'sqlite:///catboost_opt_study{LOOKAHEAD}_session_less.db',\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=50)\n",
    "        return study.best_params\n",
    "\n",
    "    def tune_meta_regressor(X_meta, y_meta):\n",
    "        \"\"\"\n",
    "        Optuna-tune CatBoostRegressor as meta-learner for stacking.\n",
    "        \"\"\"\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'iterations': 2000,\n",
    "                'depth': trial.suggest_int('depth', 4, 8),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05, log=True),\n",
    "                'loss_function': 'RMSE',\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 3.0, 10.0),\n",
    "                'random_strength': trial.suggest_float('random_strength', 1.0, 5.0),\n",
    "                'bootstrap_type': 'Bayesian',\n",
    "                'bagging_temperature': trial.suggest_float('bagging_temperature', 0.1, 1.0),\n",
    "                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
    "            }\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=3)\n",
    "            scores = []\n",
    "\n",
    "            for train_idx, val_idx in tscv.split(X_meta):\n",
    "                X_tr, X_val = X_meta.iloc[train_idx], X_meta.iloc[val_idx]\n",
    "                y_tr, y_val = y_meta.iloc[train_idx], y_meta.iloc[val_idx]\n",
    "\n",
    "                model = CatBoostRegressor(**params, random_state=42)\n",
    "                model.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    eval_set=(X_val, y_val),\n",
    "                    use_best_model=True,\n",
    "                    verbose=False,\n",
    "                    early_stopping_rounds=30\n",
    "                )\n",
    "                preds = model.predict(X_val)\n",
    "                rmse = root_mean_squared_error(y_val, preds)\n",
    "                scores.append(rmse)\n",
    "\n",
    "            return np.mean(scores)\n",
    "\n",
    "        study = optuna.create_study(\n",
    "            direction='minimize',\n",
    "            study_name='meta_catboost_stack',\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=5),\n",
    "            storage=f'sqlite:///meta_catboost_stack_{lookahead}_session_less.db',\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        study.optimize(objective, n_trials=50)\n",
    "        return study.best_params\n",
    "    \n",
    "    ####### Shap Plotting\n",
    "    ####### REGRESSION #######\n",
    "    X_shap_train, X_shap_val, y_shap_train, y_shap_val = train_test_split(\n",
    "        X_train_full, y_train_reg, test_size=0.2, shuffle=False\n",
    "    )\n",
    "    \n",
    "    print(\"Training model for SHAP analysis...\")\n",
    "    shap_model = LGBMRegressor(n_estimators=300, learning_rate=0.05, max_depth=6, random_state=42)\n",
    "    shap_model.fit(X_shap_train, y_shap_train)\n",
    "\n",
    "    print(\"Computing SHAP values...\")\n",
    "    explainer = shap.Explainer(shap_model, X_shap_train)\n",
    "    shap_values = explainer(X_shap_val)\n",
    "\n",
    "    # Calculate average SHAP importance per feature\n",
    "    mean_shap = np.abs(shap_values.values).mean(axis=0)\n",
    "    top_idx = np.argsort(mean_shap)[::-1][:25]\n",
    "    top_features = X_shap_train.columns[top_idx].tolist()\n",
    "\n",
    "    shap.summary_plot(shap_values, X_shap_val)\n",
    "    shap.summary_plot(shap_values, X_shap_val, plot_type=\"bar\")\n",
    "    shap.plots.force(explainer(X_shap_val.iloc[0]), matplotlib=True)\n",
    "\n",
    "    print(\"Top SHAP Features:\", top_features)\n",
    "\n",
    "    ###########################\n",
    "    ###### Model Training #####\n",
    "    ###########################\n",
    "    X_train_combined = X_train_full[top_features]\n",
    "    print(len(X_train_combined))\n",
    "    X_test_combined = X_test_full[top_features]\n",
    "\n",
    "    ################################################\n",
    "    ####### Ensure index consistency\n",
    "    ####### REGRESSION #######\n",
    "    y_train_reg = y_train_reg.loc[X_train_combined.index]\n",
    "    print(len(y_train_reg))\n",
    "    y_test_reg = y_test_reg.loc[X_test_combined.index]\n",
    "    ####### CLASSIFICATION #######\n",
    "    y_train_class = y_train_class.loc[X_train_combined.index]\n",
    "    y_test_class = y_test_class.loc[X_test_combined.index]\n",
    "\n",
    "    ################################################\n",
    "    ####### Tune models\n",
    "    ####### REGRESSION #######\n",
    "    lgbm_params         = tune_lightgbm(X_train_combined, y_train_reg)\n",
    "    catboost_params     = tune_catboost(X_train_combined, y_train_reg)\n",
    "    ####### CLASSIFICATION #######\n",
    "    lgbm_params_class       = tune_lgbm_classifier(X_train_combined, y_train_class)\n",
    "    catboost_params_class   = tune_catboost_classifier(X_train_combined, y_train_class)\n",
    "    xgb_params_class       = tune_xgb_classifier(X_train_combined, y_train_class)\n",
    "    rf_params_class       = tune_rf_classifier(X_train_combined, y_train_class)\n",
    "    logreg_params_class       = tune_logreg_classifier(X_train_combined, y_train_class)\n",
    "\n",
    "    ################################################\n",
    "    ####### Train models\n",
    "    ####### REGRESSION #######\n",
    "    lgbm = LGBMRegressor(**lgbm_params, random_state=42, n_jobs=-5)\n",
    "    catboost = CatBoostRegressor(**catboost_params, random_state=42, verbose=0)\n",
    "    lgbm.fit(X_train_combined, y_train_reg)\n",
    "    catboost.fit(X_train_combined, y_train_reg)\n",
    "    ####### CLASSIFICATION #######\n",
    "    lgbm_clf     = LGBMClassifier(**lgbm_params_class, random_state=42)\n",
    "    catboost_clf = CatBoostClassifier(**catboost_params_class, random_state=42, verbose=0)\n",
    "    xgb_clf      = XGBClassifier(**xgb_params_class, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "    rf_clf       = RandomForestClassifier(**rf_params_class, random_state=42)\n",
    "    logreg_clf   = LogisticRegression(**logreg_params_class, random_state=42, max_iter=1000)\n",
    "    lgbm_clf.fit(X_train_combined, y_train_class)\n",
    "    catboost_clf.fit(X_train_combined, y_train_class)\n",
    "    xgb_clf.fit(X_train_combined, y_train_class)\n",
    "    rf_clf.fit(X_train_combined, y_train_class)\n",
    "    logreg_clf.fit(X_train_combined, y_train_class)\n",
    "    \n",
    "    ################################################\n",
    "    ####### Base models selection\n",
    "    X_meta_check = X_train_combined\n",
    "    ####### REGRESSION #######\n",
    "    base_models_reg = [\n",
    "        lgbm,\n",
    "       catboost\n",
    "    ]\n",
    "    filtered_models = []\n",
    "\n",
    "    for i, model in enumerate(base_models_reg):\n",
    "        try:\n",
    "            preds = model.predict(X_meta_check)\n",
    "            pred_std = np.std(preds)\n",
    "            print(f\"üìä Model {i} std: {pred_std:.6f}\")\n",
    "            if pred_std > 1e-4:\n",
    "                filtered_models.append((f\"model_{i}\", model))\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Skipping model_{i} due to low variance\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Model {i} failed: {e}\")\n",
    "    ####### CLASSIFICATION #######\n",
    "    base_models_class = [\n",
    "        lgbm_clf,\n",
    "       catboost_clf,\n",
    "       xgb_clf,\n",
    "       rf_clf,\n",
    "       logreg_clf\n",
    "    ]\n",
    "    filtered_models_class = []\n",
    "\n",
    "    for i, model in enumerate(base_models_class):\n",
    "        try:\n",
    "            preds = model.predict(X_meta_check)\n",
    "            pred_std = np.std(preds)\n",
    "            print(f\"üìä Model {i} std: {pred_std:.6f}\")\n",
    "            if pred_std > 1e-4:\n",
    "                filtered_models_class.append((f\"model_{i}\", model))\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Skipping model_{i} due to low variance\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Model {i} failed: {e}\")\n",
    "\n",
    "    ################################################\n",
    "    ####### OOF Predicition\n",
    "    ####### REGRESSION #######\n",
    "    base_models_only = [model for name, model in filtered_models]\n",
    "    base_models_preds_train = generate_oof_predictions(base_models_only, X_train_combined, y_train_reg)\n",
    "\n",
    "    print(\"\\nüîç Checking variance in OOF base model predictions:\")\n",
    "    print(base_models_preds_train.describe())\n",
    "    print(\"Std per model:\\n\", base_models_preds_train.std())\n",
    "    ####### CLASSIFICATION #######\n",
    "    base_models_only_class = [model for name, model in filtered_models_class]\n",
    "    base_models_preds_train_class = generate_oof_predictions(base_models_only_class, X_train_combined, y_train_class)\n",
    "\n",
    "    print(\"\\nüîç Checking variance in OOF base model predictions:\")\n",
    "    print(base_models_preds_train_class.describe())\n",
    "    print(\"Std per model:\\n\", base_models_preds_train_class.std())\n",
    "\n",
    "    ################################################\n",
    "    ####### Meta Params and Training\n",
    "    ####### REGRESSION #######\n",
    "    meta_params = tune_meta_regressor(base_models_preds_train, y_train_reg)\n",
    "    meta_model = CatBoostRegressor(**meta_params, random_state=42)\n",
    "\n",
    "    stack = StackingRegressor(\n",
    "        estimators=filtered_models,\n",
    "        final_estimator=meta_model,\n",
    "        n_jobs=-5\n",
    "    )\n",
    "    stack.fit(X_train_combined, y_train_reg)\n",
    "    ####### CLASSIFICATION #######\n",
    "    meta_params_class = tune_meta_classifier(base_models_preds_train, y_train_reg)\n",
    "    meta_model_class = LogisticRegression(**meta_params_class, random_state=42)\n",
    "\n",
    "    stack_class = StackingRegressor(\n",
    "        estimators=filtered_models_class,\n",
    "        final_estimator=meta_model_class,\n",
    "        n_jobs=-5\n",
    "    )\n",
    "    stack_class.fit(X_train_combined, y_train_reg)\n",
    "\n",
    "    ################################################\n",
    "    ####### Evaluate Model\n",
    "    def evaluate_model(name, model, Xtr, Xte, ytr, yte, scaled=False):\n",
    "        train_preds = model.predict(Xtr)\n",
    "        test_preds = model.predict(Xte)\n",
    "        train_mse = mean_squared_error(ytr, train_preds)\n",
    "        test_mse = mean_squared_error(yte, test_preds)\n",
    "        overfit_ratio = test_mse / train_mse if train_mse != 0 else float('inf')\n",
    "\n",
    "        print(f\"\\nüìä {name} Performance:\")\n",
    "        print(f\"Train MSE: {train_mse:.8f}\")\n",
    "        print(f\"Test MSE: {test_mse:.8f}\")\n",
    "        print(f\"Overfit ratio (Test / Train): {overfit_ratio:.2f}\")\n",
    "        if overfit_ratio > 1.5:\n",
    "            print(\"‚ö†Ô∏è Potential overfitting detected.\")\n",
    "        elif overfit_ratio < 0.7:\n",
    "            print(\"‚ö†Ô∏è Possibly underfitting.\")\n",
    "        else:\n",
    "            print(\"‚úÖ Generalization looks reasonable.\")\n",
    "        return test_preds\n",
    "    \n",
    "    def evaluate_classifier(name, model, Xtr, Xte, ytr, yte):\n",
    "        train_preds = model.predict(Xtr)\n",
    "        test_preds = model.predict(Xte)\n",
    "\n",
    "        train_acc = accuracy_score(ytr, train_preds)\n",
    "        test_acc = accuracy_score(yte, test_preds)\n",
    "        f1 = f1_score(yte, test_preds, average=\"macro\")\n",
    "\n",
    "        print(f\"\\nüìä {name} Classifier Performance:\")\n",
    "        print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "        print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"F1 Score (Macro): {f1:.4f}\")\n",
    "\n",
    "        if test_acc / (train_acc + 1e-9) > 1.5:\n",
    "            print(\"‚ö†Ô∏è Likely overfitting.\")\n",
    "        elif test_acc / (train_acc + 1e-9) < 0.7:\n",
    "            print(\"‚ö†Ô∏è Possibly underfitting.\")\n",
    "        else:\n",
    "            print(\"‚úÖ Generalization looks reasonable.\")\n",
    "\n",
    "        return test_preds\n",
    "    ####### REGRESSION #######\n",
    "    preds_lgbm = evaluate_model(\"LightGBM\", lgbm, X_train_combined, X_test_combined, y_train_reg, y_test_reg)\n",
    "    preds_catboost = evaluate_model(\"CatBoostRegressor\", catboost, X_train_combined, X_test_combined, y_train_reg, y_test_reg)\n",
    "    preds_stack = evaluate_model(\"Stacking Ensemble\", stack, X_train_combined, X_test_combined, y_train_reg, y_test_reg)\n",
    "    ####### CLASSIFICATION #######\n",
    "    # === Evaluate Classifiers ===\n",
    "    preds_lgbm_clf     = evaluate_classifier(\"LightGBM Classifier\", lgbm_clf, X_train_combined, X_test_combined, y_train_class, y_test_class)\n",
    "    preds_catboost_clf = evaluate_classifier(\"CatBoost Classifier\", catboost_clf, X_train_combined, X_test_combined, y_train_class, y_test_class)\n",
    "    preds_xgb_clf      = evaluate_classifier(\"XGBoost Classifier\", xgb_clf, X_train_combined, X_test_combined, y_train_class, y_test_class)\n",
    "    preds_rf_clf       = evaluate_classifier(\"Random Forest Classifier\", rf_clf, X_train_combined, X_test_combined, y_train_class, y_test_class)\n",
    "    preds_logreg_clf   = evaluate_classifier(\"Logistic Regression Classifier\", logreg_clf, X_train_combined, X_test_combined, y_train_class, y_test_class)\n",
    "    preds_stack_clf    = evaluate_classifier(\"Stacking Ensemble Classifier\", stack_class, X_train_combined, X_test_combined, y_train_class, y_test_class)\n",
    "\n",
    "\n",
    "    ################################################\n",
    "    ####### Target Distribution\n",
    "    ####### CLASSIFICATION #######\n",
    "    print(\"\\nüîç Classifier Insights\")\n",
    "\n",
    "    if hasattr(stack_class, \"feature_importances_\"):\n",
    "        importances = pd.Series(stack_class.feature_importances_, index=X_train_combined.columns)\n",
    "        importances = importances.sort_values(ascending=False)\n",
    "\n",
    "        print(\"\\nüìä Top 15 Feature Importances (LGBM):\")\n",
    "        print(importances.head(15))\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.barplot(x=importances.head(15).values, y=importances.head(15).index)\n",
    "        plt.title(\"Top 15 Feature Importances (LGBMClassifier)\")\n",
    "        plt.xlabel(\"Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # === 2. Permutation Importance\n",
    "    print(\"\\n‚è≥ Calculating permutation importance (val set)...\")\n",
    "    perm_result = permutation_importance(\n",
    "        stack_class, X_test_combined, y_test_class,\n",
    "        scoring=\"accuracy\", n_repeats=10, random_state=42\n",
    "    )\n",
    "\n",
    "    perm_importances = pd.Series(perm_result.importances_mean, index=X_test_combined.columns)\n",
    "    perm_sorted = perm_importances.sort_values(ascending=False)\n",
    "\n",
    "    print(\"\\nüìä Top 15 Permutation Importances (Accuracy impact):\")\n",
    "    print(perm_sorted.head(15))\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=perm_sorted.head(15).values, y=perm_sorted.head(15).index)\n",
    "    plt.title(\"Top 15 Permutation Importances (LGBMClassifier)\")\n",
    "    plt.xlabel(\"Mean Accuracy Impact\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    unique_classes, class_counts = np.unique(preds_stack_clf, return_counts=True)\n",
    "    print(\"\\nüî¢ Predicted Class Distribution:\")\n",
    "    for cls, count in zip(unique_classes, class_counts):\n",
    "        pct = 100 * count / len(preds_stack_clf)\n",
    "        print(f\"Class {cls}: {count} samples ({pct:.2f}%)\")\n",
    "\n",
    "    ################################################\n",
    "    ####### Target Distribution\n",
    "    ####### REGRESSION #######\n",
    "    print(\"\\nüîç Target distribution:\")\n",
    "    print(y_train_reg.describe())\n",
    "    ####### CLASSIFICATION #######\n",
    "    print(\"\\nüîç Target distribution:\")\n",
    "    print(y_train_class.describe())\n",
    "    \n",
    "    ################################################\n",
    "    ####### Choose final model\n",
    "    ####### REGRESSION #######\n",
    "    preds = stack.predict(X_test_combined)\n",
    "    print(\"\\nüîç Checking prediction variance from stack model:\")\n",
    "    print(f\"Min: {preds.min():.8f}\")\n",
    "    print(f\"Max: {preds.max():.8f}\")\n",
    "    print(f\"Mean: {preds.mean():.8f}\")\n",
    "    print(f\"Std Dev: {preds.std():.8f}\")\n",
    "    print(f\"First 5 Predictions: {preds[:5]}\")\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    mae = mean_absolute_error(y_test_reg, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_reg, preds))\n",
    "    r2 = r2_score(y_test_reg, preds)\n",
    "\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R¬≤: {r2:.4f}\")\n",
    "    ####### CLASSIFICATION #######\n",
    "    preds_class = stack_class.predict(X_test_combined)\n",
    "    print(\"\\nüîç Checking prediction summary from classification stack model:\")\n",
    "    print(f\"Class Distribution: {np.bincount(preds_class)}\")\n",
    "    print(f\"First 5 Predictions: {preds_class[:5]}\")\n",
    "\n",
    "    accuracy = accuracy_score(y_test_class, preds_class)\n",
    "    precision = precision_score(y_test_class, preds_class, average='weighted')\n",
    "    recall = recall_score(y_test_class, preds_class, average='weighted')\n",
    "    f1 = f1_score(y_test_class, preds_class, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision (weighted): {precision:.4f}\")\n",
    "    print(f\"Recall (weighted): {recall:.4f}\")\n",
    "    print(f\"F1 Score (weighted): {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_class, preds_class))\n",
    "\n",
    "    return\n",
    "\n",
    "    thresholds = [0.0005, 0.005]\n",
    "    print(f\"\\nüîé Predicted return range for LOOKAHEAD={LOOKAHEAD}: min={preds.min():.6f}, max={preds.max():.6f}\")\n",
    "    for params in combinations:\n",
    "        for thresh in thresholds:\n",
    "            results = evaluate_regression_combo(\n",
    "                X_test=X_test_combined,\n",
    "                preds=preds,\n",
    "                labeled=labeled,\n",
    "                df=df,\n",
    "                avoid_funcs=avoid_funcs,\n",
    "                SL_ATR_MULT=params['SL_ATR_MULT'],\n",
    "                TP_ATR_MULT=params['TP_ATR_MULT'],\n",
    "                TRAIL_START_MULT=params['TRAIL_START_MULT'],\n",
    "                TRAIL_STOP_MULT=params['TRAIL_STOP_MULT'],\n",
    "                TICK_VALUE=params['TICK_VALUE'],\n",
    "                is_same_session=is_same_session,\n",
    "                long_thresh=thresh,\n",
    "                short_thresh=-thresh,\n",
    "\n",
    "                # üî• NEW: enable confidence-based scaling and filtering\n",
    "                base_contracts=1,\n",
    "                max_contracts=5,\n",
    "                skip_weak_conf=True,\n",
    "                weak_conf_zscore=0.2\n",
    "            )\n",
    "\n",
    "            results['params'] = params\n",
    "            all_results.append(results)\n",
    "\n",
    "            print(f\"\\n\\nüîç Evaluating with params: {params}\")\n",
    "\n",
    "            print(\n",
    "                f\"\\n‚úÖ LOOKAHEAD={LOOKAHEAD} | Threshold={thresh}\"\n",
    "                f\"\\nPnL: ${results['pnl']:.2f}\"\n",
    "                f\"\\nTrades: {results['trades']}\"\n",
    "                f\"\\nWin Rate: {results['win_rate']:.2%}\"\n",
    "                f\"\\nExpectancy: {results['expectancy']:.2f}\"\n",
    "                f\"\\nProfit Factor: {results['profit_factor']:.2f}\"\n",
    "                f\"\\nSharpe Ratio: {results['sharpe']:.2f}\"\n",
    "                f\"\\nLong Trades: {results['long_trades']} | Short Trades: {results['short_trades']}\"\n",
    "            )\n",
    "\n",
    "            print(\"Avoid Hits:\")\n",
    "            for name, count in results['avoid_hits'].items():\n",
    "                print(f\" - {name}: {count}\")\n",
    "\n",
    "            if not results['results'].empty and 'pnl' in results['results'].columns:\n",
    "                print(\"\\nüî¢ Top 10 PnL trades:\")\n",
    "                print(results['results'].sort_values(by='pnl', ascending=False).head(10))\n",
    "\n",
    "                print(\"\\nüîª Bottom 10 PnL trades:\")\n",
    "                print(results['results'].sort_values(by='pnl', ascending=True).head(10))\n",
    "            else:\n",
    "                print(\"\\n‚ö†Ô∏è No trades executed, skipping PnL trade breakdown.\")\n",
    "\n",
    "\n",
    "    summary_df = pd.DataFrame([{\n",
    "        'pnl': r['pnl'],\n",
    "        'sharpe': r['sharpe'],\n",
    "        'expectancy': r['expectancy'],\n",
    "        'profit_factor': r['profit_factor'],\n",
    "        'win_rate': r['win_rate'],\n",
    "        'trades': r['trades'],\n",
    "        **r['params']\n",
    "    } for r in all_results])\n",
    "    top = summary_df.sort_values(by='sharpe', ascending=False).head(5)\n",
    "    print(top)\n",
    "\n",
    "    metadata = {\n",
    "        \"lookahead\": LOOKAHEAD,\n",
    "        \"train_range\": [str(train[\"datetime\"].min()), str(train[\"datetime\"].max())],\n",
    "        \"test_range\": [str(test[\"datetime\"].min()), str(test[\"datetime\"].max())],\n",
    "        \"features_used\": top_features,\n",
    "        \"lgbm_params\": lgbm_params,\n",
    "        \"catboost_params\": catboost_params,\n",
    "        \"meta_params\": meta_params\n",
    "    }\n",
    "    with open(f\"model_metadata_{LOOKAHEAD}.json\", \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "        \n",
    "    joblib.dump(stack, f\"stack_model_LOOKAHEAD_{LOOKAHEAD}_session_less.pkl\")\n",
    "    with open(\"stack_features.json\", \"w\") as f:\n",
    "        json.dump(top_features, f)\n",
    "\n",
    "    return {\n",
    "        'lookahead': LOOKAHEAD,\n",
    "        'pnl': results['pnl'],\n",
    "        'win_rate': results['win_rate'],\n",
    "        'expectancy': results['expectancy'],\n",
    "        'profit_factor': results['profit_factor'],\n",
    "        'sharpe': results['sharpe'],\n",
    "        'trades': results['trades'],\n",
    "        'preds_lgbm': preds_lgbm,\n",
    "        'preds_stack': preds_stack,\n",
    "        'pres_catboost': preds_catboost,\n",
    "        'results': all_results,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lookahead(LOOKAHEAD):\n",
    "    try:\n",
    "        result = run_lookahead_for_session(LOOKAHEAD)\n",
    "        if result is None:\n",
    "            print(f\"No valid run for session_less, skipping CSV.\")\n",
    "            return\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Skipping session session_less due to error: {e}\")\n",
    "        return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookahead_values = [5]\n",
    "lookahead_results = []\n",
    "\n",
    "for val in lookahead_values:\n",
    "    result = run_lookahead(val)\n",
    "    lookahead_results.append(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for result in lookahead_results:\n",
    "#     stack_preds = result['stack'].predict(X_test_scaled)\n",
    "#     rf_preds = result['models']['rf'].predict(X_test_scaled)\n",
    "#     xgb_preds = result['models']['xgb'].predict(X_test_scaled)\n",
    "#     enet_preds = result['models']['elasticnet'].predict(X_test_scaled)\n",
    "    \n",
    "#     plt.figure(figsize=(12, 4))\n",
    "#     plt.plot(rf_preds[:100], label='RF')\n",
    "#     plt.plot(xgb_preds[:100], label='XGB')\n",
    "#     plt.plot(enet_preds[:100], label='ElasticNet')\n",
    "#     plt.plot(stack_preds[:100], label='Stack', linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for run in lookahead_results:\n",
    "#     for r in run['results']:\n",
    "#         print(r)\n",
    "#         df = r['results'].copy()\n",
    "#         df = df.sort_values(by='entry_time')\n",
    "#         df['cumulative_pnl'] = df['pnl'].cumsum()\n",
    "\n",
    "#         if df['cumulative_pnl'].iloc[-1] > 0 and r['sharpe'] > 10 and r['trades'] > 150 and r['win_rate'] > 0.55 and r['profit_factor'] > 1.5 and r['expectancy'] > 0.5 and r['pnl'] > 50000:\n",
    "#                 plt.figure(figsize=(12, 4))\n",
    "#                 plt.plot(df['entry_time'], df['cumulative_pnl'], label='Cumulative PnL', color='green')\n",
    "#                 plt.title(f\"PnL | Lookahead={run['lookahead']} | Sharpe={r['sharpe']:.2f}\")\n",
    "#                 plt.xlabel(\"Datetime\")\n",
    "#                 plt.ylabel(\"PnL\")\n",
    "#                 plt.grid(True)\n",
    "#                 plt.legend()\n",
    "#                 plt.tight_layout()\n",
    "#                 plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best result holder by lookahead value\n",
    "best_by_lookahead = {\n",
    "    5: {'win_rate': float('-inf'), 'result': None},\n",
    "    15: {'win_rate': float('-inf'), 'result': None}\n",
    "}\n",
    "\n",
    "# Fill best_by_lookahead from results\n",
    "for run in lookahead_results:\n",
    "    lookahead = run['lookahead']\n",
    "    if lookahead in best_by_lookahead:\n",
    "        for r in run['results']:\n",
    "            if r['win_rate'] > best_by_lookahead[lookahead]['win_rate']:\n",
    "                best_by_lookahead[lookahead] = {\n",
    "                    'win_rate': r['win_rate'],\n",
    "                    'result': r,\n",
    "                    'lookahead': lookahead\n",
    "                }\n",
    "\n",
    "# Display results nicely\n",
    "for lookahead in [5]:\n",
    "    best = best_by_lookahead[lookahead]\n",
    "    if best['result']:\n",
    "        df = best['result']['results'].copy()\n",
    "        df = df.sort_values(by='entry_time')\n",
    "        df['cumulative_pnl'] = df['pnl'].cumsum()\n",
    "\n",
    "        # Set float format for readable output\n",
    "        pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "        print(f\"\\nüèÜ Best Win Rate Result for Lookahead={lookahead}\")\n",
    "        print(f\"Win Rate: {best['win_rate']:.2%}\")\n",
    "        print(f\"PnL: {best['result']['pnl']:.2f}\")\n",
    "        print(f\"Trades: {best['result']['trades']}\")\n",
    "        print(f\"Sharpe: {best['result']['sharpe']:.2f}\")\n",
    "        print(f\"Expectancy: {best['result']['expectancy']:.2f}\")\n",
    "        print(f\"Profit Factor: {best['result']['profit_factor']:.2f}\")\n",
    "        print(f\"Params: {best['result']['params']}\")\n",
    "\n",
    "        print(\"\\nüßæ All Trades from Best Win Rate Result:\")\n",
    "        print(df[['entry_time', 'exit_time', 'side', 'entry_price', 'exit_price',\n",
    "                  'pnl', 'mfe', 'mae', 'cumulative_pnl']].to_string(index=False))\n",
    "\n",
    "        # Plot cumulative PnL\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(df['entry_time'], df['cumulative_pnl'], label='Cumulative PnL', color='blue')\n",
    "        plt.title(f\"Best Win Rate Run | Lookahead={lookahead} | Win Rate={best['win_rate']:.2%}\")\n",
    "        plt.xlabel(\"Datetime\")\n",
    "        plt.ylabel(\"Cumulative PnL\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No valid result found for Lookahead={lookahead}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef([lookahead_results['preds_rf'], lookahead_results['preds_xgb'], lookahead_results['preds_elasticnet']])\n",
    "preds_matrix = np.vstack([lookahead_results['preds_rf'], lookahead_results['preds_xgb'], lookahead_results['preds_elasticnet']])\n",
    "corr_matrix = np.corrcoef(preds_matrix)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(corr_matrix, annot=True, xticklabels=['RF', 'XGB', 'ENet'], yticklabels=['RF', 'XGB', 'ENet'], cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Between Base Model Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "# y_pred = best_lookahead.predict(X_test)\n",
    "best_lookahead = max(lookahead_results, key=lambda x: max(r['pnl'] for r in x['results']))\n",
    "y_pred = best_lookahead['stack'].predict(X_test_scaled)\n",
    "\n",
    "# Confusion Matrix\n",
    "labels = sorted(class_mapping)  # Make sure the order matches\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "\n",
    "# Display Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, labels=labels, digits=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
